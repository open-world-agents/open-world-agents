{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to OWA","text":""},{"location":"#open-world-agents-documentation","title":"Open World Agents Documentation","text":"<p>A comprehensive framework for building AI agents that interact with desktop applications through vision, keyboard, and mouse control.</p> <p>Open World Agents (OWA) is a monorepo containing the complete toolkit for multimodal desktop agent development. From high-performance data capture to model training and real-time evaluation, everything is designed for flexibility and performance.</p>"},{"location":"#quick-start-record-train-in-3-steps","title":"\ud83d\ude80 Quick Start: Record \u2192 Train in 3 Steps","text":"<pre><code># 1. Record desktop interaction\n$ ocap my-session.mcap\n\n# 2. Process to training format\n$ python scripts/01_raw_events_to_event_dataset.py --train-dir ./\n\n# 3. Train your model\n$ python train.py --dataset ./event-dataset\n</code></pre> <p>\ud83d\udcd6 Detailed Guide: Complete Quick Start Tutorial - Step-by-step walkthrough with examples and troubleshooting</p>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>OWA consists of the following core components:</p> <ul> <li>\ud83c\udf0d Environment Framework - Universal interface for native desktop automation (\"USB-C of desktop agents\") with pre-built plugins for desktop control, high-performance screen capture (6x faster), and zero-configuration plugin system</li> <li>\ud83d\udcca Data Infrastructure - Complete desktop agent data pipeline from recording to training with <code>OWAMcap</code> format - a universal standard powered by mcap</li> <li>\ud83d\udee0\ufe0f CLI Tools - Command-line utilities (<code>owl</code>) for recording, analyzing, and managing agent data</li> <li>\ud83e\udd16 Examples - Complete implementations and training pipelines for multimodal agents</li> </ul>"},{"location":"#environment-framework","title":"\ud83c\udf0d Environment Framework","text":"<p>Universal interface for native desktop automation with real-time event handling and zero-configuration plugin discovery.</p>"},{"location":"#environment-navigation","title":"Environment Navigation","text":"Section Description Environment Overview Core concepts and quick start guide Environment Guide Complete system overview and usage examples Custom Plugins Create your own environment extensions CLI Tools Plugin management and exploration commands <p>Built-in Plugins:</p> Plugin Description Key Features Standard Core utilities Time functions, periodic tasks Desktop Desktop automation Mouse/keyboard control, window management GStreamer High-performance capture 6x faster screen recording"},{"location":"#data-infrastructure-complete-desktop-agent-data-pipeline","title":"\ud83d\udcca Data Infrastructure: Complete Desktop Agent Data Pipeline","text":"<p>Desktop AI needs high-quality, synchronized multimodal data: screen captures, mouse/keyboard events, and window context. OWA provides the complete pipeline from recording to training.</p>"},{"location":"#the-owa-data-ecosystem","title":"The OWA Data Ecosystem","text":"<p>\ud83c\udfaf Getting Started New to OWA data? Start here:</p> <ul> <li>Why OWAMcap? - Understand the problem and solution</li> <li>Recording Data - Capture desktop interactions with <code>ocap</code></li> <li>Exploring Data - View and analyze your recordings</li> </ul> <p>\ud83d\udcda Technical Reference Deep dive into the format and pipeline:</p> <ul> <li>OWAMcap Format Guide - Complete technical specification</li> <li>Data Pipeline - Transform recordings to training-ready datasets</li> </ul> <p>\ud83d\udee0\ufe0f Tools &amp; Ecosystem</p> <ul> <li>Data Viewer - Web-based visualization tool</li> <li>Comparison with LeRobot - Technical comparison with alternatives</li> <li>CLI Tools (owl) - Command-line interface for data analysis and management</li> </ul>"},{"location":"#community-datasets","title":"\ud83e\udd17 Community Datasets","text":"<p>Browse Available Datasets: \ud83e\udd17 datasets?other=OWA</p> <ul> <li>Growing Collection: Hundreds of community-contributed datasets</li> <li>Standardized Format: All use OWAMcap for seamless integration</li> <li>Interactive Preview: Hugging Face Spaces Visualizer</li> <li>Easy Sharing: Upload recordings directly with one command</li> </ul> <p>\ud83d\ude80 Impact: OWA has democratized desktop agent data, growing from zero to hundreds of public datasets in the unified OWAMcap format.</p>"},{"location":"#awesome-examples","title":"\ud83e\udd16 Awesome Examples","text":"<p>Learn from complete implementations and training pipelines.</p> Example Description Status Multimodal Game Agent Vision-based game playing agent \ud83d\udea7 In Progress GUI Agent General desktop application automation \ud83d\udea7 In Progress Interactive World Model Predictive modeling of desktop environments \ud83d\udea7 In Progress Usage with LLMs Integration with large language models \ud83d\udea7 In Progress Usage with Transformers Vision transformer implementations \ud83d\udea7 In Progress"},{"location":"#development-resources","title":"Development Resources","text":"<p>Learn how to contribute, report issues, and get help.</p> Resource Description Help with OWA Community support resources Installation Guide Detailed installation instructions Contributing Guide Development setup, bug reports, feature proposals FAQ for Developers Common questions and troubleshooting"},{"location":"#license","title":"License","text":"<p>This project is released under the MIT License. See the LICENSE file for details.</p>"},{"location":"contributing/","title":"Contributing to Open World Agents","text":"<p>This guide covers OWA-specific development practices and testing requirements.</p>"},{"location":"contributing/#issues-and-pull-requests","title":"Issues and Pull Requests","text":"<p>Questions, feature requests and bug reports are welcome as discussions or issues.</p> <p>Security Vulnerabilities</p> <p>For security vulnerabilities, see our security policy.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>Complete Setup Instructions</p> <p>See the Installation Guide for complete development setup instructions.</p> <p>Quick setup for contributors:</p> <pre><code>git clone https://github.com/open-world-agents/open-world-agents.git\ncd open-world-agents\nconda create -n owa python=3.11 open-world-agents::gstreamer-bundle -y &amp;&amp; conda activate owa\npip install uv virtual-uv\nvuv install --dev\nvuv pip install -e projects/owa-env-example  # For testing\n</code></pre>"},{"location":"contributing/#testing-requirements","title":"Testing Requirements","text":"<p>Before submitting a PR, run these OWA-specific checks:</p> Code QualityPlugin DocumentationTest Suite <pre><code>ruff check --fix      # Fix linting issues\nruff format --check   # Check formatting\n</code></pre> <p>OWA validates environment plugin documentation automatically:</p> <pre><code>owl env docs --validate --strict\n</code></pre> <pre><code>coverage run -m pytest  # Run all tests with coverage\n</code></pre>"},{"location":"contributing/#environment-plugin-development","title":"Environment Plugin Development","text":"<p>Custom Plugin Development</p> <p>For creating custom environment plugins, see the Custom EnvPlugin Development Guide which covers:</p> <ul> <li>Plugin structure and requirements</li> <li>Entry point registration</li> <li>Component types (Callables, Listeners, Runnables)</li> <li>Complete examples and troubleshooting</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>OWA uses MkDocs with Material theme for documentation. The site includes auto-generated plugin documentation and manual content.</p> <p>To work with documentation:</p> <pre><code>vuv install --extra docs  # Install MkDocs and dependencies\nvuv run mkdocs serve       # Serve locally at http://localhost:8000\n</code></pre> <p>Documentation validation happens automatically in CI via <code>owl env docs --validate --strict</code>.</p>"},{"location":"contributing/#monorepo-development","title":"Monorepo Development","text":"<p>OWA uses <code>virtual-uv</code> for dependency management. For complete setup instructions, see Installation Guide.</p> <p>Quick commands: <pre><code>vuv install --dev              # Install all dev dependencies\nvuv pip install -e projects/X  # Install specific project\n</code></pre></p>"},{"location":"contributing/#release-management","title":"Release Management","text":"<p>For maintainers, OWA includes release automation scripts:</p> <p>Release Scripts</p> <p>See <code>scripts/release/README.md</code> for lockstep versioning and PyPI publishing tools.</p> <pre><code># Update all packages to version 1.0.0\nvuv run scripts/release/main.py version 1.0.0\n\n# Publish to PyPI\nvuv run scripts/release/main.py publish\n</code></pre>"},{"location":"faq_dev/","title":"FAQ for Developers","text":""},{"location":"faq_dev/#how-to-disable-typer-specific-traceback","title":"How to disable <code>typer</code>-specific traceback?","text":"<p>set <code>_TYPER_STANDARD_TRACEBACK=1</code></p> <p>https://stackoverflow.com/questions/76375307/how-to-make-typer-traceback-look-normal</p>"},{"location":"help_with_owa/","title":"Getting help with OWA","text":"<p>If you need help getting started with OWA or with advanced usage, the following sources may be useful.</p>"},{"location":"help_with_owa/#github-discussions","title":"GitHub Discussions","text":"<p>GitHub discussions are useful for asking questions, your question and the answer will help everyone.</p>"},{"location":"help_with_owa/#direct-messages","title":"Direct Messages","text":"<p>If you need further assistance, please feel free to directly message the main contributors via Slack, Discord, or email:</p> <ul> <li>Suhwan Choi: milkclouds00@gmail.com</li> <li>Yunsung Lee: dldbstjd9751@gmail.com</li> </ul>"},{"location":"install/","title":"Installation Guide","text":""},{"location":"install/#quick-start-recommended","title":"Quick Start (Recommended)","text":"<p>For most users who want to use Open World Agents, installation is straightforward:</p>"},{"location":"install/#option-1-full-installation-with-video-processing","title":"Option 1: Full Installation with Video Processing","text":"<p>If you need desktop recording, screen capture, or video processing capabilities:</p> <pre><code># Install GStreamer dependencies first\nconda install open-world-agents::gstreamer-bundle\n\n# Then install all OWA packages\npip install owa\n</code></pre>"},{"location":"install/#option-2-headless-installation","title":"Option 2: Headless Installation","text":"<p>For data processing, ML training, or headless servers without video capture needs:</p> <pre><code>pip install owa\n</code></pre> <p>When to use GStreamer</p> <p>Install GStreamer if you need:</p> <ul> <li>Desktop recording with <code>ocap</code></li> <li>Real-time screen capture with <code>owa.env.gst</code></li> <li>Video processing capabilities</li> <li>Complete multimodal data capture</li> </ul> <p>Skip GStreamer if you only need:</p> <ul> <li>Data processing and analysis</li> <li>ML training on existing datasets</li> <li>Headless server environments</li> <li>Working with pre-recorded MCAP files</li> </ul>"},{"location":"install/#available-packages","title":"Available Packages","text":"<p>All OWA packages are pure Python and available on PyPI. Install via <code>pip install owa</code> for all components:</p> Name PyPI Description <code>owa</code> Meta-package with all core components <code>owa-core</code> Framework foundation with registry system <code>owa-cli</code> Command-line tools (<code>owl</code>) for data analysis <code>mcap-owa-support</code> OWAMcap format support and utilities <code>ocap</code> \ud83c\udfa5 Desktop recorder for multimodal data capture <code>owa-env-desktop</code> Mouse, keyboard, window event handling <code>owa-env-gst</code> \ud83c\udfa5 GStreamer-powered screen capture (6x faster) <p>\ud83c\udfa5 Video Processing Packages: Packages marked with \ud83c\udfa5 require GStreamer dependencies. Install <code>conda install open-world-agents::gstreamer-bundle</code> first for full functionality.</p>"},{"location":"install/#gstreamer-bundle","title":"GStreamer Bundle","text":"<p>For video processing capabilities, install the GStreamer bundle separately:</p> <pre><code>conda install open-world-agents::gstreamer-bundle\n</code></pre> <p>This bundle includes all necessary GStreamer dependencies (pygobject, gst-python, gst-plugins, etc.) that are complex to install via pip.</p>"},{"location":"install/#development-installation-editable","title":"Development Installation (Editable)","text":"<p>For Contributors and Developers</p> <p>This section is for users who want to modify the source code, contribute to the project, or need the latest development features.</p>"},{"location":"install/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding with development installation, ensure you have the necessary tools:</p> <ol> <li>Git: For cloning the repository</li> <li>Python 3.11+: Required for all OWA packages</li> <li>Virtual Environment Tool: We recommend conda/mamba for GStreamer support</li> </ol>"},{"location":"install/#step-1-setup-virtual-environment","title":"Step 1: Setup Virtual Environment","text":"conda/mamba (Recommended)Other Virtual Environments <ol> <li> <p>Install miniforge following the installation guide:     <pre><code># Download and install miniforge\n# This provides both conda and mamba (faster conda)\n</code></pre></p> </li> <li> <p>Create and activate your environment:     <pre><code>conda create -n owa python=3.11 -y\nconda activate owa\n</code></pre></p> </li> <li> <p>(Optional for video processing) Install GStreamer dependencies:     <pre><code># Install GStreamer bundle for video processing\nconda install open-world-agents::gstreamer-bundle\n</code></pre></p> </li> </ol> <p>You can use other virtual environment tools (venv, virtualenv, poetry, etc.), but:</p> <ul> <li>GStreamer must be installed separately for video processing functionality, which is not easy without <code>conda</code></li> <li>We recommend conda/mamba for the best development experience</li> </ul>"},{"location":"install/#step-2-clone-and-setup-development-tools","title":"Step 2: Clone and Setup Development Tools","text":"<pre><code># Clone the repository\ngit clone https://github.com/open-world-agents/open-world-agents\ncd open-world-agents\n\n# Install uv (fast Python package manager)\npip install uv\n\n# Install virtual-uv for easier monorepo management\npip install virtual-uv\n</code></pre>"},{"location":"install/#step-3-install-in-editable-mode","title":"Step 3: Install in Editable Mode","text":"uv + virtual-uv (Recommended)uv (Simple)pip (Manual) <pre><code># Ensure you're in the project root and environment is activated\ncd open-world-agents\nconda activate owa  # or your environment name\n\n# Install all packages in editable mode\nvuv install\n</code></pre> <p>Tip</p> <p><code>vuv</code> (virtual-uv) handles the complex dependency resolution for our monorepo structure and installs all packages in the correct order.</p> <pre><code># Install with inexact dependency resolution\nuv sync --inexact\n</code></pre> <pre><code># Install in correct order (dependency order matters with pip)\npip install -e projects/owa-core\npip install -e projects/mcap-owa-support\npip install -e projects/owa-env-desktop\npip install -e projects/owa-env-gst  # Requires GStreamer\npip install -e projects/owa-cli\npip install -e projects/ocap\n</code></pre> <p>Installation Order Matters</p> <p>When using <code>pip</code> instead of <code>uv</code>, the installation order is critical because <code>pip</code> cannot resolve the monorepo dependencies specified in <code>[tool.uv.sources]</code>.</p>"},{"location":"install/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<pre><code># Test core functionality\npython -c \"from owa.core.registry import CALLABLES; print('\u2705 Core installed')\"\n\n# Test CLI tools\nowl --help\nowl env list  # List discovered plugins\nocap --help\n\n# Test GStreamer (if installed)\npython -c \"import gi; gi.require_version('Gst', '1.0'); print('\u2705 GStreamer OK')\"\n</code></pre>"},{"location":"install/#troubleshooting","title":"Troubleshooting","text":""},{"location":"install/#gstreamer-issues","title":"GStreamer Issues","text":"<p>If you encounter GStreamer-related errors:</p> <ol> <li>Install GStreamer bundle:    <pre><code>conda install open-world-agents::gstreamer-bundle\n</code></pre></li> <li>Verify GStreamer installation:    <pre><code>python -c \"import gi; gi.require_version('Gst', '1.0'); print('\u2705 GStreamer OK')\"\n</code></pre></li> <li>Restart your Python environment after installing GStreamer dependencies</li> </ol>"},{"location":"install/#virtual-environment-issues","title":"Virtual Environment Issues","text":"<ul> <li>Always activate your environment before running <code>vuv</code> or installation commands</li> <li>Use absolute paths if you encounter import issues</li> <li>Reinstall virtual-uv if you encounter dependency resolution problems:   <pre><code>pip uninstall virtual-uv\npip install virtual-uv\n</code></pre></li> </ul>"},{"location":"install/#package-version-conflicts","title":"Package Version Conflicts","text":"<p>OWA uses lockstep versioning. If you encounter version conflicts:</p> <pre><code># Check installed versions\npip list | grep owa\n\n# Reinstall all packages with matching versions\npip install --upgrade owa\n</code></pre>"},{"location":"install/#import-errors","title":"Import Errors","text":"<p>If you encounter import errors after installation:</p> <ol> <li>Ensure Python environment is activated</li> <li>Restart Python kernel/terminal after installing packages</li> <li>Verify installation: <code>pip list | grep owa</code></li> </ol>"},{"location":"quick-start/","title":"Quick Start Guide","text":"<p>Complete step-by-step walkthrough for getting started with Open World Agents</p> <p>3-Step Workflow</p> <p>This guide covers the complete OWA workflow: Record \u2192 Process \u2192 Train</p>"},{"location":"quick-start/#overview","title":"Overview","text":"<p>This guide provides detailed explanations, examples, and troubleshooting for the 3-step OWA workflow:</p> <pre><code># 1. Record desktop interaction\n$ ocap my-session.mcap\n\n# 2. Process to training format\n$ python scripts/01_raw_events_to_event_dataset.py --train-dir ./\n\n# 3. Train your model\n$ python train.py --dataset ./event-dataset\n</code></pre> <p>\ud83d\udcd6 Detailed Guide: Complete Quick Start Tutorial - Step-by-step walkthrough with examples and troubleshooting</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<p>Installation Required</p> <p>Before starting, ensure you have OWA installed. See the Installation Guide for detailed setup instructions.</p> Video RecordingData Processing Only <p>For full recording capabilities: <pre><code># Install GStreamer dependencies first\nconda install open-world-agents::gstreamer-bundle\npip install owa\n</code></pre></p> <p>For basic data processing: <pre><code>pip install owa\n</code></pre></p>"},{"location":"quick-start/#step-1-record-desktop-interaction","title":"Step 1: Record Desktop Interaction","text":"<p>Record with ocap</p> <p>Use <code>ocap</code> (Omnimodal CAPture) to record your desktop interactions with synchronized video, audio, and input events.</p> <pre><code>$ ocap my-session.mcap\n</code></pre> <p>What this captures</p> <ul> <li> Screen video with hardware acceleration</li> <li> Keyboard events with nanosecond precision</li> <li> Mouse interactions with exact coordinates</li> <li> Audio recording synchronized with video</li> <li> Everything saved in the OWAMcap format</li> </ul> <p>Learn More</p> <ul> <li>Desktop Recording Guide - Complete setup and usage</li> <li>OWAMcap Format - Technical specification</li> <li>Recording Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"quick-start/#step-2-process-to-training-format","title":"Step 2: Process to Training Format","text":"<p>Transform with Data Pipeline</p> <p>Transform your recorded data into training-ready datasets using OWA's data pipeline.</p> <pre><code>$ python scripts/01_raw_events_to_event_dataset.py --train-dir ./\n</code></pre> <p>Processing Pipeline</p> <ul> <li> Extracts events from the MCAP file</li> <li> Converts format to standardized training structure</li> <li> Handles media references and synchronization</li> <li> Prepares data for ML frameworks</li> </ul> <p>Advanced Processing</p> <pre><code>flowchart LR\n    A[MCAP File] --&gt; B[Event Dataset]\n    B --&gt; C[Binned Dataset]\n    C --&gt; D[Training Ready]\n\n    style A fill:#e1f5fe\n    style D fill:#e8f5e8</code></pre> <p>Learn More</p> <ul> <li>Data Pipeline Guide - Complete processing workflow</li> <li>Data Explorer - Analyze and visualize your data</li> <li>CLI Tools - Command-line utilities for data management</li> </ul>"},{"location":"quick-start/#step-3-train-your-model","title":"Step 3: Train Your Model","text":"<p>TODO: Training Implementation</p> <p>This section is under development. Training scripts and detailed examples are coming soon.</p> <p>Train with Processed Data</p> <p>Use the processed dataset to train your desktop agent model.</p> <pre><code>$ python train.py --dataset ./event-dataset\n</code></pre> <p>Training Capabilities</p> <ul> <li> Multimodal models on desktop interactions</li> <li> Learn from demonstrations - human behavior patterns</li> <li> Application-specific agents - tailored for your use case</li> <li> Performance evaluation on real tasks</li> </ul> <p>Training Architecture</p> <pre><code>flowchart TD\n    A[Event Dataset] --&gt; B[Vision Encoder]\n    A --&gt; C[Action Encoder]\n    B --&gt; D[Multimodal Fusion]\n    C --&gt; D\n    D --&gt; E[Policy Network]\n    E --&gt; F[Desktop Agent]\n\n    style A fill:#e1f5fe\n    style F fill:#e8f5e8</code></pre> <p>Learn More</p> <ul> <li>Agent Examples - Complete implementations and training pipelines</li> <li>Multimodal Game Agent - Vision-based game playing</li> <li>GUI Agent - General desktop automation</li> <li>Usage with LLMs - Integration patterns</li> </ul>"},{"location":"quick-start/#environment-framework-integration","title":"Environment Framework Integration","text":"<p>Real-time Agent Interactions</p> <p>While recording and training, you can also use OWA's real-time environment framework for live agent interactions:</p> Screen CaptureEvent MonitoringAgent Actions <pre><code>from owa.core import CALLABLES\n\n# Real-time screen capture\nscreen = CALLABLES[\"desktop/screen.capture\"]()\n</code></pre> <pre><code>from owa.core import LISTENERS\n\n# Monitor user interactions\ndef on_key(event):\n    print(f\"Key pressed: {event.vk}\")\n\nlistener = LISTENERS[\"desktop/keyboard\"]().configure(callback=on_key)\n</code></pre> <pre><code>from owa.core import CALLABLES\n\n# Perform desktop actions\nCALLABLES[\"desktop/mouse.click\"](\"left\", 2)  # Double-click\nCALLABLES[\"desktop/keyboard.type\"](\"Hello World!\")\n</code></pre> <p>Learn More</p> <ul> <li>Environment Guide - Complete system overview</li> <li>Environment Framework - Core concepts and quick start</li> <li>Custom Plugins - Extend functionality</li> </ul>"},{"location":"quick-start/#community-resources","title":"Community Resources","text":"<p>Datasets &amp; Tools</p> Community DatasetsGetting Help <ul> <li> Browse Community Datasets - Hundreds of OWAMcap datasets</li> <li> Dataset Visualizer - Interactive preview tool</li> </ul> <ul> <li> FAQ - Common questions and troubleshooting</li> <li> Contributing Guide - Development setup and contribution guidelines</li> <li> Help with OWA - Community support resources</li> </ul>"},{"location":"quick-start/#next-steps","title":"Next Steps","text":"<p>Your Journey Continues</p> <ol> <li> <p> Explore Examples: Start with Agent Examples to see complete implementations</p> </li> <li> <p> Join the Community: Browse and contribute datasets</p> </li> <li> <p> Build Custom Plugins: Extend OWA with custom environment plugins</p> </li> <li> <p> Advanced Usage: Dive into technical documentation for advanced features</p> </li> </ol> <p>Quick Links</p> <ul> <li>Need help? \u2192 FAQ or Community Support</li> <li>Ready to build? \u2192 Agent Examples</li> <li>Want to contribute? \u2192 Contributing Guide</li> </ul>"},{"location":"cli/","title":"OWA CLI (<code>owl</code>) - Command Line Tools","text":"<p>The <code>owl</code> command provides comprehensive tools for working with OWA data, environments, and message types. It's your primary interface for managing MCAP files, environment plugins, message schemas, and video processing.</p>"},{"location":"cli/#installation","title":"Installation","text":"<p>The CLI is included with the <code>owa-cli</code> package:</p> <pre><code>pip install owa-cli\n</code></pre> <p>After installation, the <code>owl</code> command becomes available in your terminal.</p>"},{"location":"cli/#quick-start","title":"Quick Start","text":"<pre><code># Get help for any command\nowl --help\nowl mcap --help\n\n# Common workflows\nowl mcap info session.mcap              # Inspect MCAP files\nowl env list                            # List environment plugins  \nowl messages show desktop/MouseEvent    # View message schemas\nowl video probe recording.mkv           # Analyze video files\n</code></pre>"},{"location":"cli/#command-groups","title":"Command Groups","text":"<p>The <code>owl</code> CLI is organized into specialized command groups:</p>"},{"location":"cli/#mcap-commands-owl-mcap","title":"\ud83d\udcc1 MCAP Commands (<code>owl mcap</code>)","text":"<p>Tools for working with MCAP files - the core data format for multimodal desktop recordings.</p> <p>Key commands: <code>info</code>, <code>cat</code>, <code>convert</code>, <code>migrate</code>, <code>sanitize</code></p> <pre><code>owl mcap info session.mcap              # File information\nowl mcap cat session.mcap --n 10        # View messages  \nowl mcap convert session.mcap           # Convert to subtitles\n</code></pre>"},{"location":"cli/#environment-commands-owl-env","title":"\ud83d\udd0c Environment Commands (<code>owl env</code>)","text":"<p>Manage environment plugins that capture desktop data and provide system integration.</p> <p>Key commands: <code>list</code>, <code>search</code>, <code>validate</code>, <code>stats</code>, <code>docs</code></p> <pre><code>owl env list                            # List all plugins\nowl env list desktop                    # Plugin details\nowl env search keyboard                 # Find components\nowl env stats --namespaces              # Show namespaces\n</code></pre>"},{"location":"cli/#message-commands-owl-messages","title":"\ud83d\udccb Message Commands (<code>owl messages</code>)","text":"<p>Inspect and validate message type schemas used in MCAP files.</p> <p>Key commands: <code>list</code>, <code>show</code>, <code>validate</code></p> <pre><code>owl messages list                       # All message types\nowl messages show desktop/KeyboardEvent # Schema details\nowl messages validate                   # Validate definitions\n</code></pre>"},{"location":"cli/#video-commands-owl-video","title":"\ud83c\udfa5 Video Commands (<code>owl video</code>)","text":"<p>Process and analyze video files from OWA recordings.</p> <p>Key commands: <code>probe</code>, <code>vfr-to-cfr</code></p> <pre><code>owl video probe session.mkv            # Analyze video\nowl video vfr-to-cfr session.mkv       # Convert frame rate\n</code></pre>"},{"location":"cli/#complete-command-reference","title":"Complete Command Reference","text":""},{"location":"cli/#owl","title":"owl","text":"<p>owl - Open World agents cLi - Tools for managing OWA data and environments</p> <p>Usage:</p> <pre><code>owl [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--silent</code>, <code>-s</code> boolean Suppress non-essential output <code>False</code> <code>--no-update-check</code> boolean Skip version update check <code>False</code> <code>--install-completion</code> boolean Install completion for the current shell. None <code>--show-completion</code> boolean Show completion for the current shell, to copy it or customize the installation. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-env","title":"owl env","text":"<p>Environment plugin management commands</p> <p>Usage:</p> <pre><code>owl env [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-env-docs","title":"owl env docs","text":"<p>Manage plugin documentation - validate quality and show statistics.</p> <p>This command provides comprehensive documentation management for plugins, including validation for CI/CD integration and statistics for development.</p> <p>Usage:</p> <pre><code>owl env docs [OPTIONS] [PLUGIN_NAMESPACE]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--validate</code> boolean Validate plugin documentation <code>False</code> <code>--strict</code> boolean Enable strict mode (100% coverage + 100% quality) <code>False</code> <code>--min-coverage-pass</code> float Minimum coverage for PASS status <code>0.8</code> <code>--min-coverage-fail</code> float Minimum coverage to avoid FAIL status <code>0.6</code> <code>--min-quality-pass</code> float Minimum good quality ratio for PASS status <code>0.6</code> <code>--min-quality-fail</code> float Minimum good quality ratio to avoid FAIL status <code>0.0</code> <code>--output-format</code> text Output format: text or json <code>text</code> <code>--by-type</code> boolean Group statistics by component type <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-env-list","title":"owl env list","text":"<p>List environment plugins and components.</p> <p>Usage:</p> <pre><code>owl env list [OPTIONS] [NAMESPACES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--components</code>, <code>-c</code> boolean Show individual components <code>False</code> <code>--details</code>, <code>-d</code> boolean Show import paths and load status <code>False</code> <code>--table</code> boolean Display in table format <code>False</code> <code>--type</code>, <code>-t</code> text Filter by component type (callables/listeners/runnables) None <code>--search</code>, <code>-s</code> text Search components by name pattern None <code>--inspect</code> text Inspect specific component (show docstring/signature) None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-env-search","title":"owl env search","text":"<p>Search for components across all plugins using pattern matching.</p> <p>Usage:</p> <pre><code>owl env search [OPTIONS] PATTERN\n</code></pre> <p>Options:</p> Name Type Description Default <code>--type</code>, <code>-t</code> text Filter by component type None <code>--namespace</code>, <code>-n</code> text Filter by namespace None <code>--case-sensitive</code>, <code>-c</code> boolean Case sensitive search <code>False</code> <code>--details</code>, <code>-d</code> boolean Show detailed component information <code>False</code> <code>--table</code> boolean Display results in table format <code>False</code> <code>--limit</code>, <code>-l</code> integer Limit number of results <code>50</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-env-stats","title":"owl env stats","text":"<p>Show comprehensive statistics about the plugin ecosystem.</p> <p>Usage:</p> <pre><code>owl env stats [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--detailed</code>, <code>-d</code> boolean Show detailed statistics <code>False</code> <code>--by-namespace</code>, <code>-n</code> boolean Group statistics by namespace <code>False</code> <code>--by-type</code>, <code>-t</code> boolean Group statistics by component type <code>False</code> <code>--loaded-only</code>, <code>-l</code> boolean Show statistics for loaded components only <code>False</code> <code>--namespaces</code> boolean Show available namespaces <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-env-validate","title":"owl env validate","text":"<p>Validate a plugin specification from YAML file or entry point.</p> <p>This command can validate plugin specifications in two ways:</p> <ol> <li>From YAML files: owl env validate ./plugin.yaml</li> <li>From entry points: owl env validate owa.env.plugins.desktop:plugin_spec</li> </ol> <p>The command automatically detects the input type and validates accordingly.</p> <p>Usage:</p> <pre><code>owl env validate [OPTIONS] SPEC_INPUT\n</code></pre> <p>Options:</p> Name Type Description Default <code>--check-imports</code> / <code>--no-check-imports</code> boolean Validate that component import paths are accessible <code>True</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed validation information <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap","title":"owl mcap","text":"<p>MCAP file management commands</p> <p>Usage:</p> <pre><code>owl mcap [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-cat","title":"owl mcap cat","text":"<p>Print messages from an <code>.mcap</code> file in a readable format.</p> <p>Usage:</p> <pre><code>owl mcap cat [OPTIONS] MCAP_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--pretty</code> / <code>--no-pretty</code> boolean Pretty print JSON output <code>True</code> <code>--topics</code> text Topics to include (space-separated or multiple --topics flags) None <code>--exclude</code> text Topics to exclude (space-separated or multiple --exclude flags) None <code>--start-time</code> integer Start time in seconds None <code>--end-time</code> integer End time in seconds None <code>--n</code> integer Number of messages to print None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-convert","title":"owl mcap convert","text":"<p>Convert an <code>.mcap</code> file into an <code>.srt</code> subtitle file. After the conversion, you may play <code>.mkv</code> file and verify the sanity of data.</p> <p>Usage:</p> <pre><code>owl mcap convert [OPTIONS] MCAP_PATH [OUTPUT_SRT]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--topics</code> text Comma-separated list of topics to include in the subtitle file <code>['mouse/raw', 'mouse', 'keyboard']</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-info","title":"owl mcap info","text":"<p>Display information about the .mcap file(s). Shows detailed info for single file, summary for multiple files.</p> <p>Usage:</p> <pre><code>owl mcap info [OPTIONS] MCAP_PATHS...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--force-upgrade</code> boolean Force upgrade mcap CLI to latest version <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-migrate","title":"owl mcap migrate","text":"<p>MCAP migration commands with rollback and cleanup support.</p> <p>Usage:</p> <pre><code>owl mcap migrate [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-migrate-cleanup","title":"owl mcap migrate cleanup","text":"<p>Clean up MCAP backup files.</p> <p>This command finds backup files (.mcap.backup) using the specified patterns and removes them after confirmation. Use --dry-run to preview what would be deleted.</p> <p>Examples:     owl mcap migrate cleanup                    # Clean all backup files in current directory tree     owl mcap migrate cleanup \"*.mcap.backup\"   # Clean backup files in current directory only     owl mcap migrate cleanup /path/to/backups  # Clean backup files in specific directory     owl mcap migrate cleanup file.mcap         # Clean backup for specific MCAP file</p> <p>Usage:</p> <pre><code>owl mcap migrate cleanup [OPTIONS] [PATTERNS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--dry-run</code> boolean Show what would be deleted without actually deleting <code>False</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed cleanup information <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-migrate-rollback","title":"owl mcap migrate rollback","text":"<p>Rollback MCAP files from their backup files.</p> <p>This command finds backup files (.mcap.backup) corresponding to the specified MCAP files and restores the original files from the backups. The backup files are removed after successful rollback.</p> <p>Usage:</p> <pre><code>owl mcap migrate rollback [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed rollback information <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-migrate-run","title":"owl mcap migrate run","text":"<p>Migrate MCAP files to the highest reachable version with automatic version detection.</p> <p>Usage:</p> <pre><code>owl mcap migrate run [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--target</code>, <code>-t</code> text Target version (default: highest reachable) None <code>--dry-run</code> boolean Show what would be migrated without making changes <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed migration information <code>False</code> <code>--keep-backups</code> / <code>--no-backups</code> boolean Keep backup files after migration <code>True</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-record","title":"owl mcap record","text":"<p>Record screen, keyboard, mouse, and window events to an <code>.mcap</code> and <code>.mkv</code> file.</p> <p>Usage:</p> <pre><code>owl mcap record [OPTIONS] FILE_LOCATION\n</code></pre> <p>Options:</p> Name Type Description Default <code>--record-audio</code> / <code>--no-record-audio</code> boolean Whether to record audio <code>True</code> <code>--record-video</code> / <code>--no-record-video</code> boolean Whether to record video <code>True</code> <code>--record-timestamp</code> / <code>--no-record-timestamp</code> boolean Whether to record timestamp <code>True</code> <code>--show-cursor</code> / <code>--no-show-cursor</code> boolean Whether to show the cursor in the capture <code>True</code> <code>--fps</code> float The frame rate of the video. Default is 60 fps. <code>60.0</code> <code>--window-name</code> text The name of the window to capture, substring of window name is supported None <code>--monitor-idx</code> integer The index of the monitor to capture None <code>--width</code> integer The width of the video. If None, the width will be determined by the source. None <code>--height</code> integer The height of the video. If None, the height will be determined by the source. None <code>--additional-args</code> text Additional arguments to pass to the pipeline. For detail, see https://gstreamer.freedesktop.org/documentation/d3d11/d3d11screencapturesrc.html None <code>--start-after</code> float Delay recording start by this many seconds. Shows countdown during delay. None <code>--stop-after</code> float Automatically stop recording after this many seconds from start. None <code>--health-check-interval</code> float Interval in seconds for checking resource health. Set to 0 to disable. <code>5.0</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-rename-uri","title":"owl mcap rename-uri","text":"<p>Rename URIs in mediaref fields of screen topic events in MCAP files.</p> <p>This command processes MCAP files to set all URIs in the mediaref fields of screen topic events to the specified new URI. This is useful for updating file paths or URLs when media files have been moved or renamed.</p> <p>Examples:     owl mcap rename-uri recording.mcap --uri \"new_video.mkv\"     owl mcap rename-uri *.mcap --uri \"/new/path/video.mp4\"     owl mcap rename-uri data.mcap --uri \"http://new.com/video\" --dry-run</p> <p>Usage:</p> <pre><code>owl mcap rename-uri [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--uri</code> text URI to use for all screen topic events _required <code>--dry-run</code> boolean Show what would be changed without making modifications <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed processing information <code>False</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--keep-backups</code> / <code>--no-backups</code> boolean Keep backup files after processing <code>True</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-mcap-sanitize","title":"owl mcap sanitize","text":"<p>Sanitize MCAP files by keeping only events when a specific window is active.</p> <p>This command filters MCAP files to retain only the events that occurred when the specified window was active, effectively removing data from other applications for privacy or focus purposes.</p> <p>Safety feature: By default, the operation will be blocked if more than 20% of messages would be removed, preventing accidental over-sanitization. Use --max-removal-ratio to adjust this threshold.</p> <p>Examples:     owl mcap sanitize recording.mcap --keep-window \"Notepad\"     owl mcap sanitize *.mcap --keep-window \"Work App\" --exact     owl mcap sanitize data.mcap --keep-window \"Browser\" --dry-run     owl mcap sanitize data.mcap --keep-window \"App\" --max-removal-ratio 0.95     owl mcap sanitize recording.mcap --auto-detect-window</p> <p>Usage:</p> <pre><code>owl mcap sanitize [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--keep-window</code> text Window name to keep events for None <code>--auto-detect-window</code> boolean Auto-detect the most frequent window to keep <code>False</code> <code>--exact</code> / <code>--substring</code> boolean Use exact window name matching (default: substring) <code>False</code> <code>--dry-run</code> boolean Show what would be changed without making modifications <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed sanitization information <code>False</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--keep-backups</code> / <code>--no-backups</code> boolean Keep backup files after sanitization <code>True</code> <code>--max-removal-ratio</code> float range (between <code>0.0</code> and <code>1.0</code>) Maximum ratio of messages that can be removed (0.0-1.0). Safety feature to prevent accidental over-sanitization. <code>0.2</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-messages","title":"owl messages","text":"<p>Message registry management commands</p> <p>Usage:</p> <pre><code>owl messages [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-messages-list","title":"owl messages list","text":"<p>List and search message types</p> <p>Usage:</p> <pre><code>owl messages list [OPTIONS] [MESSAGE_TYPES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--domain</code>, <code>-d</code> text Filter by domain (e.g., 'desktop') None <code>--search</code>, <code>-s</code> text Search message types by pattern None <code>--output-format</code> text Output format: table, json, yaml <code>table</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed information <code>False</code> <code>--case-sensitive</code>, <code>-c</code> boolean Case sensitive search <code>False</code> <code>--limit</code>, <code>-l</code> integer Limit number of results <code>50</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-messages-show","title":"owl messages show","text":"<p>Show detailed information about a specific message type</p> <p>Usage:</p> <pre><code>owl messages show [OPTIONS] MESSAGE_TYPE\n</code></pre> <p>Options:</p> Name Type Description Default <code>--output-format</code> text Output format: rich, json, schema <code>rich</code> <code>--example</code>, <code>-e</code> boolean Show usage example <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#owl-messages-validate","title":"owl messages validate","text":"<p>Validate message registry and definitions</p> <p>Usage:</p> <pre><code>owl messages validate [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--verbose</code>, <code>-v</code> boolean Show detailed validation results <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#common-workflows","title":"Common Workflows","text":"<pre><code># Record and analyze data\nocap my-session\nowl mcap info my-session.mcap\nowl mcap convert my-session.mcap\n\n# Environment management\nowl env list\nowl env validate desktop\n\n# Data processing\nowl mcap info *.mcap\nowl video probe session.mkv\n</code></pre>"},{"location":"cli/#getting-help","title":"Getting Help","text":"<pre><code>owl --help                              # General help\nowl mcap --help                         # Command group help\nowl mcap info --help                    # Specific command help\n</code></pre>"},{"location":"cli/#related-documentation","title":"Related Documentation","text":"<ul> <li>Installation Guide - Installing OWA and CLI tools</li> <li>Recording Data - Creating MCAP files with ocap</li> <li>Exploring Data - Data analysis workflows</li> <li>Environment Guide - Understanding environment plugins</li> <li>Custom Messages - Creating custom message types</li> </ul>"},{"location":"cli/env/","title":"Environment Commands (<code>owl env</code>)","text":"<p>Tools for managing OWA environment plugins - modular components that capture desktop data.</p>"},{"location":"cli/env/#command-reference","title":"Command Reference","text":""},{"location":"cli/env/#owl-env","title":"owl env","text":"<p>Environment plugin management commands.</p> <p>Usage:</p> <pre><code>owl env [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--install-completion</code> boolean Install completion for the current shell. None <code>--show-completion</code> boolean Show completion for the current shell, to copy it or customize the installation. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/env/#owl-env-docs","title":"owl env docs","text":"<p>Manage plugin documentation - validate quality and show statistics.</p> <p>This command provides comprehensive documentation management for plugins, including validation for CI/CD integration and statistics for development.</p> <p>Usage:</p> <pre><code>owl env docs [OPTIONS] [PLUGIN_NAMESPACE]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--validate</code> boolean Validate plugin documentation <code>False</code> <code>--strict</code> boolean Enable strict mode (100% coverage + 100% quality) <code>False</code> <code>--min-coverage-pass</code> float Minimum coverage for PASS status <code>0.8</code> <code>--min-coverage-fail</code> float Minimum coverage to avoid FAIL status <code>0.6</code> <code>--min-quality-pass</code> float Minimum good quality ratio for PASS status <code>0.6</code> <code>--min-quality-fail</code> float Minimum good quality ratio to avoid FAIL status <code>0.0</code> <code>--output-format</code> text Output format: text or json <code>text</code> <code>--by-type</code> boolean Group statistics by component type <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/env/#owl-env-list","title":"owl env list","text":"<p>List environment plugins and components.</p> <p>Usage:</p> <pre><code>owl env list [OPTIONS] [NAMESPACES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--components</code>, <code>-c</code> boolean Show individual components <code>False</code> <code>--details</code>, <code>-d</code> boolean Show import paths and load status <code>False</code> <code>--table</code> boolean Display in table format <code>False</code> <code>--type</code>, <code>-t</code> text Filter by component type (callables/listeners/runnables) None <code>--search</code>, <code>-s</code> text Search components by name pattern None <code>--inspect</code> text Inspect specific component (show docstring/signature) None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/env/#owl-env-search","title":"owl env search","text":"<p>Search for components across all plugins using pattern matching.</p> <p>Usage:</p> <pre><code>owl env search [OPTIONS] PATTERN\n</code></pre> <p>Options:</p> Name Type Description Default <code>--type</code>, <code>-t</code> text Filter by component type None <code>--namespace</code>, <code>-n</code> text Filter by namespace None <code>--case-sensitive</code>, <code>-c</code> boolean Case sensitive search <code>False</code> <code>--details</code>, <code>-d</code> boolean Show detailed component information <code>False</code> <code>--table</code> boolean Display results in table format <code>False</code> <code>--limit</code>, <code>-l</code> integer Limit number of results <code>50</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/env/#owl-env-stats","title":"owl env stats","text":"<p>Show comprehensive statistics about the plugin ecosystem.</p> <p>Usage:</p> <pre><code>owl env stats [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--detailed</code>, <code>-d</code> boolean Show detailed statistics <code>False</code> <code>--by-namespace</code>, <code>-n</code> boolean Group statistics by namespace <code>False</code> <code>--by-type</code>, <code>-t</code> boolean Group statistics by component type <code>False</code> <code>--loaded-only</code>, <code>-l</code> boolean Show statistics for loaded components only <code>False</code> <code>--namespaces</code> boolean Show available namespaces <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/env/#owl-env-validate","title":"owl env validate","text":"<p>Validate a plugin specification from YAML file or entry point.</p> <p>This command can validate plugin specifications in two ways:</p> <ol> <li>From YAML files: owl env validate ./plugin.yaml</li> <li>From entry points: owl env validate owa.env.plugins.desktop:plugin_spec</li> </ol> <p>The command automatically detects the input type and validates accordingly.</p> <p>Usage:</p> <pre><code>owl env validate [OPTIONS] SPEC_INPUT\n</code></pre> <p>Options:</p> Name Type Description Default <code>--check-imports</code> / <code>--no-check-imports</code> boolean Validate that component import paths are accessible <code>True</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed validation information <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/env/#related-documentation","title":"Related Documentation","text":"<ul> <li>Environment Guide - Environment system overview</li> <li>Custom EnvPlugins - Creating custom plugins</li> <li>CLI Tools - Complete CLI overview</li> </ul>"},{"location":"cli/mcap/","title":"MCAP Commands (<code>owl mcap</code>)","text":"<p>Tools for working with MCAP files - the core data format for multimodal desktop recordings.</p>"},{"location":"cli/mcap/#command-reference","title":"Command Reference","text":""},{"location":"cli/mcap/#owl-mcap","title":"owl mcap","text":"<p>MCAP file management commands.</p> <p>Usage:</p> <pre><code>owl mcap [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--install-completion</code> boolean Install completion for the current shell. None <code>--show-completion</code> boolean Show completion for the current shell, to copy it or customize the installation. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-cat","title":"owl mcap cat","text":"<p>Print messages from an <code>.mcap</code> file in a readable format.</p> <p>Usage:</p> <pre><code>owl mcap cat [OPTIONS] MCAP_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--pretty</code> / <code>--no-pretty</code> boolean Pretty print JSON output <code>True</code> <code>--topics</code> text Topics to include (space-separated or multiple --topics flags) None <code>--exclude</code> text Topics to exclude (space-separated or multiple --exclude flags) None <code>--start-time</code> integer Start time in seconds None <code>--end-time</code> integer End time in seconds None <code>--n</code> integer Number of messages to print None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-convert","title":"owl mcap convert","text":"<p>Convert an <code>.mcap</code> file into an <code>.srt</code> subtitle file. After the conversion, you may play <code>.mkv</code> file and verify the sanity of data.</p> <p>Usage:</p> <pre><code>owl mcap convert [OPTIONS] MCAP_PATH [OUTPUT_SRT]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--topics</code> text Comma-separated list of topics to include in the subtitle file <code>['mouse/raw', 'mouse', 'keyboard']</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-info","title":"owl mcap info","text":"<p>Display information about the .mcap file(s). Shows detailed info for single file, summary for multiple files.</p> <p>Usage:</p> <pre><code>owl mcap info [OPTIONS] MCAP_PATHS...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--force-upgrade</code> boolean Force upgrade mcap CLI to latest version <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-migrate","title":"owl mcap migrate","text":"<p>MCAP migration commands with rollback and cleanup support.</p> <p>Usage:</p> <pre><code>owl mcap migrate [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-migrate-cleanup","title":"owl mcap migrate cleanup","text":"<p>Clean up MCAP backup files.</p> <p>This command finds backup files (.mcap.backup) using the specified patterns and removes them after confirmation. Use --dry-run to preview what would be deleted.</p> <p>Examples:     owl mcap migrate cleanup                    # Clean all backup files in current directory tree     owl mcap migrate cleanup \"*.mcap.backup\"   # Clean backup files in current directory only     owl mcap migrate cleanup /path/to/backups  # Clean backup files in specific directory     owl mcap migrate cleanup file.mcap         # Clean backup for specific MCAP file</p> <p>Usage:</p> <pre><code>owl mcap migrate cleanup [OPTIONS] [PATTERNS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--dry-run</code> boolean Show what would be deleted without actually deleting <code>False</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed cleanup information <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-migrate-rollback","title":"owl mcap migrate rollback","text":"<p>Rollback MCAP files from their backup files.</p> <p>This command finds backup files (.mcap.backup) corresponding to the specified MCAP files and restores the original files from the backups. The backup files are removed after successful rollback.</p> <p>Usage:</p> <pre><code>owl mcap migrate rollback [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed rollback information <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-migrate-run","title":"owl mcap migrate run","text":"<p>Migrate MCAP files to the highest reachable version with automatic version detection.</p> <p>Usage:</p> <pre><code>owl mcap migrate run [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--target</code>, <code>-t</code> text Target version (default: highest reachable) None <code>--dry-run</code> boolean Show what would be migrated without making changes <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed migration information <code>False</code> <code>--keep-backups</code> / <code>--no-backups</code> boolean Keep backup files after migration <code>True</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-record","title":"owl mcap record","text":"<p>Record screen, keyboard, mouse, and window events to an <code>.mcap</code> and <code>.mkv</code> file.</p> <p>Usage:</p> <pre><code>owl mcap record [OPTIONS] FILE_LOCATION\n</code></pre> <p>Options:</p> Name Type Description Default <code>--record-audio</code> / <code>--no-record-audio</code> boolean Whether to record audio <code>True</code> <code>--record-video</code> / <code>--no-record-video</code> boolean Whether to record video <code>True</code> <code>--record-timestamp</code> / <code>--no-record-timestamp</code> boolean Whether to record timestamp <code>True</code> <code>--show-cursor</code> / <code>--no-show-cursor</code> boolean Whether to show the cursor in the capture <code>True</code> <code>--fps</code> float The frame rate of the video. Default is 60 fps. <code>60.0</code> <code>--window-name</code> text The name of the window to capture, substring of window name is supported None <code>--monitor-idx</code> integer The index of the monitor to capture None <code>--width</code> integer The width of the video. If None, the width will be determined by the source. None <code>--height</code> integer The height of the video. If None, the height will be determined by the source. None <code>--additional-args</code> text Additional arguments to pass to the pipeline. For detail, see https://gstreamer.freedesktop.org/documentation/d3d11/d3d11screencapturesrc.html None <code>--start-after</code> float Delay recording start by this many seconds. Shows countdown during delay. None <code>--stop-after</code> float Automatically stop recording after this many seconds from start. None <code>--health-check-interval</code> float Interval in seconds for checking resource health. Set to 0 to disable. <code>5.0</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-rename-uri","title":"owl mcap rename-uri","text":"<p>Rename URIs in mediaref fields of screen topic events in MCAP files.</p> <p>This command processes MCAP files to set all URIs in the mediaref fields of screen topic events to the specified new URI. This is useful for updating file paths or URLs when media files have been moved or renamed.</p> <p>Examples:     owl mcap rename-uri recording.mcap --uri \"new_video.mkv\"     owl mcap rename-uri *.mcap --uri \"/new/path/video.mp4\"     owl mcap rename-uri data.mcap --uri \"http://new.com/video\" --dry-run</p> <p>Usage:</p> <pre><code>owl mcap rename-uri [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--uri</code> text URI to use for all screen topic events _required <code>--dry-run</code> boolean Show what would be changed without making modifications <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed processing information <code>False</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--keep-backups</code> / <code>--no-backups</code> boolean Keep backup files after processing <code>True</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#owl-mcap-sanitize","title":"owl mcap sanitize","text":"<p>Sanitize MCAP files by keeping only events when a specific window is active.</p> <p>This command filters MCAP files to retain only the events that occurred when the specified window was active, effectively removing data from other applications for privacy or focus purposes.</p> <p>Safety feature: By default, the operation will be blocked if more than 20% of messages would be removed, preventing accidental over-sanitization. Use --max-removal-ratio to adjust this threshold.</p> <p>Examples:     owl mcap sanitize recording.mcap --keep-window \"Notepad\"     owl mcap sanitize *.mcap --keep-window \"Work App\" --exact     owl mcap sanitize data.mcap --keep-window \"Browser\" --dry-run     owl mcap sanitize data.mcap --keep-window \"App\" --max-removal-ratio 0.95     owl mcap sanitize recording.mcap --auto-detect-window</p> <p>Usage:</p> <pre><code>owl mcap sanitize [OPTIONS] FILES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--keep-window</code> text Window name to keep events for None <code>--auto-detect-window</code> boolean Auto-detect the most frequent window to keep <code>False</code> <code>--exact</code> / <code>--substring</code> boolean Use exact window name matching (default: substring) <code>False</code> <code>--dry-run</code> boolean Show what would be changed without making modifications <code>False</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed sanitization information <code>False</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--keep-backups</code> / <code>--no-backups</code> boolean Keep backup files after sanitization <code>True</code> <code>--max-removal-ratio</code> float range (between <code>0.0</code> and <code>1.0</code>) Maximum ratio of messages that can be removed (0.0-1.0). Safety feature to prevent accidental over-sanitization. <code>0.2</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/mcap/#related-documentation","title":"Related Documentation","text":"<ul> <li>OWAMcap Format Guide - Format specification</li> <li>Exploring Data - Analysis workflows</li> <li>CLI Tools - Complete CLI overview</li> </ul>"},{"location":"cli/messages/","title":"Message Commands (<code>owl messages</code>)","text":"<p>Tools for managing OWA message types - structured data schemas used in MCAP files.</p>"},{"location":"cli/messages/#command-reference","title":"Command Reference","text":""},{"location":"cli/messages/#owl-messages","title":"owl messages","text":"<p>Message registry management commands</p> <p>Usage:</p> <pre><code>owl messages [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--install-completion</code> boolean Install completion for the current shell. None <code>--show-completion</code> boolean Show completion for the current shell, to copy it or customize the installation. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/messages/#owl-messages-list","title":"owl messages list","text":"<p>List and search message types</p> <p>Usage:</p> <pre><code>owl messages list [OPTIONS] [MESSAGE_TYPES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--domain</code>, <code>-d</code> text Filter by domain (e.g., 'desktop') None <code>--search</code>, <code>-s</code> text Search message types by pattern None <code>--output-format</code> text Output format: table, json, yaml <code>table</code> <code>--verbose</code>, <code>-v</code> boolean Show detailed information <code>False</code> <code>--case-sensitive</code>, <code>-c</code> boolean Case sensitive search <code>False</code> <code>--limit</code>, <code>-l</code> integer Limit number of results <code>50</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/messages/#owl-messages-show","title":"owl messages show","text":"<p>Show detailed information about a specific message type</p> <p>Usage:</p> <pre><code>owl messages show [OPTIONS] MESSAGE_TYPE\n</code></pre> <p>Options:</p> Name Type Description Default <code>--output-format</code> text Output format: rich, json, schema <code>rich</code> <code>--example</code>, <code>-e</code> boolean Show usage example <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/messages/#owl-messages-validate","title":"owl messages validate","text":"<p>Validate message registry and definitions</p> <p>Usage:</p> <pre><code>owl messages validate [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--verbose</code>, <code>-v</code> boolean Show detailed validation results <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/messages/#related-documentation","title":"Related Documentation","text":"<ul> <li>Custom Message Types - Creating custom messages</li> <li>OWAMcap Format Guide - Message format specifications</li> <li>CLI Tools - Complete CLI overview</li> </ul>"},{"location":"cli/video/","title":"Video Commands (<code>owl video</code>)","text":"<p>Tools for processing and analyzing MKV video files from OWA recordings.</p> <p>FFmpeg Required</p> <p>Video commands require FFmpeg to be installed and available in your system PATH.</p>"},{"location":"cli/video/#command-reference","title":"Command Reference","text":""},{"location":"cli/video/#owl-video","title":"owl video","text":"<p>Video processing commands.</p> <p>Usage:</p> <pre><code>owl video [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--install-completion</code> boolean Install completion for the current shell. None <code>--show-completion</code> boolean Show completion for the current shell, to copy it or customize the installation. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/video/#owl-video-probe","title":"owl video probe","text":"<p>Analyze frame types and patterns in a video file</p> <p>Usage:</p> <pre><code>owl video probe [OPTIONS] VIDEO_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--detailed</code>, <code>-d</code> boolean Show detailed frame information <code>False</code> <code>--frames</code>, <code>-f</code> boolean Show intervals in frames instead of seconds <code>False</code> <code>--max-frames</code>, <code>-m</code> integer Maximum frames to show in pattern visualization <code>200</code> <code>--max-gops</code>, <code>-g</code> integer Maximum GOPs to analyze in detail <code>3</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/video/#owl-video-transcode","title":"owl video transcode","text":"<p>Transcode video files with professional encoding settings.</p> <p>Options:     fps: Target frame rate (forces constant frame rate output)     width/height: Target resolution in pixels (maintains aspect ratio if only one specified)     codec: Video codec (libx264 for H.264, libx265 for H.265)     crf: Quality level (0-51, lower=better quality, 18=high, 23=default, 28=smaller file)     keyint: Keyframe interval/GOP size (lower=better seeking, higher=better compression)     min-keyint: Minimum keyframe interval (optional, for fine control)     scenecut: Scene change detection (0=disable for consistent GOP [default], 40=adaptive)     dry-run: Show command without executing</p> <p>Examples:     # Basic transcoding     owa video transcode input.mkv output.mkv</p> <pre><code># Custom resolution and frame rate\nowa video transcode input.mkv output.mkv --fps 30 --width 1920 --height 1080\n\n# High quality encoding for archival\nowa video transcode input.mkv output.mkv --crf 18 --keyint 60 --scenecut 0\n\n# Streaming-optimized (consistent keyframes)\nowa video transcode input.mkv output.mkv --keyint 30 --scenecut 0\n\n# Preview command without execution\nowa video transcode input.mkv output.mkv --dry-run\n</code></pre> <p>Usage:</p> <pre><code>owl video transcode [OPTIONS] INPUT_PATH OUTPUT_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--fps</code>, <code>-f</code> float Target FPS None <code>--width</code>, <code>-w</code> integer Target width None <code>--height</code>, <code>-h</code> integer Target height None <code>--codec</code>, <code>-c</code> text Video codec <code>libx264</code> <code>--crf</code> integer Quality (0-51, lower=better) None <code>--keyint</code>, <code>-k</code> integer Keyframe interval <code>30</code> <code>--min-keyint</code> integer Min keyframe interval None <code>--scenecut</code> integer Scene cut threshold (0=disable, default: 0) <code>0</code> <code>--dry-run</code> boolean Show command only <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/video/#owl-video-vfr-to-cfr","title":"owl video vfr-to-cfr","text":"<p>Convert MKV files with Variable Frame Rate (VFR) to Constant Frame Rate (CFR).</p> <p>Usage:</p> <pre><code>owl video vfr-to-cfr [OPTIONS] PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--workers</code>, <code>-w</code> integer Maximum number of parallel conversions None <code>--dry-run</code> boolean Show what would be done without actually converting files <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/video/#related-documentation","title":"Related Documentation","text":"<ul> <li>Recording Data - How OWA generates video files</li> <li>CLI Tools - Complete CLI overview</li> </ul>"},{"location":"data/","title":"Data in OWA: Complete Desktop Agent Data Pipeline","text":"<p>Desktop AI needs high-quality, synchronized multimodal data: screen captures, mouse/keyboard events, and window context. OWA provides the complete pipeline from recording to training.</p>"},{"location":"data/#quick-start-record-train-in-3-steps","title":"\ud83d\ude80 Quick Start: Record \u2192 Train in 3 Steps","text":"<pre><code># 1. Record desktop interaction\n$ ocap my-session.mcap\n\n# 2. Process to training format\n$ python scripts/01_raw_events_to_event_dataset.py --train-dir ./\n\n# 3. Train your model\n$ python train.py --dataset ./event-dataset\n</code></pre> <p>\ud83d\udcd6 Detailed Guide: Complete Quick Start Tutorial - Step-by-step walkthrough with examples and troubleshooting</p>"},{"location":"data/#the-owa-data-ecosystem","title":"The OWA Data Ecosystem","text":""},{"location":"data/#getting-started","title":"\ud83c\udfaf Getting Started","text":"<p>New to OWA data? Start here:</p> <ul> <li>Why OWAMcap? - Understand the problem and solution</li> <li>Recording Data - Capture desktop interactions with <code>ocap</code></li> <li>Exploring Data - View and analyze your recordings</li> </ul>"},{"location":"data/#technical-reference","title":"\ud83d\udcda Technical Reference","text":"<p>Deep dive into the format and pipeline:</p> <ul> <li>OWAMcap Format Guide - Complete technical specification</li> <li>Data Pipeline - Transform recordings to training-ready datasets</li> </ul>"},{"location":"data/#tools-ecosystem","title":"\ud83d\udee0\ufe0f Tools &amp; Ecosystem","text":"<ul> <li>Data Viewer - Web-based visualization tool</li> <li>Comparison with LeRobot - Technical comparison with alternatives</li> </ul>"},{"location":"data/#community-datasets","title":"\ud83e\udd17 Community Datasets","text":"<p>Browse Available Datasets: \ud83e\udd17 datasets?other=OWA</p> <ul> <li>Growing Collection: Hundreds of community-contributed datasets</li> <li>Standardized Format: All use OWAMcap for seamless integration</li> <li>Interactive Preview: Hugging Face Spaces Visualizer</li> <li>Easy Sharing: Upload recordings directly with one command</li> </ul> <p>\ud83d\ude80 Impact: OWA has democratized desktop agent data, growing from zero to hundreds of public datasets in the unified OWAMcap format.</p>"},{"location":"data/examples/conversions/","title":"Data Conversion Examples","text":"<p>Open World Agents provides conversion scripts to transform existing gaming and interaction datasets into the standardized OWAMcap format. This enables researchers to leverage existing datasets for training multimodal desktop agents.</p> <p>What are Data Conversions?</p> <p>Data conversions transform existing gaming datasets (VPT, CS:GO, etc.) into the standardized OWAMcap format, enabling unified training across different games and interaction types.</p>"},{"location":"data/examples/conversions/#why-convert-to-owamcap","title":"Why Convert to OWAMcap?","text":"<p>OWAMcap (Open World Agents MCAP) is a standardized format with these key features:</p> <ul> <li> Universal Standard: Unlike fragmented formats, enables seamless dataset combination for large-scale foundation models (OWAMcap)</li> <li> High-Performance Multimodal Storage: Lightweight MCAP container with nanosecond precision for synchronized data streams (MCAP)</li> <li> Flexible MediaRef: Smart references to both external and embedded media (file paths, URLs, data URIs, video frames) with lazy loading - keeps metadata files small while supporting rich media (OWAMcap) \u2192 Learn more</li> <li> Training Pipeline Ready: Native HuggingFace integration, seamless dataset loading, and direct compatibility with ML frameworks (Ecosystem) \u2192 Browse datasets | Data pipeline</li> </ul>"},{"location":"data/examples/conversions/#available-conversions","title":"Available Conversions","text":"VPT (Minecraft)CS:GO (FPS)"},{"location":"data/examples/conversions/#video-pretraining-vpt-owamcap","title":"Video PreTraining (VPT) \u2192 OWAMcap","text":"<p>Convert OpenAI's Minecraft VPT dataset for navigation and basic interaction training.</p> <p> View VPT Conversion Guide</p>"},{"location":"data/examples/conversions/#counter-strike-deathmatch-owamcap","title":"Counter-Strike Deathmatch \u2192 OWAMcap","text":"<p>Convert expert CS:GO gameplay data for competitive FPS agent training.</p> <p> View CS:GO Conversion Guide</p>"},{"location":"data/examples/conversions/#getting-started","title":"Getting Started","text":"<p>For detailed installation, usage instructions, and troubleshooting, see the individual conversion guides above.</p> <p> Browse All Conversion Scripts</p>"},{"location":"data/getting-started/exploring-data/","title":"Exploring OWAMcap Data","text":"<p>Practical guide to viewing and analyzing OWAMcap recordings using different tools and workflows.</p>"},{"location":"data/getting-started/exploring-data/#sample-dataset","title":"\ud83d\udcc1 Sample Dataset","text":"<p>Download our example dataset to follow along:</p> <ul> <li><code>example.mcap</code> [Download] - 22 KiB metadata file</li> <li><code>example.mkv</code> [Download] - Video recording</li> </ul> Preview: example.mkv <p> </p>"},{"location":"data/getting-started/exploring-data/#exploration-workflows","title":"\ud83d\udd0d Exploration Workflows","text":"<p>Choose the approach that fits your use case:</p>"},{"location":"data/getting-started/exploring-data/#interactive-web-viewer-recommended","title":"\ud83c\udf10 Interactive Web Viewer (Recommended)","text":"<p>Best for: Visual exploration, beginners, sharing with others</p> <p>OWA Dataset Visualizer provides synchronized playback of video and events.</p> <p>Quick Start:</p> <ol> <li>Visit the visualizer link</li> <li>Upload your <code>.mcap</code> file or enter a HuggingFace dataset ID</li> <li>Use timeline controls to explore synchronized data</li> </ol> <p>Limitations: 100MB file limit for public hosting \u2192 Self-hosting guide</p>"},{"location":"data/getting-started/exploring-data/#command-line-analysis","title":"\ud83d\udcbb Command Line Analysis","text":"<p>Best for: Quick inspection, scripting, CI/CD pipelines</p> <p>The <code>owl</code> CLI provides fast analysis without loading video data:</p> <p>Common Commands:</p> <pre><code># Get file overview\nowl mcap info example.mcap\n\n# List first 10 messages\nowl mcap cat example.mcap --n 10\n\n# Filter by topic\nowl mcap cat example.mcap --topics screen --topics mouse\n\n# Convert to subtitle format\nowl mcap convert example.mcap  # Creates example.srt\n</code></pre> <p>Example Output: <pre><code>library:   mcap-owa-support 0.5.1\nmessages:  864 (10.36s duration)\nchannels:  screen(590), mouse(209), keyboard(32), window(11)\n</code></pre></p>"},{"location":"data/getting-started/exploring-data/#video-player-with-subtitles","title":"\ud83c\udfac Video Player with Subtitles","text":"<p>Best for: Visual timeline analysis, understanding user behavior</p> <ol> <li> <p>Generate subtitle file:    <pre><code>owl mcap convert example.mcap  # Creates example.srt\n</code></pre></p> </li> <li> <p>Open in video player: Use VLC or any player that supports subtitles</p> </li> <li>Load <code>example.mkv</code></li> <li>Load <code>example.srt</code> as subtitles</li> <li>See events overlaid on video timeline</li> </ol> <p>Download example: <code>example.srt</code> [Download]</p>"},{"location":"data/getting-started/exploring-data/#python-api","title":"\ud83d\udc0d Python API","text":"<p>Best for: Custom analysis, data processing, integration</p> <p>For programmatic access, see the OWAMcap Format Guide which covers:</p> <ul> <li>Reading and writing MCAP files</li> <li>Working with media references</li> <li>Advanced filtering and processing</li> <li>Custom message types</li> </ul>"},{"location":"data/getting-started/exploring-data/#analysis-workflows","title":"\ud83d\udd27 Analysis Workflows","text":""},{"location":"data/getting-started/exploring-data/#quick-dataset-overview","title":"\ud83d\udcca Quick Dataset Overview","text":"<pre><code># Get basic stats\nowl mcap info *.mcap\n\n# Compare multiple files\nfor file in *.mcap; do\n  echo \"=== $file ===\"\n  owl mcap info \"$file\" | grep -E \"(messages|duration|channels)\"\ndone\n</code></pre>"},{"location":"data/getting-started/exploring-data/#event-timeline-analysis","title":"\u23f1\ufe0f Event Timeline Analysis","text":"<pre><code># Extract events to subtitle format for timeline view\nowl mcap convert session.mcap\n\n# View in VLC with subtitles to see event timing\nvlc session.mkv --sub-file session.srt\n</code></pre>"},{"location":"data/getting-started/exploring-data/#topic-specific-analysis","title":"\ud83c\udfaf Topic-Specific Analysis","text":"<pre><code># Focus on user interactions\nowl mcap cat session.mcap --topics mouse --topics keyboard\n\n# Screen capture analysis\nowl mcap cat session.mcap --topics screen --n 100\n</code></pre>"},{"location":"data/getting-started/exploring-data/#creating-and-modifying-files","title":"\ud83d\udee0\ufe0f Creating and Modifying Files","text":"<p>For programmatic creation and editing of OWAMcap files, see the comprehensive guide in OWAMcap Format Guide, which covers:</p> <ul> <li>Writing MCAP files with Python API</li> <li>Custom message types and registration</li> <li>Media handling strategies</li> <li>Advanced usage patterns</li> </ul>"},{"location":"data/getting-started/exploring-data/#next-steps","title":"\ud83d\udcca Next Steps","text":"<ul> <li>Data Pipeline - Transform recordings for ML training</li> <li>Format Guide - Complete technical reference</li> <li>Viewer Setup - Self-host for large datasets</li> </ul>"},{"location":"data/getting-started/recording-data/","title":"ocap","text":"<p>High-performance desktop recorder for Windows. Captures screen, audio, keyboard, mouse, and window events.</p>"},{"location":"data/getting-started/recording-data/#what-is-ocap","title":"What is ocap?","text":"<p>ocap (Omnimodal CAPture) captures all essential desktop signals in synchronized format. Records screen video, audio, keyboard/mouse input, and window events. Built for the open-world-agents project but works for any desktop recording needs.</p> <p>TL;DR: Complete, high-performance desktop recording tool for Windows. Captures everything in one command.</p>"},{"location":"data/getting-started/recording-data/#key-features","title":"Key Features","text":"<ul> <li>Complete desktop recording: Video, audio, keyboard/mouse events, window events</li> <li>High performance: Hardware-accelerated with Windows APIs and GStreamer</li> <li>Efficient encoding: H265/HEVC for high quality and small file size</li> <li>Simple operation: <code>ocap FILE_LOCATION</code> (stop with Ctrl+C)</li> <li>Clean architecture: Core logic in single 320-line Python file</li> <li>Modern formats: MKV with embedded timestamps, MCAP format for events</li> </ul>"},{"location":"data/getting-started/recording-data/#system-requirements","title":"System Requirements","text":"<p>Based on OBS Studio recommended specs + NVIDIA GPU requirements:</p> Component Specification OS Windows 11 (64-bit) Processor Intel i7 8700K / AMD Ryzen 1600X Memory 8 GB RAM Graphics NVIDIA GeForce 10 Series or newer \u26a0\ufe0f DirectX Version 11 Storage 600 MB + ~100MB per minute recording <p>\u26a0\ufe0f NVIDIA GPU Required: Currently only supports NVIDIA GPUs for hardware acceleration. AMD/Intel GPU support possible through GStreamer framework - contributions welcome!</p> <p>\ud83d\udda5\ufe0f OS Support: Currently only supports Windows. However, support for other operating systems (Linux, macOS) can be relatively easily extended due to the presence of GStreamer. Simply using different GStreamer pipelines can enable capture on other platforms - contributions welcome!</p>"},{"location":"data/getting-started/recording-data/#installation-usage","title":"Installation &amp; Usage","text":""},{"location":"data/getting-started/recording-data/#option-1-download-release","title":"Option 1: Download Release","text":"<ol> <li>Download <code>ocap.zip</code> from releases</li> <li>Unzip and run:<ul> <li>Double-click <code>run.bat</code> (opens terminal with virtual environment)</li> <li>Or in CLI: <code>run.bat --help</code></li> </ul> </li> </ol>"},{"location":"data/getting-started/recording-data/#option-2-package-install","title":"Option 2: Package Install","text":"<p>All OWA packages are available on PyPI:</p> <pre><code># Install GStreamer dependencies first (for video recording)\n$ conda install open-world-agents::gstreamer-bundle\n\n# Install ocap\n$ pip install ocap\n</code></pre>"},{"location":"data/getting-started/recording-data/#basic-usage","title":"Basic Usage","text":"<pre><code># Start recording (stop with Ctrl+C)\n$ ocap my-recording\n\n# Show all options\n$ ocap --help\n\n# Advanced options\n$ ocap FILENAME --window-name \"App\"   # Record specific window\n$ ocap FILENAME --monitor-idx 1       # Record specific monitor\n$ ocap FILENAME --fps 60              # Set framerate\n$ ocap FILENAME --no-record-audio     # Disable audio\n</code></pre>"},{"location":"data/getting-started/recording-data/#output-files","title":"Output Files","text":"<ul> <li><code>.mcap</code> \u2014 Event log (keyboard, mouse, windows)</li> <li><code>.mkv</code>  \u2014 Video/audio with embedded timestamps</li> </ul> <p>Your recording files will be ready immediately!</p>"},{"location":"data/getting-started/recording-data/#feature-comparison","title":"Feature Comparison","text":"Feature ocap OBS wcap pillow/mss Advanced data formats (MCAP/MKV) \u2705 Yes \u274c No \u274c No \u274c No Timestamp aligned logging \u2705 Yes \u274c No \u274c No \u274c No Customizable event definition &amp; Listener \u2705 Yes \u274c No \u274c No \u274c No Single python file \u2705 Yes \u274c No \u274c No \u274c No Audio + Window + Keyboard + Mouse \u2705 Yes \u26a0\ufe0f Partial \u274c No \u274c No Hardware-accelerated encoder \u2705 Yes \u2705 Yes \u2705 Yes \u274c No Supports latest Windows APIs \u2705 Yes \u2705 Yes \u2705 Yes \u274c No (legacy APIs only) Optional mouse cursor capture \u2705 Yes \u2705 Yes \u2705 Yes \u274c No"},{"location":"data/getting-started/recording-data/#technical-architecture","title":"Technical Architecture","text":"<p>Built on GStreamer with clean, maintainable design:</p> <pre><code>flowchart TD\n    %% Input Sources\n    A[owa.env.desktop] --&gt; B[Keyboard Events]\n    A --&gt; C[Mouse Events] \n    A --&gt; D[Window Events]\n    E[owa.env.gst] --&gt; F[Screen Capture]\n    E --&gt; G[Audio Capture]\n\n    %% Core Processing\n    B --&gt; H[Event Queue]\n    C --&gt; H\n    D --&gt; H\n    F --&gt; H\n    F --&gt; I[Video/Audio Pipeline]\n    G --&gt; I\n\n    %% Outputs\n    H --&gt; J[MCAP Writer]\n    I --&gt; K[MKV Pipeline]\n\n    %% Files\n    J --&gt; L[\ud83d\udcc4 events.mcap]\n    K --&gt; M[\ud83c\udfa5 video.mkv]\n\n    style A fill:#e1f5fe\n    style E fill:#e1f5fe\n    style H fill:#fff3e0\n    style L fill:#e8f5e8\n    style M fill:#e8f5e8</code></pre> <ul> <li>Easy to verify: Extensive OWA's Env design enables customizable <code>recorder.py</code></li> <li>Native performance: Direct Windows API integration (DXGI/WGC, WASAPI)</li> </ul>"},{"location":"data/getting-started/recording-data/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Record terminates right after start? Re-run the same command a few times. This is due to an intermittent GStreamer crash with an unknown cause.</li> <li>GStreamer error message box appears on first run? This is a known issue where GStreamer may show error dialogs the first time you run <code>ocap</code>. These messages do not affect recording\u2014simply close the dialogs and continue. <code>ocap</code> will function normally.</li> <li>Audio not recording? By default, only audio from the target process is recorded. To change this, manually edit the GStreamer pipeline.</li> <li>Large file sizes? Reduce file size by adjusting the <code>gop-size</code> parameter in the <code>nvd3d11h265enc</code> element. See pipeline.py.</li> <li>Performance tips: Close unnecessary applications before recording, use SSD storage for better write performance, and record to a different drive than your OS drive.</li> </ul>"},{"location":"data/getting-started/recording-data/#faq","title":"FAQ","text":"<ul> <li>How much disk space do recordings use? ~100MB per minute for 1080p H265 recording.</li> <li>Can I customize recorded events? Yes. Enable/disable audio, keyboard, mouse, and window events individually. Since recorder.py is just a 320-line single python script, you may customize it easily.</li> <li>Will ocap slow down my computer? Minimal impact with hardware acceleration. Designed for low overhead.</li> <li>What formats are supported? MKV with H265/HEVC encoding for video and MCAP format for events for efficient storage and querying is supported, but you may customize it easily. (e.g. saving <code>jsonl</code> instead of <code>mcap</code> file takes minimal effort by editing recorder.py)</li> </ul>"},{"location":"data/getting-started/recording-data/#when-to-use-ocap","title":"When to Use ocap","text":"<ul> <li>Agent training: Capture all inputs and outputs for AI training</li> <li>Workflow documentation: Record exact steps with precise timing</li> <li>Performance testing: Low-overhead recording during intensive tasks</li> <li>Complete screen recording: When you need more than just video</li> </ul>"},{"location":"data/getting-started/why-owamcap/","title":"Why OWAMcap?","text":"<p>The Problem: Desktop AI datasets are fragmented. Every research group uses different formats, making it impossible to combine datasets or build large-scale foundation models.</p> <p>The Solution: OWAMcap provides a universal standard that treats all desktop interaction datasets equally.</p>"},{"location":"data/getting-started/why-owamcap/#the-robotics-lesson","title":"The Robotics Lesson","text":"<p>The Open-X Embodiment project had to manually convert 22 different robotics datasets - months of work just to combine data. Desktop automation is heading down the same path.</p>"},{"location":"data/getting-started/why-owamcap/#owamcap-changes-this","title":"OWAMcap Changes This","text":""},{"location":"data/getting-started/why-owamcap/#before-data-silos","title":"Before: Data Silos","text":"<pre><code>Dataset A (Custom Format) \u2500\u2500\u2510\nDataset B (Custom Format) \u2500\u2500\u253c\u2500\u2500 Manual Conversion \u2500\u2500\u2192 Limited Training Data\nDataset C (Custom Format) \u2500\u2500\u2518\n</code></pre>"},{"location":"data/getting-started/why-owamcap/#after-universal-standard","title":"After: Universal Standard","text":"<pre><code>Dataset A (OWAMcap) \u2500\u2500\u2510\nDataset B (OWAMcap) \u2500\u2500\u253c\u2500\u2500 Direct Combination \u2500\u2500\u2192 Large-Scale Foundation Models\nDataset C (OWAMcap) \u2500\u2500\u2518\n</code></pre>"},{"location":"data/getting-started/why-owamcap/#from-recording-to-training-in-3-commands","title":"From Recording to Training in 3 Commands","text":"<p>OWAMcap integrates with the complete OWA Data Pipeline:</p> <pre><code># 1. Record desktop interaction\n$ ocap my-session.mcap\n\n# 2. Process to training format\n$ python scripts/01_raw_events_to_event_dataset.py --train-dir ./\n\n# 3. Train your model\n$ python train.py --dataset ./event-dataset\n</code></pre> <p>\ud83d\udcd6 Detailed Guide: Complete Quick Start Tutorial - Step-by-step walkthrough with examples and troubleshooting</p> <p>Result: Any OWAMcap dataset works with any OWA-compatible training pipeline.</p>"},{"location":"data/getting-started/why-owamcap/#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd04 Universal Standard: Unlike fragmented formats, enables seamless dataset combination for large-scale foundation models (OWAMcap)</li> <li>\ud83c\udfaf High-Performance Multimodal Storage: Lightweight MCAP container with nanosecond precision for synchronized data streams (MCAP)</li> <li>\ud83d\udd17 Flexible MediaRef: Smart references to both external and embedded media (file paths, URLs, data URIs, video frames) with lazy loading - keeps metadata files small while supporting rich media (OWAMcap) \u2192 Learn more</li> <li>\ud83e\udd17 Training Pipeline Ready: Native HuggingFace integration, seamless dataset loading, and direct compatibility with ML frameworks (Ecosystem) \u2192 Browse datasets | Data pipeline</li> </ul>"},{"location":"data/getting-started/why-owamcap/#real-impact","title":"Real Impact","text":"<pre><code>$ owl mcap info example.mcap\nmessages:  864 (10.36s of interaction data)\nfile size: 22 KiB (vs 1+ GB raw)\nchannels:  screen, mouse, keyboard, window\n</code></pre> <p>Bottom Line: OWAMcap transforms desktop interaction data from isolated collections into a unified resource for building the next generation of foundation models.</p> <p>Ready to get started? Continue to the OWAMcap Format Guide for technical details.</p>"},{"location":"data/technical-reference/custom-messages/","title":"Custom Message Types in OWAMcap","text":"<p>OWAMcap's extensible design allows you to define and register custom message types for domain-specific data while maintaining compatibility with the standard OWAMcap ecosystem.</p> <p>When to Use Custom Messages</p> <p>Custom messages are perfect for:</p> <ul> <li>Domain-specific data: Sensor readings, game events, robotics telemetry</li> <li>Application-specific context: Custom metadata, annotations, or derived data</li> <li>Research extensions: Novel data types for experimental workflows</li> </ul> <p>Standard desktop messages (<code>mouse</code>, <code>keyboard</code>, <code>screen</code>, <code>window</code>) cover most desktop agent use cases.</p>"},{"location":"data/technical-reference/custom-messages/#creating-custom-messages","title":"Creating Custom Messages","text":"<p>All custom messages must inherit from <code>OWAMessage</code> and follow the domain/MessageType naming convention:</p> <pre><code>from owa.core.message import OWAMessage\nfrom typing import Optional, List\nfrom pydantic import Field, validator\nimport time\n\nclass TemperatureReading(OWAMessage):\n    _type = \"sensors/TemperatureReading\"\n\n    temperature: float          # Temperature in Celsius\n    humidity: float = Field(..., ge=0, le=100)  # Relative humidity (0-100%)\n    location: str              # Sensor location identifier\n    timestamp: Optional[int] = Field(default_factory=time.time_ns)  # Unix timestamp in nanoseconds\n\n    @validator('temperature')\n    def validate_temperature(cls, v):\n        if v &lt; -273.15:  # Absolute zero check\n            raise ValueError('Temperature cannot be below absolute zero')\n        return v\n\nclass GameEvent(OWAMessage):\n    _type = \"gaming/PlayerAction\"\n\n    action_type: str           # \"move\", \"attack\", \"interact\"\n    player_id: str            # Unique player identifier\n    coordinates: List[float] = Field(..., min_items=3, max_items=3)  # [x, y, z] world coordinates\n    metadata: dict = {}        # Additional action-specific data\n\n    @validator('action_type')\n    def validate_action_type(cls, v):\n        allowed_actions = {'move', 'attack', 'interact', 'idle'}\n        if v not in allowed_actions:\n            raise ValueError(f'action_type must be one of {allowed_actions}')\n        return v\n</code></pre>"},{"location":"data/technical-reference/custom-messages/#package-registration","title":"Package Registration","text":"<p>Custom messages are registered through Python entry points in your package's <code>pyproject.toml</code>:</p> <pre><code>[project.entry-points.\"owa.msgs\"]\n\"sensors/TemperatureReading\" = \"my_sensors.messages:TemperatureReading\"\n\"gaming/PlayerAction\" = \"my_game.events:GameEvent\"\n\"custom/MyMessage\" = \"my_package.messages:MyMessage\"\n</code></pre> <p>Important: The package containing your custom messages must be installed in the same environment where you're using OWAMcap for the entry points to be discovered:</p> <pre><code># Install your custom message package\npip install my-custom-messages\n\n# Or install in development mode\npip install -e /path/to/my-custom-messages\n\n# Now custom messages are available in the registry\npython -c \"from owa.core import MESSAGES; print('sensors/TemperatureReading' in MESSAGES)\"\n</code></pre>"},{"location":"data/technical-reference/custom-messages/#usage-with-owamcap","title":"Usage with OWAMcap","text":"<p>Once registered, custom messages work seamlessly with OWAMcap tools:</p> <pre><code>from mcap_owa.highlevel import OWAMcapWriter, OWAMcapReader\nfrom owa.core import MESSAGES\n\n# Access your custom message through the registry\nTemperatureReading = MESSAGES['sensors/TemperatureReading']\n\n# Write custom messages to MCAP\nwith OWAMcapWriter(\"sensor_data.mcap\") as writer:\n    reading = TemperatureReading(\n        temperature=23.5,\n        humidity=65.2,\n        location=\"office_desk\"\n    )\n    writer.write_message(reading, topic=\"temperature\", timestamp=reading.timestamp)\n\n# Read custom messages from MCAP\nwith OWAMcapReader(\"sensor_data.mcap\") as reader:\n    for msg in reader.iter_messages(topics=[\"temperature\"]):\n        temp_data = msg.decoded\n        print(f\"Temperature: {temp_data.temperature}\u00b0C at {temp_data.location}\")\n</code></pre>"},{"location":"data/technical-reference/custom-messages/#best-practices","title":"Best Practices","text":"Naming ConventionsSchema DesignPackage Structure <ul> <li>Domain: Use descriptive domain names (<code>sensors</code>, <code>gaming</code>, <code>robotics</code>)</li> <li>MessageType: Use PascalCase (<code>TemperatureReading</code>, <code>PlayerAction</code>)</li> <li>Avoid conflicts: Check existing message types before naming</li> <li>Be specific: <code>sensors/TemperatureReading</code> vs generic <code>sensors/Reading</code></li> </ul> <ul> <li>Use type hints: Enable automatic JSON schema generation</li> <li>Leverage pydantic features: See Pydantic documentation for validation, field constraints, and defaults</li> <li>Documentation: Include docstrings for complex message types</li> </ul> <pre><code>my_custom_package/\n\u251c\u2500\u2500 pyproject.toml              # Entry point registration\n\u251c\u2500\u2500 my_package/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 messages.py             # Message definitions\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 test_messages.py        # Message validation tests\n</code></pre>"},{"location":"data/technical-reference/custom-messages/#cli-integration","title":"CLI Integration","text":"<p>Custom messages automatically work with OWA CLI tools:</p> <pre><code># List all available message types (including custom)\nowl messages list\n\n# View custom message schema\nowl messages show sensors/TemperatureReading\n\n# View custom messages in MCAP files\nowl mcap cat sensor_data.mcap --topics temperature\n</code></pre> <p>Complete CLI Reference</p> <p>For detailed information about all CLI commands and options:</p> <ul> <li>CLI Tools - Complete command overview</li> <li>Message Commands - Detailed <code>owl messages</code> documentation</li> <li>MCAP Commands - Working with custom messages in MCAP files</li> </ul>"},{"location":"data/technical-reference/custom-messages/#next-steps","title":"Next Steps","text":"<ul> <li>OWAMcap Format Guide: Return to the main format documentation</li> <li>Data Pipeline: Learn how custom messages work in the training pipeline</li> <li>CLI Reference: Complete CLI documentation for working with custom messages</li> </ul>"},{"location":"data/technical-reference/data-pipeline/","title":"OWA Data Pipeline: From Raw MCAP to VLA Training","text":""},{"location":"data/technical-reference/data-pipeline/#quick-demo-3-commands-to-vla-training","title":"Quick Demo: 3 Commands to VLA Training","text":"<p>Step 1: Process raw MCAP files</p> python scripts/01_raw_events_to_event_dataset.py \\   --train-dir /data/mcaps/game-session \\   --output-dir /data/event-dataset \\   --rate mouse=60 --rate screen=20 \\   --keep-topic screen --keep-topic keyboard\ud83d\udd04 Raw Events to Event Dataset\ud83d\udcc1 Loading from: /data/mcaps/game-session\ud83d\udcca Found 3 train, 1 test files\u2713 Created 24,907 train, 20,471 test examples\ud83d\udcbe Saving to /data/event-dataset\u2713 Saved successfully\ud83c\udf89 Completed in 3.9s (0.1min) <p>Step 2: Create time bins (optional)</p> python scripts/02_event_dataset_to_binned_dataset.py \\   --input-dir /data/event-dataset \\   --output-dir /data/binned-dataset \\   --fps 10 \\   --filter-empty-actions\ud83d\uddc2\ufe0f Event Dataset to Binned Dataset\ud83d\udcc1 Loading from: /data/event-dataset\ud83d\udcca Found 3 files to process\u2713 Created 2,235 binned entries for train split\u2713 Created 1,772 binned entries for test split\ud83d\udcbe Saving to /data/binned-dataset\u2713 Saved 4,007 total binned entries\ud83c\udf89 Completed in 4.0s (0.1min) <p>Step 3: Train your model</p> python&gt;&gt;&gt; from datasets import load_from_disk&gt;&gt;&gt; from owa.data import create_binned_dataset_transform&gt;&gt;&gt;&gt;&gt;&gt; # Load and transform dataset&gt;&gt;&gt; dataset = load_from_disk(\"/data/binned-dataset\")&gt;&gt;&gt; transform = create_binned_dataset_transform(...     encoder_type=\"hierarchical\",...     instruction=\"Complete the computer task\"... )&gt;&gt;&gt; dataset.set_transform(transform)&gt;&gt;&gt;&gt;&gt;&gt; # Use in training&gt;&gt;&gt; for sample in dataset[\"train\"].take(1):...     print(f\"Images: {len(sample['images'])} frames\")...     print(f\"Actions: {sample['encoded_events'][:3]}...\")...     print(f\"Instruction: {sample['instruction']}\")Images: 12 framesActions: ['&lt;EVENT_START&gt;mouse_move&lt;EVENT_END&gt;', '&lt;EVENT_START&gt;key_press:w&lt;EVENT_END&gt;', '&lt;EVENT_START&gt;mouse_click:left&lt;EVENT_END&gt;']...Instruction: Complete the computer task <p>That's it! Your MCAP recordings are now ready for VLA training.</p> <p>The OWA Data Pipeline is a streamlined 2-stage processing system that transforms raw MCAP recordings into training-ready datasets for Vision-Language-Action (VLA) models. This pipeline bridges the gap between desktop interaction capture and foundation model training.</p>"},{"location":"data/technical-reference/data-pipeline/#pipeline-architecture","title":"Pipeline Architecture","text":"<pre><code>graph LR\n    A[Raw MCAP Files] --&gt; B[Stage 1: Event Dataset]\n    B --&gt; C[Stage 2: Binned Dataset]\n    B --&gt; D[Dataset Transforms]\n    C --&gt; D\n    D --&gt; E[VLA Training Ready]\n\n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#ffebee</code></pre> <p>Key Features:</p> <ul> <li>\ud83d\udd04 Flexible: Skip binning and use Event Dataset directly, or use traditional Binned Dataset approach</li> <li>\ud83d\udcbe Storage Optimized: Since event/binned dataset saves only reference to media, the entire pipeline is designed to be space-efficient. <pre><code>/data/\n\u251c\u2500\u2500 mcaps/           # Raw recordings (400MB)\n\u251c\u2500\u2500 event-dataset/   # References only (20MB)\n\u2514\u2500\u2500 binned-dataset/  # Aggregated refs (2MB)\n</code></pre></li> <li>\ud83e\udd17 Native HuggingFace: Event/binned dataset is a true HuggingFace <code>datasets.Dataset</code> with <code>set_transform()</code>, not wrappers. <pre><code># Since event/binned datasets are true HuggingFace datasets,\n# they can be loaded directly into training pipelines\nfrom datasets import load_from_disk\ndataset = load_from_disk(\"/data/event-dataset\")\ndataset = load_from_disk(\"/data/binned-dataset\")\n\n# Transform to VLA training format is applied on-the-fly during training\nfrom owa.data import create_binned_dataset_transform\ntransform = create_binned_dataset_transform(\n    encoder_type=\"hierarchical\",\n    instruction=\"Complete the computer task\",\n)\ndataset.set_transform(transform)\n\n# Use in training\nfor sample in dataset[\"train\"].take(1):\n    print(f\"Images: {len(sample['images'])} frames\")\n    print(f\"Actions: {sample['encoded_events'][:3]}...\")\n    print(f\"Instruction: {sample['instruction']}\")\n</code></pre></li> <li>\u26a1 Compute-optimized, On-the-Fly Processing: During preprocess stage, media is not loaded. During training, only the required media is loaded on-demand.</li> </ul> python scripts/01_raw_events_to_event_dataset.py\ud83d\udd04 Raw Events to Event Dataset\ud83d\udcc1 Loading from: /data/mcaps/game-session\ud83d\udcca Found 3 train, 1 test files\u2713 Created 24,907 train, 20,471 test examples\ud83d\udcbe Saving to /data/event-dataset\u2713 Saved successfully\ud83c\udf89 Completed in **3.9s** (0.1min)"},{"location":"data/technical-reference/data-pipeline/#stage-1-raw-mcap-event-dataset","title":"Stage 1: Raw MCAP \u2192 Event Dataset","text":"<p>Purpose</p> <p>Extract and downsample raw events from MCAP files while preserving temporal precision and event context.</p>"},{"location":"data/technical-reference/data-pipeline/#script-usage","title":"Script Usage","text":"<pre><code>python scripts/01_raw_events_to_event_dataset.py \\\n  --train-dir /path/to/mcap/files \\\n  --output-dir /path/to/event/dataset \\\n  --rate mouse=60 --rate screen=20 \\\n  --keep-topic screen --keep-topic keyboard\n</code></pre>"},{"location":"data/technical-reference/data-pipeline/#key-parameters","title":"Key Parameters","text":"Parameter Description Example <code>--train-dir</code> Directory containing MCAP files <code>/data/recordings/</code> <code>--output-dir</code> Output directory for Event Dataset <code>/data/event-dataset/</code> <code>--rate</code> Rate limiting per topic (Hz) <code>mouse=60 screen=20</code> <code>--keep-topic</code> Topics to include in dataset <code>screen keyboard mouse</code>"},{"location":"data/technical-reference/data-pipeline/#output-schema","title":"Output Schema","text":"<p>The Event Dataset uses a flat structure optimized for temporal queries:</p> <pre><code>{\n    \"file_path\": Value(\"string\"),      # Source MCAP file path\n    \"topic\": Value(\"string\"),          # Event topic (keyboard, mouse, screen)\n    \"timestamp_ns\": Value(\"int64\"),    # Timestamp in nanoseconds\n    \"message_type\": Value(\"string\"),   # Full message type identifier\n    \"mcap_message\": Value(\"binary\"),   # Serialized McapMessage bytes\n}\n</code></pre> <p>When to Use Event Dataset</p> <ul> <li>High-frequency training: When you need precise temporal resolution</li> <li>Custom binning: When you want to implement your own temporal aggregation</li> <li>Event-level analysis: When studying individual interaction patterns</li> </ul>"},{"location":"data/technical-reference/data-pipeline/#stage-2-event-dataset-binned-dataset","title":"Stage 2: Event Dataset \u2192 Binned Dataset","text":"<p>Purpose</p> <p>Aggregate events into fixed-rate time bins for uniform temporal sampling, separating state (screen) from actions (keyboard/mouse). This format is equivalent to most existing VLA datasets, such as LeRobotDataset</p>"},{"location":"data/technical-reference/data-pipeline/#script-usage_1","title":"Script Usage","text":"<pre><code>python scripts/02_event_dataset_to_binned_dataset.py \\\n  --input-dir /path/to/event/dataset \\\n  --output-dir /path/to/binned/dataset \\\n  --fps 10 \\\n  --filter-empty-actions\n</code></pre>"},{"location":"data/technical-reference/data-pipeline/#key-parameters_1","title":"Key Parameters","text":"Parameter Description Default <code>--fps</code> Binning frequency (frames per second) <code>10</code> <code>--filter-empty-actions</code> Remove bins with no actions <code>False</code> <code>--input-dir</code> Event Dataset directory Required <code>--output-dir</code> Output directory for Binned Dataset Required"},{"location":"data/technical-reference/data-pipeline/#output-schema_1","title":"Output Schema","text":"<p>The Binned Dataset organizes events into temporal bins with state-action separation:</p> <pre><code>{\n    \"file_path\": Value(\"string\"),      # Source MCAP file path\n    \"bin_idx\": Value(\"int32\"),         # Time bin index\n    \"timestamp_ns\": Value(\"int64\"),    # Bin start timestamp\n    \"state\": Sequence(feature=Value(\"binary\"), length=-1),    # Screen events\n    \"actions\": Sequence(feature=Value(\"binary\"), length=-1),  # Action events\n}\n</code></pre> <p>When to Use Binned Dataset</p> <ul> <li>Traditional VLA training: When following established vision-language-action patterns</li> <li>Fixed-rate processing: When you need consistent temporal sampling</li> <li>State-action separation: When your model expects distinct state and action inputs</li> <li>Efficient filtering: When you want to remove inactive periods</li> </ul>"},{"location":"data/technical-reference/data-pipeline/#dataset-transforms-the-magic-layer","title":"Dataset Transforms: The Magic Layer","text":"<p>Dataset transforms provide the crucial bridge between stored data and training-ready format. They apply on-demand during data loading, not during preprocessing.</p>"},{"location":"data/technical-reference/data-pipeline/#unified-transform-interface","title":"Unified Transform Interface","text":"<p>Both Event Dataset and Binned Dataset support the same transform interface:</p> Event Dataset TransformBinned Dataset Transform <pre><code>from datasets import load_from_disk\nfrom owa.data import create_event_dataset_transform\n\n# Load dataset\ndataset = load_from_disk(\"/path/to/event-dataset\")\n\n# Create transform\ntransform = create_event_dataset_transform(\n    encoder_type=\"hierarchical\",\n    load_images=True,\n    encode_actions=True,\n)\n\n# Apply transform\ndataset.set_transform(transform)\n\n# Use in training\nfor sample in dataset[\"train\"]:\n    images = sample[\"images\"]          # List[PIL.Image]\n    events = sample[\"encoded_events\"]  # List[str]\n</code></pre> <pre><code>from datasets import load_from_disk\nfrom owa.data import create_binned_dataset_transform\n\n# Load dataset\ndataset = load_from_disk(\"/path/to/binned-dataset\")\n\n# Create transform\ntransform = create_binned_dataset_transform(\n    encoder_type=\"hierarchical\",\n    instruction=\"Complete the computer task\",\n    load_images=True,\n    encode_actions=True,\n)\n\n# Apply transform\ndataset.set_transform(transform)\n\n# Use in training\nfor sample in dataset[\"train\"]:\n    images = sample[\"images\"]          # List[PIL.Image]\n    actions = sample[\"encoded_events\"] # List[str]\n    instruction = sample[\"instruction\"] # str\n</code></pre>"},{"location":"data/technical-reference/data-pipeline/#transform-parameters","title":"Transform Parameters","text":"Parameter Description Options Default <code>encoder_type</code> Event encoding strategy <code>hierarchical</code>, <code>json</code> <code>hierarchical</code> <code>load_images</code> Load screen images <code>True</code>, <code>False</code> <code>True</code> <code>encode_actions</code> Encode action events <code>True</code>, <code>False</code> <code>True</code> <code>instruction</code> Task instruction (Binned only) Any string <code>\"Complete the task\"</code>"},{"location":"data/technical-reference/data-pipeline/#references","title":"References","text":"<ul> <li>Format Guide - OWAMcap details</li> <li>Recording Data - Create with <code>ocap</code></li> <li>HuggingFace Datasets - <code>datasets</code> library</li> </ul>"},{"location":"data/technical-reference/format-guide/","title":"OWAMcap Format Guide","text":"<p>What is OWAMcap?</p> <p>OWAMcap is a specification for using the open-source MCAP container format with Open World Agents (OWA) message definitions. It provides an efficient way to store and process multimodal desktop interaction data including screen captures, mouse events, keyboard events, and window information.</p> <p>New to OWAMcap?</p> <p>Start with Why OWAMcap? to understand the problem it solves and why you should use it.</p>"},{"location":"data/technical-reference/format-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Getting Started<ul> <li>Quick Start - Get started in 3 steps</li> <li>Core Concepts - Essential message types and features</li> </ul> </li> <li>Working with OWAMcap<ul> <li>Media Handling - External references and lazy loading</li> <li>Reading and Writing - File operations and CLI tools</li> <li>Storage &amp; Performance - Efficiency characteristics</li> </ul> </li> <li>Advanced Topics<ul> <li>Extending OWAMcap - Custom message types and extensibility</li> <li>Data Pipeline Integration - Real-world integrations</li> <li>Best Practices - Performance and organization guidelines</li> </ul> </li> <li>Reference<ul> <li>Migration &amp; Troubleshooting - Practical help and common issues</li> <li>Technical Reference - Specifications and standards</li> </ul> </li> </ul>"},{"location":"data/technical-reference/format-guide/#getting-started","title":"Getting Started","text":""},{"location":"data/technical-reference/format-guide/#quick-start","title":"Quick Start","text":"<p>Try OWAMcap in 3 Steps</p> <p>1. Install the packages: <pre><code>pip install mcap-owa-support owa-msgs\n</code></pre></p> <p>2. Explore an example file with the <code>owl</code> CLI:</p> <p>What is <code>owl</code>?</p> <p><code>owl</code> is the command-line interface for OWA tools, installed with <code>owa-cli</code>. See the CLI documentation for complete usage.</p> <pre><code># Download example file\nwget https://github.com/open-world-agents/open-world-agents/raw/main/docs/data/examples/example.mcap\n\n# View file info\nowl mcap info example.mcap\n\n# List first 5 messages\nowl mcap cat example.mcap --n 5\n</code></pre> <p>3. Load in Python: <pre><code>from mcap_owa.highlevel import OWAMcapReader\n\nwith OWAMcapReader(\"example.mcap\", decode_args={\"return_dict\": True}) as reader:\n    for msg in reader.iter_messages(topics=[\"screen\"]):\n        screen_data = msg.decoded\n        print(f\"Frame: {screen_data.shape} at {screen_data.utc_ns}\")\n        break  # Just show first frame\n</code></pre></p>"},{"location":"data/technical-reference/format-guide/#core-concepts","title":"Core Concepts","text":"<p>OWAMcap combines the robustness of the MCAP container format with OWA's specialized message types for desktop environments, creating a powerful format for recording, analyzing, and training on human-computer interaction data.</p>"},{"location":"data/technical-reference/format-guide/#key-terms","title":"Key Terms","text":"<p>Essential Terminology</p> <ul> <li>MCAP: A modular container file format for heterogeneous, timestamped data (like a ZIP file for time-series data). Developed by Foxglove, MCAP provides efficient random access, compression, and self-describing schemas. Widely adopted in robotics (ROS ecosystem), autonomous vehicles, and IoT applications for its performance and interoperability.</li> <li>Topic: A named channel in MCAP files (e.g., \"screen\", \"mouse\") that groups related messages</li> <li>Lazy Loading: Loading data only when needed, crucial for memory efficiency with large datasets</li> </ul>"},{"location":"data/technical-reference/format-guide/#what-makes-a-file-owamcap","title":"What Makes a File \"OWAMcap\"","text":"Architecture OverviewTechnical DefinitionPractical Example <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    OWAMcap File (.mcap)                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Metadata      \u2502  \u2502   Timestamps    \u2502  \u2502  Messages   \u2502  \u2502\n\u2502  \u2502   - Profile     \u2502  \u2502   - Nanosecond  \u2502  \u2502  - Mouse    \u2502  \u2502\n\u2502  \u2502   - Topics      \u2502  \u2502     precision   \u2502  \u2502  - Keyboard \u2502  \u2502\n\u2502  \u2502   - Schemas     \u2502  \u2502   - Event sync  \u2502  \u2502  - Window   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u2502 References\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                External Media Files (.mkv, .png)            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Video Frames   \u2502  \u2502  Screenshots    \u2502  \u2502   Audio     \u2502  \u2502\n\u2502  \u2502  - H.265 codec  \u2502  \u2502  - PNG/JPEG     \u2502  \u2502  - Optional \u2502  \u2502\n\u2502  \u2502  - Hardware acc \u2502  \u2502  - Lossless     \u2502  \u2502  - Sync'd   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Base Format: Standard MCAP container format</li> <li>Profile: <code>owa</code> designation in MCAP metadata</li> <li>Schema Encoding: JSON Schema</li> <li>Message Interface: All messages implement <code>BaseMessage</code> from <code>owa.core.message</code></li> <li>Standard Messages: Core message types from <code>owa-msgs</code> package</li> </ul> <p>Why MCAP?</p> <p>Built as the successor to ROSBag, MCAP offers efficient storage and retrieval for heterogeneous timestamped data with minimal dependencies. It's designed for modern use cases with optimized random access, built-in compression, and language-agnostic schemas. The format has gained significant adoption across the robotics community, autonomous vehicle companies (Cruise, Waymo), and IoT platforms due to its performance advantages and excellent tooling ecosystem.</p> <pre><code>$ owl mcap info example.mcap\nlibrary:   mcap-owa-support 0.5.1; mcap 1.3.0\nprofile:   owa\nmessages:  864\nduration:  10.3574349s\nstart:     2025-06-27T18:49:52.129876+09:00 (1751017792.129876000)\nend:       2025-06-27T18:50:02.4873109+09:00 (1751017802.487310900)\ncompression:\n        zstd: [1/1 chunks] [116.46 KiB/16.61 KiB (85.74%)] [1.60 KiB/sec]\nchannels:\n        (1) window           11 msgs (1.06 Hz)    : desktop/WindowInfo [jsonschema]\n        (2) keyboard/state   11 msgs (1.06 Hz)    : desktop/KeyboardState [jsonschema]\n        (3) mouse/state      11 msgs (1.06 Hz)    : desktop/MouseState [jsonschema]\n        (4) screen          590 msgs (56.96 Hz)   : desktop/ScreenCaptured [jsonschema]\n        (5) mouse           209 msgs (20.18 Hz)   : desktop/MouseEvent [jsonschema]\n        (6) keyboard         32 msgs (3.09 Hz)    : desktop/KeyboardEvent [jsonschema]\nchannels: 6\nattachments: 0\nmetadata: 0\n</code></pre>"},{"location":"data/technical-reference/format-guide/#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd04 Universal Standard: Unlike fragmented formats, enables seamless dataset combination for large-scale foundation models (OWAMcap)</li> <li>\ud83c\udfaf High-Performance Multimodal Storage: Lightweight MCAP container with nanosecond precision for synchronized data streams (MCAP)</li> <li>\ud83d\udd17 Flexible MediaRef: Smart references to both external and embedded media (file paths, URLs, data URIs, video frames) with lazy loading - keeps metadata files small while supporting rich media (OWAMcap) \u2192 Learn more</li> <li>\ud83e\udd17 Training Pipeline Ready: Native HuggingFace integration, seamless dataset loading, and direct compatibility with ML frameworks (Ecosystem) \u2192 Browse datasets | Data pipeline</li> </ul>"},{"location":"data/technical-reference/format-guide/#core-message-types","title":"Core Message Types","text":"<p>OWA provides standardized message types through the <code>owa-msgs</code> package for consistent desktop interaction recording:</p> Message Type Description <code>desktop/KeyboardEvent</code> Keyboard press/release events <code>desktop/KeyboardState</code> Current keyboard state <code>desktop/MouseEvent</code> Mouse movement, clicks, scrolls <code>desktop/MouseState</code> Current mouse position and buttons <code>desktop/RawMouseEvent</code> High-definition raw mouse input data <code>desktop/ScreenCaptured</code> Screen capture frames with timestamps <code>desktop/WindowInfo</code> Active window information KeyboardEventKeyboardStateMouseEventMouseStateRawMouseEventScreenCapturedWindowInfo <pre><code>class KeyboardEvent(OWAMessage):\n    _type = \"desktop/KeyboardEvent\"\n\n    event_type: str  # \"press\" or \"release\"\n    vk: int         # Virtual key code (e.g., 65 for 'A')\n    timestamp: int  # Event timestamp\n\n# Example: User presses the 'A' key\nKeyboardEvent(event_type=\"press\", vk=65, timestamp=1234567890)\n</code></pre> <p>What's VK (Virtual Key Code)?</p> <p>Operating systems don't directly use the physical keyboard input values (scan codes) but instead use virtualized keys called VKs. OWA's recorder uses VKs to record keyboard-agnostic data. If you're interested in more details, you can refer to the following resources:</p> <ul> <li>Keyboard Input Overview, Microsoft</li> <li>Virtual-Key Codes, Microsoft</li> </ul> <pre><code>class KeyboardState(OWAMessage):\n    _type = \"desktop/KeyboardState\"\n\n    buttons: List[int]  # List of currently pressed virtual key codes\n\n# Example: No keys currently pressed\nKeyboardState(buttons=[])\n</code></pre> <pre><code>class MouseEvent(OWAMessage):\n    _type = \"desktop/MouseEvent\"\n\n    event_type: str  # \"move\", \"click\", \"scroll\", \"drag\"\n    x: int          # Screen X coordinate\n    y: int          # Screen Y coordinate\n    button: Optional[str] = None    # \"left\", \"right\", \"middle\"\n\n# Example: Mouse click at position (100, 200)\nMouseEvent(event_type=\"click\", x=100, y=200, button=\"left\")\n</code></pre> <pre><code>class MouseState(OWAMessage):\n    _type = \"desktop/MouseState\"\n\n    x: int                    # Current mouse X coordinate\n    y: int                    # Current mouse Y coordinate\n    buttons: List[str] = []   # Currently pressed mouse buttons\n\n# Example: Mouse at position with no buttons pressed\nMouseState(x=1594, y=1112, buttons=[])\n</code></pre> <pre><code>class RawMouseEvent(OWAMessage):\n    _type = \"desktop/RawMouseEvent\"\n\n    us_flags: mouse state flags, containing movement data type (relative/absolute). Default is relative.\n    last_x: can be relative or absolute, depends on us_flags\n    last_y: can be relative or absolute, depends on us_flags\n    button_flags: Raw button state flags from Windows RAWMOUSE structure\n    button_data: Additional button data (wheel delta, etc.)\n    device_handle: Raw input device handle (optional)\n    timestamp: Optional timestamp in nanoseconds since epoch\n\n# Example: Raw mouse movement\nRawMouseEvent(us_flags=0x0000, last_x=15, last_y=-10, button_flags=0x0000, button_data=0)\n</code></pre> <pre><code>class ScreenCaptured(OWAMessage):\n    _type = \"desktop/ScreenCaptured\"\n\n    utc_ns: Optional[int] = None                    # System timestamp (nanoseconds)\n    source_shape: Optional[Tuple[int, int]] = None  # Original (width, height)\n    shape: Optional[Tuple[int, int]] = None         # Current (width, height)\n    media_ref: Optional[MediaRef] = None            # URI or file path reference\n    frame_arr: Optional[np.ndarray] = None          # In-memory BGRA array (excluded from JSON)\n</code></pre> <p>Working with ScreenCaptured Messages</p> <p>For detailed information on creating, loading, and working with ScreenCaptured messages, see the Media Handling section below. It covers MediaRef formats, lazy loading, and practical usage patterns.</p> <pre><code>class WindowInfo(OWAMessage):\n    _type = \"desktop/WindowInfo\"\n\n    title: str              # Window title text\n    rect: List[int]         # [x, y, width, height]\n    hWnd: Optional[int]     # Windows handle (platform-specific)\n\n# Example: Browser window\nWindowInfo(\n    title=\"GitHub - Open World Agents - Chrome\",\n    rect=[100, 50, 1200, 800]\n)\n</code></pre>"},{"location":"data/technical-reference/format-guide/#working-with-owamcap","title":"Working with OWAMcap","text":"<p>This section covers the essential operations for working with OWAMcap files in your applications. Whether you're processing recorded desktop sessions or creating new datasets, these patterns will help you work efficiently with the format.</p>"},{"location":"data/technical-reference/format-guide/#media-handling","title":"Media Handling","text":"<p>OWAMcap's key advantage is efficient media handling through external media references. Instead of storing large image/video data directly in the MCAP file, OWAMcap stores lightweight references to external media files, keeping the MCAP file small and fast to process.</p> Creating ScreenCaptured MessagesLoading and Accessing Frame Data <p>Understanding MediaRef</p> <p>MediaRef is OWAMcap's way of referencing media content. It supports multiple formats:</p> <ul> <li>File paths: <code>/absolute/path</code> or <code>relative/path</code></li> <li>File URIs: <code>file:///path/to/file</code></li> <li>HTTP URLs: <code>https://example.com/image.png</code></li> <li>Data URIs: <code>data:image/png;base64,...</code> (embedded content)</li> </ul> <p>For videos, add <code>pts_ns</code> (presentation timestamp) to specify which frame.</p> <pre><code>from owa.core import MESSAGES\nimport numpy as np\n\nScreenCaptured = MESSAGES['desktop/ScreenCaptured']\n\n# File paths (absolute/relative) - works for images and videos\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"/absolute/path/image.png\"})\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"relative/video.mkv\", \"pts_ns\": 123456})\n\n# File URIs - works for images and videos\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"file:///path/to/image.jpg\"})\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"file:///path/to/video.mp4\", \"pts_ns\": 123456})\n\n# HTTP/HTTPS URLs - works for images and videos\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"https://example.com/image.png\"})\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"https://example.com/video.mp4\", \"pts_ns\": 123456})\n\n# Data URIs (embedded base64) - typically for images\nscreen_msg = ScreenCaptured(media_ref={\"uri\": \"data:image/png;base64,iVBORw0KGgo...\"})\n\n# From raw image array (BGRA format required)\nbgra_array = np.random.randint(0, 255, (1080, 1920, 4), dtype=np.uint8)\nscreen_msg = ScreenCaptured(frame_arr=bgra_array)\nscreen_msg.embed_as_data_uri(format=\"png\")  # Required for serialization\n# Now screen_msg.media_ref contains: {\"uri\": \"data:image/png;base64,...\"}\n</code></pre> <p>Why Lazy Loading Matters</p> <p>Lazy Loading means frame data is only loaded when you explicitly request it. This is crucial for performance:</p> <ul> <li>\u2705 Fast: Iterate through thousands of messages instantly</li> <li>\u2705 Memory efficient: Only load frames you actually need</li> <li>\u2705 Scalable: Work with datasets larger than your RAM</li> </ul> <p>Without lazy loading, opening a 1-hour recording would try to load ~200GB of frame data into memory!</p> <pre><code># IMPORTANT: For MCAP files, resolve relative paths first\n# The OWA recorder saves media paths relative to the MCAP file location\nScreenCaptured = MESSAGES['desktop/ScreenCaptured']\nscreen_msg = ScreenCaptured(\n    media_ref={\"uri\": \"relative/video.mkv\", \"pts_ns\": 123456789}\n)\n\n# Must resolve external paths before loading from MCAP files\nscreen_msg.resolve_relative_path(\"/path/to/data.mcap\")\n\n# Lazy loading: Frame data is loaded on-demand when these methods are called\nrgb_array = screen_msg.to_rgb_array()        # RGB numpy array (most common)\npil_image = screen_msg.to_pil_image()        # PIL Image object\nbgra_array = screen_msg.load_frame_array()   # Raw BGRA array (native format)\n\n# Check if frame data is loaded (lazy loading means it starts as None)\nif screen_msg.frame_arr is not None:\n    height, width, channels = screen_msg.frame_arr.shape\n    print(f\"Frame: {width}x{height}, {channels} channels\")\nelse:\n    print(\"Frame data not loaded - use load_frame_array() first\")\n</code></pre>"},{"location":"data/technical-reference/format-guide/#reading-and-writing","title":"Reading and Writing","text":"ReadingWritingAdvancedCLI Tools <pre><code>from mcap_owa.highlevel import OWAMcapReader\n\nwith OWAMcapReader(\"session.mcap\") as reader:\n    # File metadata\n    print(f\"Topics: {reader.topics}\")\n    print(f\"Duration: {(reader.end_time - reader.start_time) / 1e9:.2f}s\")\n\n    # Lazy loading advantage: Fast iteration without loading frame data\n    for msg in reader.iter_messages(topics=[\"screen\"]):\n        screen_data = msg.decoded\n        print(f\"Frame metadata: {screen_data.shape} at {screen_data.utc_ns}\")\n        # No frame data loaded yet - extremely fast for large datasets\n\n        # Only load frame data when actually needed\n        if some_condition:  # e.g., every 10th frame\n            frame = screen_data.to_rgb_array()  # Now frame is loaded\n            break  # Just show first frame\n</code></pre> <pre><code>from mcap_owa.highlevel import OWAMcapWriter\nfrom owa.core import MESSAGES\n\nScreenCaptured = MESSAGES['desktop/ScreenCaptured']\nMouseEvent = MESSAGES['desktop/MouseEvent']\n\nwith OWAMcapWriter(\"output.mcap\") as writer:\n    # Write screen capture\n    screen_msg = ScreenCaptured(\n        utc_ns=1234567890,\n        media_ref={\"uri\": \"video.mkv\", \"pts_ns\": 1234567890},\n        shape=(1920, 1080)\n    )\n    writer.write_message(screen_msg, topic=\"screen\", timestamp=1234567890)\n\n    # Write standard mouse event\n    mouse_msg = MouseEvent(event_type=\"click\", x=100, y=200)\n    writer.write_message(mouse_msg, topic=\"mouse\", timestamp=1234567891)\n</code></pre> <pre><code># Time range filtering\nwith OWAMcapReader(\"session.mcap\") as reader:\n    start_time = reader.start_time + 1_000_000_000  # Skip first second\n    end_time = reader.start_time + 10_000_000_000   # First 10 seconds\n\n    for msg in reader.iter_messages(start_time=start_time, end_time=end_time):\n        print(f\"Message in range: {msg.topic}\")\n\n# Remote files\nwith OWAMcapReader(\"https://example.com/data.mcap\") as reader:\n    for msg in reader.iter_messages(topics=[\"screen\"]):\n        print(f\"Remote frame: {msg.decoded.shape}\")\n</code></pre> <pre><code># File information\nowl mcap info session.mcap\n\n# List messages\nowl mcap cat session.mcap --n 10 --topics screen --topics mouse\n\n# Migrate between versions\nowl mcap migrate run session.mcap\n\n# Extract frames\nowl mcap extract-frames session.mcap --output frames/\n</code></pre>"},{"location":"data/technical-reference/format-guide/#storage-performance","title":"Storage &amp; Performance","text":"<p>OWAMcap achieves remarkable storage efficiency through external video references and intelligent compression:</p>"},{"location":"data/technical-reference/format-guide/#compression-benefits","title":"Compression Benefits","text":"<p>Compression Performance</p> <p>Compression performance varies significantly across formats. H.265 encoding achieves a 217.8\u00d7 compression ratio compared to raw BGRA data while maintaining visual quality suitable for agent training, enabling practical storage of large-scale desktop interaction datasets.</p> <p>Desktop screen capture at 1920 \u00d7 1080 resolution, 12 s @ 60 Hz:</p> Format Size per Frame Whole Size Compression Ratio Raw BGRA 5.97 MB 4.2 GB 1.0\u00d7 (baseline) PNG 1.87 MB 1.31 GB 3.2\u00d7 JPEG (Quality 85) 191 KB 135 MB 31.9\u00d7 H.265 (keyframe 0.5s, nvd3d11h265enc) 27.8 KB avg 19.6 MB 217.8\u00d7 <p>Compression benefit per resolution</p> <p>Compression performance is resolution-dependent. Lower resolutions yield lower compression ratios.</p> <p>Desktop screen capture at 600 \u00d7 800 resolution, 13 s @ 60 Hz:</p> Format Size per Frame Whole Size Compression Ratio Raw BGRA 1.37 MB 1.0 GB 1.0\u00d7 (baseline) PNG 468 KB 341 MB 3.0\u00d7 JPEG (Quality 85) 64.6 KB 47.2 MB 21.7\u00d7 H.265 (keyframe 0.5s, nvd3d11h265enc) 15.3 KB avg 11.2 MB 91.7\u00d7 <p>H.265 Configuration</p> <p>The H.265 settings shown above (keyframe 0.5s, nvd3d11h265enc) are the same as those used by ocap for efficient desktop recording.</p> <p>Key advantages:</p> <ul> <li>Lightweight MCAP: very fast to parse, transfer, and back up  </li> <li>Video Compression: leverages hardware-accelerated codecs for extreme savings  </li> <li>Selective Loading: grab only the frames you need without full decompression  </li> <li>Standard Tools: preview in any video player and edit with off-the-shelf software  </li> </ul>"},{"location":"data/technical-reference/format-guide/#advanced-topics","title":"Advanced Topics","text":""},{"location":"data/technical-reference/format-guide/#extending-owamcap","title":"Extending OWAMcap","text":""},{"location":"data/technical-reference/format-guide/#custom-message-types","title":"Custom Message Types","text":"<p>Need to store domain-specific data beyond standard desktop interactions? OWAMcap supports custom message types for sensors, gaming, robotics, and more.</p> <p>Custom Messages Documentation</p> <p>\ud83d\udcd6 Custom Message Types Guide - Complete guide to creating, registering, and using custom message types in OWAMcap.</p> <p>Covers: message creation, package registration, best practices, and CLI integration.</p>"},{"location":"data/technical-reference/format-guide/#data-pipeline-integration","title":"Data Pipeline Integration","text":"# 1. Record desktop interactionocap my-session.mcap\ud83c\udfa5 Recording desktop interaction...\u2713 Saved 1,247 events to my-session.mcap# 2. Process to training formatpython scripts/01_raw_events_to_event_dataset.py --train-dir ./\ud83d\udd04 Raw Events to Event Dataset\ud83d\udcc1 Loading from: ./\ud83d\udcca Found 1 train files\u2713 Created 1,247 train examples\ud83d\udcbe Saving to ./event-dataset\u2713 Saved successfully# 3. Train your modelpython train.py --dataset ./event-dataset\ud83d\ude80 Loading dataset...\ud83c\udfcb\ufe0f Training desktop agent...\ud83d\udcc8 Epoch 1/10: loss=0.234 <p>Pipeline Benefits:</p> <ul> <li>\ud83d\udd04 Flexible: Skip binning and use Event Dataset directly, or use traditional Binned Dataset approach</li> <li>\ud83d\udcbe Storage Optimized: Since event/binned dataset saves only reference to media, the entire pipeline is designed to be space-efficient. <pre><code>/data/\n\u251c\u2500\u2500 mcaps/           # Raw recordings (400MB)\n\u251c\u2500\u2500 event-dataset/   # References only (20MB)\n\u2514\u2500\u2500 binned-dataset/  # Aggregated refs (2MB)\n</code></pre></li> <li>\ud83e\udd17 Native HuggingFace: Event/binned dataset is a true HuggingFace <code>datasets.Dataset</code> with <code>set_transform()</code>, not wrappers. <pre><code># Since event/binned datasets are true HuggingFace datasets,\n# they can be loaded directly into training pipelines\nfrom datasets import load_from_disk\ndataset = load_from_disk(\"/data/event-dataset\")\n\n# Transform to VLA training format is applied on-the-fly during training\nfrom owa.data import create_event_dataset_transform\ntransform = create_event_dataset_transform(\n    encoder_type=\"hierarchical\",\n    load_images=True,\n    encode_actions=True,\n)\ndataset.set_transform(transform)\n\n# Use in training\nfor sample in dataset[\"train\"].take(1):\n    print(f\"Images: {len(sample['images'])} frames\")\n    print(f\"Actions: {sample['encoded_events'][:3]}...\")\n    print(f\"Instruction: {sample['instruction']}\")\n</code></pre></li> <li>\u26a1 Compute-optimized, On-the-Fly Processing: During preprocess stage, media is not loaded. During training, only the required media is loaded on-demand. <pre><code>$ python scripts/01_raw_events_to_event_dataset.py\n\ud83d\udd04 Raw Events to Event Dataset\n\ud83d\udcc1 Loading from: /data/mcaps/game-session\n\ud83d\udcca Found 3 train, 1 test files\n---&gt; 100%\n\u2713 Created 24,907 train, 20,471 test examples\n\ud83d\udcbe Saving to /data/event-dataset\n\u2713 Saved successfully\n\ud83c\udf89 Completed in 3.9s (0.1min)\n</code></pre></li> </ul> <p>Complete Pipeline Documentation</p> <p>See \ud83d\ude80 Data Pipeline for detailed documentation on each stage, configuration options, and integration with training frameworks.</p>"},{"location":"data/technical-reference/format-guide/#best-practices","title":"Best Practices","text":"Storage StrategyPerformanceFile Organization <p>Decision Tree: Choose Your Storage Approach</p> <pre><code>Recording Length?\n\u251c\u2500 &lt; 30 seconds\n\u2502  \u2514\u2500 Use embedded data URIs (self-contained)\n\u2514\u2500 &gt; 30 seconds\n   \u2514\u2500 File Size Priority?\n      \u251c\u2500 Minimize MCAP size\n      \u2502  \u2514\u2500 Use external video (.mkv)\n      \u2514\u2500 Maximize quality\n         \u2514\u2500 Use external images (.png)\n</code></pre> Use Case Strategy Benefits Trade-offs Long recordings External video Minimal MCAP size, efficient Requires external files Short sessions Embedded data Self-contained Larger MCAP files High-quality External images Lossless compression Many files to manage Remote datasets Video + URLs Bandwidth efficient Network dependency <pre><code># \u2705 Good: Filter topics early\nwith OWAMcapReader(\"file.mcap\") as reader:\n    for msg in reader.iter_messages(topics=[\"screen\"]):\n        process_frame(msg.decoded)\n\n# \u2705 Good: Lazy loading\nfor msg in reader.iter_messages(topics=[\"screen\"]):\n    if should_process_frame(msg.timestamp):\n        frame = msg.decoded.load_frame_array()  # Only when needed\n\n# \u274c Avoid: Loading all frames\nframes = [msg.decoded.load_frame_array() for msg in reader.iter_messages()]\n</code></pre> <p>Recommended structure: <pre><code>/data/\n\u251c\u2500\u2500 mcaps/                          # Raw MCAP recordings\n\u2502   \u251c\u2500\u2500 session_001.mcap\n\u2502   \u251c\u2500\u2500 session_001.mkv             # External video files\n\u2502   \u2514\u2500\u2500 session_002.mcap\n\u251c\u2500\u2500 event-dataset/                  # Stage 1: Event Dataset\n\u2502   \u251c\u2500\u2500 train/\n\u2502   \u2514\u2500\u2500 test/\n\u2514\u2500\u2500 binned-dataset/                 # Stage 2: Binned Dataset\n    \u251c\u2500\u2500 train/\n    \u2514\u2500\u2500 test/\n</code></pre></p> <p>See OWA Data Pipeline for complete pipeline details.</p>"},{"location":"data/technical-reference/format-guide/#reference","title":"Reference","text":""},{"location":"data/technical-reference/format-guide/#migration-troubleshooting","title":"Migration &amp; Troubleshooting","text":""},{"location":"data/technical-reference/format-guide/#file-migration","title":"File Migration","text":"<p>OWAMcap format evolves over time. When you encounter older files that need updating, use the migration tool:</p> <p>When Do You Need Migration?</p> <ul> <li>Error messages about unsupported schema versions</li> <li>Missing fields when loading older recordings</li> <li>Compatibility warnings from OWA tools</li> <li>Performance issues with legacy file formats</li> </ul> <p>Migration Commands:</p> <pre><code># Check if migration is needed\nowl mcap info old_file.mcap  # Look for version warnings\n\n# Preview what will change (safe, no modifications)\nowl mcap migrate run old_file.mcap --dry-run\n\n# Migrate single file (creates backup automatically)\nowl mcap migrate run old_file.mcap\n\n# Migrate multiple files in batch\nowl mcap migrate run *.mcap\n\n# Migrate with custom output location\nowl mcap migrate run old_file.mcap --output new_file.mcap\n</code></pre> <p>Migration Safety</p> <ul> <li>Automatic backups: Original files are preserved as <code>.backup</code></li> <li>Validation: Migrated files are automatically validated</li> <li>Rollback: Use backup files if migration causes issues</li> </ul> <p>Complete Migration Reference</p> <p>For detailed information about all migration commands and options, see the OWA CLI - MCAP Commands documentation.</p>"},{"location":"data/technical-reference/format-guide/#common-issues","title":"Common Issues","text":"<p>File Not Found Errors</p> <p>When video files are missing: <pre><code># Resolve relative paths\nscreen_msg.resolve_relative_path(\"/path/to/mcap/file.mcap\")\n# Check if external media exists\nscreen_msg.media_ref.validate_uri()\n</code></pre></p> <p>Memory Usage</p> <p>Large datasets can consume memory: <pre><code># Use lazy loading instead of loading all frames\nfor msg in reader.iter_messages(topics=[\"screen\"]):\n    if should_process_frame(msg.timestamp):\n        frame = msg.decoded.load_frame_array()  # Only when needed\n</code></pre></p>"},{"location":"data/technical-reference/format-guide/#technical-reference","title":"Technical Reference","text":"<p>For detailed technical specifications, see:</p> <ul> <li>OEP-0006: OWAMcap Profile Specification - Authoritative format specification</li> <li>MCAP Format - Base container format documentation</li> <li>Message Registry - See <code>projects/owa-core/owa/core/messages.py</code> for implementation</li> </ul>"},{"location":"data/technical-reference/format-guide/#next-steps","title":"Next Steps","text":"<ul> <li>Explore and Edit: Learn to work with OWAMcap files</li> <li>Data Pipeline: Process OWAMcap for ML training</li> <li>Viewer: Visualize OWAMcap data interactively</li> <li>Comparison with LeRobot: See how OWAMcap differs from other formats</li> </ul>"},{"location":"data/tools/comparison-with-lerobot/","title":"OWAMcap vs LeRobotDataset: A Technical Comparison","text":""},{"location":"data/tools/comparison-with-lerobot/#executive-summary","title":"Executive Summary","text":"<p>Both OWAMcap and LeRobotDataset address the critical need for standardized multimodal data formats in embodied AI. However, they differ significantly in their architectural approach and target domains. This comparison analyzes three distinct layers: container format, data schema, and library ecosystem.</p>"},{"location":"data/tools/comparison-with-lerobot/#three-layer-comparison-framework","title":"Three-Layer Comparison Framework","text":"<p>To properly compare OWAMcap and LeRobotDataset, we need to understand that they operate at different architectural levels. Rather than comparing them directly, we analyze three distinct layers of the data stack:</p> <p>Why Three Layers Matter:</p> <ul> <li>Container Format: Think of this as your storage unit\u2014how you pack your stuff (MCAP vs Parquet)</li> <li>Data Schema: This is what you actually put in those boxes\u2014the \"language\" your data speaks (OWAMcap vs LeRobotDataset)</li> <li>Library Ecosystem: The tools and trucks you need to move everything around (mcap-owa-support vs lerobot)</li> </ul> <p>This separation matters because without it, we'd be comparing fundamentally different things. It's like trying to compare a car's engine (container format) with its GPS system (data schema) with its maintenance costs (library ecosystem)\u2014they're all important, but they solve different problems and need to be evaluated on their own terms.</p>"},{"location":"data/tools/comparison-with-lerobot/#layer-1-container-format-mcap-vs-parquet","title":"Layer 1: Container Format (MCAP vs Parquet)","text":"<p>Imagine you're organizing your digital life. MCAP is like having a smart filing cabinet that automatically timestamps everything and keeps related items together. Parquet? That's more like Excel on steroids\u2014fantastic for crunching numbers, but ask it to handle your mixed media collection and things get messy.</p> Feature MCAP Parquet (LeRobotDataset) Primary Design Time-synchronized multimodal logging Columnar analytics storage Data Organization Multiple channels/topics with explicit schemas Single table structure Heterogeneous Data \u2705 Native support for mixed data types \u274c Tabular data only; external file references Time Synchronization \u2705 Per-message timestamps with indexing \u274c Manual alignment across files required Streaming Safety \u2705 Crash-safe incremental writes \u274c Bulk writes; vulnerable to data loss Random Access \u2705 Indexed time/channel queries \u274c Sequential column scans Schema Extensibility \u2705 Custom message types supported \u274c Fixed table schema Self-Containedness \u2705 Embedded schemas and metadata \u274c External dependencies for interpretation"},{"location":"data/tools/comparison-with-lerobot/#layer-2-data-format-owamcap-vs-lerobotdataset","title":"Layer 2: Data Format (OWAMcap vs LeRobotDataset)","text":"<p>While MCAP vs Parquet represents the container comparison, OWAMcap vs LeRobotDataset represents the data schema comparison\u2014how domain-specific message types and structures are defined on top of these containers.</p> <p>Commonalities: Both use lazy-loading for video frames to optimize storage and memory usage.</p> <p>Key Differences:</p> <pre><code># OWAMcap: Desktop-specific message types\nclass ScreenCaptured(OWAMessage):\n    path: str           # Video file reference\n    pts: int           # Precise frame timestamp\n    utc_ns: int        # System timestamp\n\nclass MouseEvent(OWAMessage):\n    event_type: str    # move, click, scroll\n    x: int, y: int     # Screen coordinates\n\nclass KeyboardEvent(OWAMessage):\n    event_type: str    # press, release\n    vk: int           # Virtual key code\n</code></pre> <pre><code># LeRobotDataset: Generic robotics observations\n{\n    \"observation.image\": \"path/to/frame.jpg\",\n    \"observation.state\": [x, y, z, ...],  # Robot joint positions\n    \"action\": [dx, dy, dz, ...]           # Action commands\n}\n</code></pre> <p>Domain Specialization Impact:</p> <ul> <li>OWAMcap: Pre-defined messages enables seamless integration across diverse desktop tasks (web browsing, document editing, gaming)</li> <li>LeRobotDataset: Generic structure requires domain-specific adaptations for each robot platform</li> </ul>"},{"location":"data/tools/comparison-with-lerobot/#layer-3-library-ecosystem","title":"Layer 3: Library Ecosystem","text":"<p>Library Design Philosophy:</p> <p>The fundamental difference reflects two approaches: minimal dependencies (OWAMcap) for worry-free adoption vs comprehensive ecosystem (LeRobotDataset) bundling complete toolchains.</p> Metric mcap-owa-support lerobot Dependencies 21 packages 93 packages Install Time 0.75s 66.65s Adoption Friction \"Just works\" territory \"Hope nothing breaks\" zone <p>Dependency Analysis:</p> <pre><code># OWAMcap: The minimalist's dream\nmcap-owa-support\n\u251c\u2500\u2500 mcap (the core engine)\n\u251c\u2500\u2500 pydantic (keeps data honest)\n\u251c\u2500\u2500 loguru (friendly logging)\n\u2514\u2500\u2500 zstandard (compression magic)\n\n# LeRobotDataset: The everything ecosystem\nlerobot\n\u251c\u2500\u2500 torch + torchvision (GPU go brrrr)\n\u251c\u2500\u2500 gym + mujoco (virtual robot playground)\n\u251c\u2500\u2500 opencv + imageio (pixel manipulation station)\n\u251c\u2500\u2500 wandb (experiment diary)\n\u251c\u2500\u2500 hydra (configuration wizard)\n\u2514\u2500\u2500 [85+ more packages having a dependency party]\n</code></pre> <p>The Zero-Friction Philosophy \ud83d\udca1</p> <p>Our guiding principle is simple: developers should install our library and immediately get back to building cool stuff, not debugging dependency conflicts or waiting for installations to finish.</p>"},{"location":"data/tools/comparison-with-lerobot/#why-container-choice-matters-for-foundation-models","title":"Why Container Choice Matters for Foundation Models","text":""},{"location":"data/tools/comparison-with-lerobot/#random-access-the-need-for-speed","title":"Random Access: The Need for Speed","text":"<p>The difference between MCAP and Parquet for data access is like comparing a sports car to a city bus. Both get you there, but the experience is... different.</p> <pre><code># MCAP: \"I want data from 2:30 PM to 2:35 PM, please\"\nmessages = reader.iter_messages(\n    start_time=start_ns,\n    end_time=end_ns,\n    topics=[\"screen\", \"mouse\"]\n)  # Boom. Done. Lightning fast.\n\n# Parquet: \"Let me read everything and then filter...\"\ndf = pd.read_parquet(\"data.parquet\")\nfiltered = df[(df.timestamp &gt;= start) &amp; (df.timestamp &lt;= end)]\n# *waiting music intensifies*\n</code></pre>"},{"location":"data/tools/comparison-with-lerobot/#multi-modal-synchronization-keeping-everyone-in-sync","title":"Multi-Modal Synchronization: Keeping Everyone in Sync","text":"<p>MCAP: Like a conductor with perfect timing\u2014every instrument (modality) hits their notes exactly when they should.</p> <pre><code>Channel 1: screen     [t1, t3, t5, t7, ...]\nChannel 2: mouse      [t1, t2, t4, t6, t8, ...]\nChannel 3: keyboard   [t2, t5, t9, ...]\n</code></pre> <p>Parquet: More like a garage band where everyone's trying to stay in time but someone's always slightly off-beat.</p>"},{"location":"data/tools/comparison-with-lerobot/#desktop-vs-robotics-two-different-worlds","title":"Desktop vs Robotics: Two Different Worlds","text":"Domain Desktop Automation Robotics Session Length Hours of continuous interaction Minutes of task execution Event Frequency High-frequency input events Lower-frequency control commands Crash Recovery Critical for long sessions Less critical for short episodes Data Types Window focus, UI interactions, multi-monitor Joint positions, sensor readings, control commands"},{"location":"data/tools/comparison-with-lerobot/#performance-implications-for-vla-training","title":"Performance Implications for VLA Training","text":""},{"location":"data/tools/comparison-with-lerobot/#storage-efficiency","title":"Storage Efficiency","text":"<pre><code># Example 45-min desktop session\nMetadata (mcap):     24 MiB\nVideo (external):    5.4 GiB\nTotal:              5.4 GiB\n\n# Equivalent data in uncompressed format\nRaw frames:         ~447 GiB\nCompression ratio:  82x reduction\n</code></pre>"},{"location":"data/tools/comparison-with-lerobot/#training-pipeline-impact","title":"Training Pipeline Impact","text":"<p>\ud83d\udea7 TODO: Here is TODO and subject to be changed.</p> <p>Data Loading Performance: <pre><code># OWAMcap: Efficient batch loading with precise temporal control\nfor batch in dataloader:\n    # Direct access to synchronized multimodal streams\n    screens = [msg.lazy_load() for msg in batch.screen_messages]\n    actions = batch.mouse_events + batch.keyboard_events\n    # No resampling artifacts; preserves original event timing\n\n# LeRobotDataset: The \"close enough\" approach\nfor batch in dataloader:\n    # delta_timestamps is the key design\n    frames = dataset[i:i+batch_size]\n    # Manual synchronization across heterogeneous streams required\n</code></pre></p> <p>Write Performance:</p> Scenario MCAP (OWAMcap) Parquet (LeRobotDataset) Real-time logging \u2705 Optimized append-only writes \u274c Requires batching; write overhead High-frequency events \u2705 Native support \u274c Must aggregate before writing Crash recovery \u2705 Partial file recovery possible \u274c Risk of data loss during writes"},{"location":"data/tools/comparison-with-lerobot/#schema-evolution-and-fair-data-principles","title":"Schema Evolution and FAIR Data Principles","text":"<p>Schema Evolution:</p> <ul> <li>OWAMcap: Each channel maintains independent schema; new modalities added without affecting existing data</li> <li>LeRobotDataset: Global schema changes affect entire dataset</li> </ul> <p>FAIR Data Alignment:</p> Principle OWAMcap LeRobotDataset Findable \u2705 Rich embedded metadata \u26a0\ufe0f Depends on HF Hub infrastructure Accessible \u2705 Self-contained files \u26a0\ufe0f Multi-file dependencies Interoperable \u2705 Standard MCAP readers \u2705 HF ecosystem compatibility Reusable \u2705 Embedded schemas + provenance \u26a0\ufe0f External documentation required"},{"location":"data/tools/comparison-with-lerobot/#strategic-recommendations","title":"Strategic Recommendations","text":""},{"location":"data/tools/comparison-with-lerobot/#the-decision-matrix","title":"The Decision Matrix","text":"Use Case Recommended Format Why This Makes Sense Desktop Foundation Models OWAMcap Purpose-built, lightweight, just works Production Desktop Agents OWAMcap Zero dependencies headaches, crash-safe Novel Multimodal Research OWAMcap Flexibility to experiment without limits Academic Robotics Research LeRobotDataset Join the party everyone's already at"},{"location":"data/tools/comparison-with-lerobot/#the-hybrid-approach-best-of-both-worlds","title":"The Hybrid Approach: Best of Both Worlds","text":"<p>For the ambitious researchers who want it all:</p> <ol> <li>Capture Phase: Use OWAMcap to grab everything (think of it as your digital net)</li> <li>Consumption Phase: Transform relevant bits for your ML pipeline (curated data delivery)</li> </ol>"},{"location":"data/tools/comparison-with-lerobot/#conclusion-the-plot-twist-ending","title":"Conclusion: The Plot Twist Ending","text":"<p>Here's the thing\u2014OWAMcap and LeRobotDataset aren't really competitors. They're more like specialized tools designed for different jobs. OWAMcap is the precision instrument for desktop automation\u2014lightweight, focused, and built for the unique chaos of human-computer interaction. LeRobotDataset(rather, LeRobot) is the comprehensive toolkit for robotics research\u2014heavy-duty, feature-rich, and backed by a thriving community.</p> <p>The real question isn't \"which is better?\" but \"which fits your mission?\" If you're building the next generation of desktop AI agents, OWAMcap's specialized design will save you months of headaches. If you're advancing robotics research within existing academic frameworks, LeRobot's ecosystem might be your golden ticket.</p> <p>The future of embodied AI isn't about choosing sides\u2014it's about picking the right tool for the job and maybe, just maybe, building bridges between these different worlds. After all, the best AI systems might need to understand both digital desktops and physical robots. Now wouldn't that be something? \ud83d\ude80</p>"},{"location":"data/tools/viewer/","title":"OWAMcap Data Viewer","text":"<p>Interactive web-based visualization tool for exploring OWAMcap datasets with synchronized playback of screen recordings and interaction events.</p>"},{"location":"data/tools/viewer/#public-hosted-viewer","title":"\ud83c\udf10 Public Hosted Viewer","text":"<p>Quick Start: https://huggingface.co/spaces/open-world-agents/visualize_dataset</p>"},{"location":"data/tools/viewer/#features","title":"Features","text":"<ul> <li>Upload Files: Drag &amp; drop your <code>.mcap</code> files (up to 100MB)</li> <li>HuggingFace Integration: Enter any <code>repo_id</code> to view public datasets</li> <li>Synchronized Playback: Video + events timeline</li> <li>Interactive Controls: Pause, seek, frame-by-frame navigation</li> </ul>"},{"location":"data/tools/viewer/#usage","title":"Usage","text":"<ol> <li>Visit the viewer URL</li> <li>Either upload your files or enter a HuggingFace dataset ID</li> <li>Explore your data with synchronized video and event timeline</li> </ol>"},{"location":"data/tools/viewer/#self-hosted-setup","title":"\ud83c\udfe0 Self-Hosted Setup","text":"<p>For larger files or private datasets, run the viewer locally:</p> <pre><code># Navigate to viewer directory\ncd projects/owa-mcap-viewer\n\n# Set data path\nexport EXPORT_PATH=/path/to/your/mcap-files\n\n# Install dependencies\nvuv install\n\n# Start server\nuvicorn owa_viewer:app --host 0.0.0.0 --port 7860 --reload\n</code></pre> <p>Access at <code>http://localhost:7860</code></p>"},{"location":"data/tools/viewer/#benefits-of-self-hosting","title":"Benefits of Self-Hosting","text":"<ul> <li>No file size limits</li> <li>Private data stays local</li> <li>Faster loading for large datasets</li> <li>Customizable interface</li> </ul>"},{"location":"env/","title":"Environment Framework","text":"<p>OWA's Env is the \"USB-C of desktop agents\" - a universal interface for native desktop automation.</p> <p>Think MCP for Desktop</p> <p> Just as Model Context Protocol (MCP) provides a standardized way for LLMs to connect to data sources and tools, OWA's Env provides a standardized way for agents to connect to desktop environments.</p> <ul> <li>MCP: \"USB-C of LLMs\" - universal interface for AI tools</li> <li>OWA's Env: \"USB-C of desktop agents\" - universal interface for native desktop automation </li> </ul> <p>Quick Start</p> <p><pre><code>pip install owa\n</code></pre> <pre><code>from owa.core import CALLABLES, LISTENERS\n# Components automatically available - no configuration needed!\n</code></pre></p>"},{"location":"env/#core-concepts","title":"Core Concepts","text":"<p>OWA's Environment provides three types of components for real-time agent interaction:</p> CallablesListenersRunnables <p>Direct function calls for immediate actions <pre><code># Get current time, capture screen, click mouse\nCALLABLES[\"std/time_ns\"]()\nCALLABLES[\"desktop/screen.capture\"]()\nCALLABLES[\"desktop/mouse.click\"](\"left\", 2)\n</code></pre></p> <p>Event monitoring with user-defined callbacks <pre><code># Monitor keyboard events\ndef on_key(event):\n    print(f\"Key pressed: {event.vk}\")\n\nlistener = LISTENERS[\"desktop/keyboard\"]().configure(callback=on_key)\nwith listener.session:\n    input(\"Press Enter to stop...\")\n</code></pre></p> <p>Background processes that can be started/stopped <pre><code># Periodic screen capture\ncapture = RUNNABLES[\"gst/screen_capture\"]().configure(fps=60)\nwith capture.session:\n    frame = capture.grab()\n</code></pre></p>"},{"location":"env/#why-choose-owas-env","title":"Why Choose OWA's Env?","text":"<p>Traditional frameworks like gymnasium.Env use synchronous <code>env.step()</code> calls that assume infinite processing time. Real-world agents need real-time responses.</p> <p>OWA's Env delivers:</p> <ul> <li>\u26a1 Real-time Performance: Optimized for responsive agent interactions (GStreamer components achieve &lt;30ms latency)</li> <li>\ud83d\udd0c Zero-Configuration: Automatic plugin discovery via Python Entry Points</li> <li>\ud83c\udf10 Event-Driven: Asynchronous processing that mirrors real-world dynamics</li> <li>\ud83e\udde9 Extensible: Community-driven plugin ecosystem</li> </ul>"},{"location":"env/#quick-navigation","title":"Quick Navigation","text":"Section Description Environment Guide Complete system overview and usage examples Custom Plugins Create your own environment extensions CLI Tools Plugin management and exploration commands <p>Built-in Plugins:</p> Plugin Description Key Features Standard Core utilities Time functions, periodic tasks Desktop Desktop automation Mouse/keyboard control, window management GStreamer High-performance capture 6x faster screen recording"},{"location":"env/custom_plugins/","title":"Custom EnvPlugin Development","text":"<p>Create plugins that extend OWA with your own functionality.</p> <p>OWA's Env: MCP for Desktop Agents</p> <p>Just as Model Context Protocol (MCP) is the \"USB-C of LLMs\", OWA's Env is the \"USB-C of desktop agents\" - a universal interface for native desktop automation.</p>"},{"location":"env/custom_plugins/#plugin-discovery","title":"Plugin Discovery","text":""},{"location":"env/custom_plugins/#how-it-works","title":"How It Works","text":"<p>OWA automatically discovers plugins using Python's Entry Points system:</p> <pre><code>flowchart TD\n    A[Your Plugin Package] --&gt; B[pyproject.toml]\n    B --&gt; C[Entry Point Declaration]\n    C --&gt; E[Plugin Specification]\n\n    E --&gt; F[Component Definitions]\n\n    F --&gt; G[Callables]\n    F --&gt; H[Listeners]\n    F --&gt; I[Runnables]\n\n    J[OWA Core Registry] -.-&gt;|Plugin Discovery| C\n    G -.-&gt; J\n    H -.-&gt; J\n    I -.-&gt; J\n\n    J --&gt; K[Available to Users]\n    K --&gt; L[\"CALLABLES['namespace/name']\"]\n    K --&gt; M[\"LISTENERS['namespace/name']\"]\n    K --&gt; N[\"RUNNABLES['namespace/name']\"]\n\n    style A fill:#e1f5fe\n    style J fill:#f3e5f5\n    style K fill:#e8f5e8</code></pre>"},{"location":"env/custom_plugins/#discovery-process","title":"Discovery Process","text":"<ol> <li>Entry Point Scanning - OWA scans all installed packages for <code>\"owa.env.plugins\"</code> entry points</li> <li>Plugin Spec Loading - Loads and validates each <code>PluginSpec</code> object</li> <li>Lazy Registration - Registers component metadata without importing actual code</li> <li>On-Demand Loading - Components are imported only when first accessed</li> </ol>"},{"location":"env/custom_plugins/#quick-start-your-first-plugin-in-5-minutes","title":"Quick Start: Your First Plugin in 5 Minutes","text":""},{"location":"env/custom_plugins/#step-1-copy-the-template","title":"Step 1: Copy the Template","text":"<pre><code># Copy the example plugin as your starting point\ncp -r projects/owa-env-example my-first-plugin\ncd my-first-plugin\n</code></pre>"},{"location":"env/custom_plugins/#step-2-make-it-yours","title":"Step 2: Make It Yours","text":"<p>Edit <code>pyproject.toml</code> to change the plugin name:</p> <pre><code>[project.entry-points.\"owa.env.plugins\"]\nmyfirst = \"owa.env.plugins.myfirst:plugin_spec\"  # Changed from 'example'\n</code></pre> <p>Edit <code>owa/env/plugins/example.py</code> and change the namespace:</p> <pre><code>plugin_spec = PluginSpec(\n    namespace=\"myfirst\",  # Changed from 'example'\n    version=\"0.1.0\",\n    description=\"My first OWA plugin\",\n    # ... rest stays the same\n)\n</code></pre>"},{"location":"env/custom_plugins/#step-3-install-and-test","title":"Step 3: Install and Test","text":"<pre><code># Install your plugin\npip install -e .\n\n# Verify OWA discovered it\nowl env list myfirst\n\n# Test a component\npython -c \"from owa.core import CALLABLES; print(CALLABLES['myfirst/add'](2, 3))\"\n</code></pre> <p>\ud83c\udf89 Congratulations!</p> <p>You just created your first OWA plugin. Your components are now available to any OWA user or application.</p>"},{"location":"env/custom_plugins/#component-types","title":"Component Types","text":""},{"location":"env/custom_plugins/#callables","title":"Callables","text":"<p>Functions for immediate results:</p> <pre><code>def get_weather(city: str) -&gt; dict:\n    return {\"city\": city, \"temp\": 25, \"condition\": \"sunny\"}\n\n# Usage: CALLABLES[\"myplugin/weather\"](\"New York\")\n</code></pre>"},{"location":"env/custom_plugins/#listeners","title":"Listeners","text":"<p>Event monitoring with callbacks (inherits from Runnable):</p> <pre><code>from owa.core import Listener\n\nclass FileWatcher(Listener):\n    def on_configure(self, callback, watch_folder, **kwargs):\n        self.callback = callback\n        self.watch_folder = watch_folder\n\n    def start(self):\n        # Monitor folder, call self.callback(event) on changes\n        pass\n\n    def stop(self):\n        # Stop and cleanup\n        pass\n</code></pre>"},{"location":"env/custom_plugins/#runnables","title":"Runnables","text":"<p>Background processes with start/stop control:</p> <pre><code>from owa.core import Runnable\n\nclass DataCollector(Runnable):\n    def on_configure(self, output_file, interval=60, **kwargs):\n        self.output_file = output_file\n        self.interval = interval\n\n    def loop(self, *, stop_event):\n        while not stop_event.is_set():\n            # Do work\n            stop_event.wait(self.interval)\n</code></pre>"},{"location":"env/custom_plugins/#plugin-specification","title":"Plugin Specification","text":""},{"location":"env/custom_plugins/#structure","title":"Structure","text":"owa/env/plugins/myplugin.py<pre><code>from owa.core.plugin_spec import PluginSpec\n\nplugin_spec = PluginSpec(\n    namespace=\"myplugin\",\n    version=\"0.1.0\",\n    description=\"My custom plugin\",\n    components={\n        \"callables\": {\n            \"weather\": \"owa.env.myplugin.api:get_weather\",\n            \"calculate\": \"owa.env.myplugin.math:add_numbers\",\n        },\n        \"listeners\": {\n            \"file_watcher\": \"owa.env.myplugin.watchers:FileWatcher\",\n        },\n        \"runnables\": {\n            \"data_collector\": \"owa.env.myplugin.workers:DataCollector\",\n        }\n    }\n)\n</code></pre>"},{"location":"env/custom_plugins/#key-elements","title":"Key Elements","text":"<ul> <li>namespace: Unique identifier for your plugin</li> <li>components: Maps component names to import paths</li> <li>Import format: <code>\"module.path:object_name\"</code></li> </ul>"},{"location":"env/custom_plugins/#reference-implementation","title":"Reference Implementation","text":"<p>Study the working example: <code>projects/owa-env-example</code></p>"},{"location":"env/custom_plugins/#getting-started","title":"Getting Started","text":"<pre><code>cd projects/owa-env-example\npip install -e .\nowl env list example\n\n# Test it works\npython -c \"\nfrom owa.core import CALLABLES\nresult = CALLABLES['example/add'](2, 3)\nprint(f'2 + 3 = {result}')\n\"\n</code></pre>"},{"location":"env/custom_plugins/#what-it-shows","title":"What It Shows","text":"<ul> <li>File organization and project structure</li> <li>All three component types with working examples</li> <li>Proper entry point configuration</li> <li>Complete test suite</li> </ul>"},{"location":"env/custom_plugins/#project-structure-options","title":"Project Structure Options","text":"<p>Choose based on your needs</p> Simple/FlatCompany/DomainOWA Recommended <p>Everything in one file - good for prototypes: <pre><code>my-plugin/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 plugin.py              # All code here\n\u2514\u2500\u2500 tests/\n</code></pre></p> pyproject.toml<pre><code>[project.entry-points.\"owa.env.plugins\"]\nmyplugin = \"plugin:plugin_spec\"\n</code></pre> <p>Integrate with existing code: <pre><code>acme-tools/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 acme/tools/\n\u2502   \u251c\u2500\u2500 core/\n\u2502   \u2514\u2500\u2500 owa_plugin.py       # Plugin spec\n\u2514\u2500\u2500 tests/\n</code></pre></p> pyproject.toml<pre><code>[project.entry-points.\"owa.env.plugins\"]\nacme_tools = \"acme.tools.owa_plugin:plugin_spec\"\n</code></pre> <p>Follow OWA conventions: <pre><code>owa-env-myplugin/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 owa/env/\n\u2502   \u251c\u2500\u2500 myplugin/           # Implementation\n\u2502   \u2514\u2500\u2500 plugins/myplugin.py # Plugin spec\n\u2514\u2500\u2500 tests/\n</code></pre></p> pyproject.toml<pre><code>[project.entry-points.\"owa.env.plugins\"]\nmyplugin = \"owa.env.plugins.myplugin:plugin_spec\"\n</code></pre>"},{"location":"env/custom_plugins/#best-practices","title":"Best Practices","text":""},{"location":"env/custom_plugins/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Namespace: <code>desktop</code>, <code>my_company</code> (lowercase, underscores)</li> <li>Components: <code>mouse.click</code>, <code>file.read</code> (dots for hierarchy)</li> <li>Package: <code>owa-env-yourplugin</code></li> </ul>"},{"location":"env/custom_plugins/#error-handling","title":"Error Handling","text":"<pre><code>def safe_function(param: str) -&gt; dict:\n    try:\n        result = do_work(param)\n        return {\"success\": True, \"data\": result}\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n</code></pre>"},{"location":"env/custom_plugins/#resource-management","title":"Resource Management","text":"<pre><code>class MyRunnable(Runnable):\n    def loop(self, *, stop_event):\n        try:\n            resource = acquire_resource()\n            while not stop_event.is_set():\n                use_resource(resource)\n                stop_event.wait(0.1)  # Small delay\n        finally:\n            release_resource(resource)\n</code></pre>"},{"location":"env/custom_plugins/#troubleshooting","title":"Troubleshooting","text":"<p>Common Issues and Solutions</p> \ud83d\udd0d Plugin Not Discovered\u274c Import Errors\ud83d\udeab Component Issues\ud83d\udd27 Quick Diagnostics <p>Symptoms: <code>owl env list</code> doesn't show your plugin</p> <p>Debug steps:</p> <ol> <li> <p>Verify installation:    <pre><code>pip list | grep your-plugin-name\n</code></pre></p> </li> <li> <p>Check entry points:    <pre><code>python -c \"\ntry:\n    from importlib.metadata import entry_points\nexcept ImportError:\n    from importlib_metadata import entry_points\n\neps = entry_points(group='owa.env.plugins')\nfor ep in eps:\n    print(f'{ep.name}: {ep.value}')\n\"\n</code></pre></p> </li> <li> <p>Test plugin spec import:    <pre><code>python -c \"from your.module.path import plugin_spec; print(plugin_spec.namespace)\"\n</code></pre></p> </li> </ol> <p>Common causes:</p> <ul> <li>Plugin not installed (<code>pip install -e .</code>)</li> <li>Entry point name conflicts with existing plugin</li> <li>Incorrect entry point path in <code>pyproject.toml</code></li> </ul> <p>Symptoms: Validation fails with import errors</p> <p>Debug command: <pre><code>owl env docs --validate yourplugin --output-format text\n</code></pre></p> <p>Common causes &amp; solutions:</p> Problem Solution Missing dependencies Add them to <code>pyproject.toml</code> dependencies Wrong import paths Check <code>module.path:object_name</code> format Circular imports Keep plugin spec separate from implementation Module not found Ensure module is importable after installation <p>\"Component not callable\" errors:</p> <pre><code># \u274c Wrong - points to module\n\"callables\": {\n    \"bad\": \"mymodule.utils\"\n}\n\n# \u2705 Correct - points to function\n\"callables\": {\n    \"good\": \"mymodule.utils:my_function\"\n}\n</code></pre> <p>Listener/Runnable doesn't work:</p> <pre><code># \u2705 Correct structure\nfrom owa.core import Listener\n\nclass MyListener(Listener):  # Must inherit\n    def on_configure(self, callback, **kwargs):  # Must implement\n        self.callback = callback\n        # Your setup code\n</code></pre> <p>Common issues:</p> <ul> <li>Not inheriting from <code>owa.core.Listener</code> or <code>owa.core.Runnable</code></li> <li>Missing <code>on_configure()</code> method</li> <li>Not calling <code>super().__init__()</code> in custom <code>__init__</code></li> </ul> <p>Run these commands to diagnose issues:</p> <pre><code># Check if OWA can see your plugin\nowl env list yourplugin\n\n# Validate plugin specification\nowl env docs --validate yourplugin --strict\n\n# Check for namespace conflicts\nowl env stats --namespaces\n\n# Test component loading manually\npython -c \"\nfrom owa.core import CALLABLES, LISTENERS, RUNNABLES\nprint('Available namespaces:')\nnamespaces = set()\nfor key in list(CALLABLES.keys()) + list(LISTENERS.keys()) + list(RUNNABLES.keys()):\n    namespaces.add(key.split('/')[0])\nfor ns in sorted(namespaces):\n    print(f'  - {ns}')\n\"\n</code></pre> <p>Still having issues?</p> <ul> <li>Check the OWA GitHub Issues</li> <li>Look at working examples in <code>projects/owa-env-*</code></li> <li>Ensure you're using compatible versions of dependencies</li> </ul>"},{"location":"env/custom_plugins/#publishing","title":"Publishing","text":"<p>PyPI (Recommended): <pre><code>uv build\nuv publish\n</code></pre></p> <p>GitHub/Git: <pre><code>pip install git+https://github.com/user/owa-env-plugin.git\n</code></pre></p> <p>Local Development: <pre><code>pip install -e /path/to/plugin\n</code></pre></p>"},{"location":"env/custom_plugins/#next-steps","title":"Next Steps","text":"Topic Description Environment Guide Complete system overview and advanced usage patterns Built-in Plugins Learn from standard, desktop, and GStreamer implementations CLI Tools Plugin management and exploration commands"},{"location":"env/guide/","title":"Environment Guide","text":""},{"location":"env/guide/#component-types","title":"Component Types","text":"<p>OWA's Environment provides three types of components for building real-time agents:</p> <p>Component Overview</p> CallablesListenersRunnables <p>Direct function calls - Invoke immediately for actions or state <pre><code>CALLABLES[\"std/time_ns\"]()  # Get current time\nCALLABLES[\"desktop/mouse.click\"](\"left\", 2)  # Double-click\n</code></pre></p> <p>Event monitoring - Respond to events with callbacks <pre><code>def on_event(data):\n    print(f\"Event: {data}\")\n\nlistener = LISTENERS[\"desktop/keyboard\"]().configure(callback=on_event)\nwith listener.session:\n    input(\"Press Enter to stop...\")\n</code></pre></p> <p>Background processes - Long-running tasks with start/stop control <pre><code>process = RUNNABLES[\"gst/screen_capture\"]().configure(fps=60)\nwith process.session:\n    frame = process.grab()\n</code></pre></p> <p>Component Relationships</p> <p>Who initiates the action:</p> <ul> <li>Callable: You actively call the function</li> <li>Listener: The system calls your callback when events occur (inherits from Runnable)</li> <li>Runnable: Base class for background processes</li> </ul> <p>Traditional frameworks like gymnasium.Env only provide Callable-style interfaces.</p>"},{"location":"env/guide/#registry-system","title":"Registry System","text":"<p>Components are automatically discovered and registered when plugins are installed:</p> <pre><code>from owa.core import CALLABLES, LISTENERS, RUNNABLES\n# All installed plugins automatically available\n</code></pre> <p>Key Features:</p> <ul> <li>Zero Configuration: Automatic discovery via Python Entry Points</li> <li>Unified Naming: All components use <code>namespace/name</code> pattern</li> <li>Immediate Availability: Components ready after <code>pip install</code></li> </ul>"},{"location":"env/guide/#usage-examples","title":"Usage Examples","text":""},{"location":"env/guide/#basic-usage","title":"Basic Usage","text":"Time &amp; SchedulingDesktop AutomationHigh-Performance Capture <pre><code>from owa.core import CALLABLES, LISTENERS\nimport time\n\n# Get current time\ncurrent_time = CALLABLES[\"std/time_ns\"]()\nprint(f\"Current time: {current_time}\")\n\n# Periodic callback using context manager\ndef on_tick():\n    print(f\"Tick: {CALLABLES['std/time_ns']()}\")\n\ntick = LISTENERS[\"std/tick\"]().configure(callback=on_tick, interval=1)\nwith tick.session:\n    time.sleep(3)  # Prints time every second for 3 seconds\n</code></pre> <pre><code>from owa.core import CALLABLES, LISTENERS\nfrom owa.msgs.desktop.keyboard import KeyboardEvent\n\n# Screen capture and window management\nscreen = CALLABLES['desktop/screen.capture']()\nprint(f\"Screen size: {screen.shape}\")\n\nactive_window = CALLABLES['desktop/window.get_active_window']()\nprint(f\"Active window: {active_window}\")\n\n# Mouse control\nCALLABLES[\"desktop/mouse.click\"](\"left\", 2)  # Double-click\n\n# Keyboard monitoring\ndef on_key(event: KeyboardEvent):\n    print(f\"Key {event.event_type}: {event.vk}\")\n\nwith LISTENERS[\"desktop/keyboard\"]().configure(callback=on_key).session:\n    input(\"Press Enter to stop monitoring...\")\n</code></pre> <pre><code>from owa.core import RUNNABLES\nimport cv2\n\n# Real-time screen capture with GStreamer\ndef process_frame(frame):\n    cv2.imshow(\"Screen\", frame.frame_arr)\n    cv2.waitKey(1)\n\nscreen = LISTENERS[\"gst/screen\"]().configure(\n    callback=process_frame,\n    fps=60,\n    show_cursor=True\n)\n\nwith screen.session:\n    input(\"Press Enter to stop capture...\")\n</code></pre>"},{"location":"env/guide/#custom-plugin-development","title":"Custom Plugin Development","text":"<p>Create your own plugins for automatic discovery:</p> <pre><code># pyproject.toml\n[project.entry-points.\"owa.env.plugins\"]\nmyplugin = \"owa.env.myplugin:plugin_spec\"\n\n# Plugin specification\nfrom owa.core.plugin_spec import PluginSpec\n\nplugin_spec = PluginSpec(\n    namespace=\"myplugin\",\n    version=\"0.1.0\",\n    description=\"My custom plugin\",\n    components={\n        \"callables\": {\"add\": \"owa.env.myplugin:add_function\"},\n        \"listeners\": {\"events\": \"owa.env.myplugin:EventListener\"}\n    }\n)\n\n# Usage (automatically available after pip install)\nresult = CALLABLES[\"myplugin/add\"](5, 3)  # Returns 8\n</code></pre> <p>Plugin Development</p> <p>See Custom Plugins Guide for detailed plugin creation instructions.</p>"},{"location":"env/guide/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Plugin Installation\"\n        PI[pip install owa-env-*]\n        EP[Python Entry Points]\n    end\n\n    subgraph \"Plugin Discovery\"\n        STD[owa.env.std]\n        DESK[owa.env.desktop]\n        GST[owa.env.gst]\n        MSGS[owa-msgs]\n    end\n\n    subgraph \"Component Registry\"\n        CMPTS[CALLABLES, LISTENERS, RUNNABLES]\n        MSG[MESSAGES]\n    end\n\n    subgraph \"User Application\"\n        APP[Your Agent Code]\n    end\n\n    PI --&gt; EP\n    EP --&gt; STD\n    EP --&gt; DESK\n    EP --&gt; GST\n    EP --&gt; MSGS\n\n    STD --&gt; CMPTS\n    DESK --&gt; CMPTS\n    GST --&gt; CMPTS\n    MSGS --&gt; MSG\n\n    CMPTS --&gt; APP\n    MSG --&gt; APP</code></pre>"},{"location":"env/guide/#cli-tools","title":"CLI Tools","text":"<p>Explore and manage plugins with the <code>owl env</code> command:</p> <p>Essential Commands</p> Plugin DiscoveryPlugin DevelopmentExample Output <pre><code># List all plugins\nowl env list\n\n# Show specific plugin details\nowl env list desktop\n\n# Search for components\nowl env search mouse\n</code></pre> <pre><code># Validate plugin specification\nowl env validate ./plugin.yaml\n\n# Check documentation quality\nowl env docs --validate\n\n# View ecosystem statistics\nowl env stats --namespaces\n</code></pre> <pre><code>$ owl env list\n\ud83d\udce6 Discovered Plugins (4)\n\u251c\u2500\u2500 desktop (25 components)\n\u251c\u2500\u2500 gst (4 components)\n\u251c\u2500\u2500 std (2 components)\n\u2514\u2500\u2500 example (6 components)\n\n$ owl env search mouse --table\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Component               \u2503 Type      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 desktop/mouse           \u2502 listeners \u2502\n\u2502 desktop/mouse.click     \u2502 callables \u2502\n\u2502 desktop/mouse.move      \u2502 callables \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Complete CLI Reference</p> <p>For detailed command options and examples, see CLI Environment Commands</p>"},{"location":"env/guide/#message-registry","title":"Message Registry","text":"<p>OWA provides centralized message definitions with automatic discovery:</p> <pre><code>from owa.core import MESSAGES\n\n# Access message classes\nKeyboardEvent = MESSAGES['desktop/KeyboardEvent']\nMouseEvent = MESSAGES['desktop/MouseEvent']\n\n# Create instances\nevent = KeyboardEvent(event_type=\"press\", vk=65, timestamp=1234567890)\n</code></pre> <p>Message Naming: <code>domain/MessageType</code> (e.g., <code>desktop/KeyboardEvent</code>)</p> <p>Core Message Types:</p> Type Description <code>desktop/KeyboardEvent</code> Keyboard press/release events <code>desktop/MouseEvent</code> Mouse movement, clicks, scrolls <code>desktop/ScreenCaptured</code> Screen capture frames <code>desktop/WindowInfo</code> Window information <p>Custom Messages: Register via entry points in <code>pyproject.toml</code>: <pre><code>[project.entry-points.\"owa.msgs\"]\n\"sensors/TemperatureReading\" = \"custom_sensors.messages:TemperatureReading\"\n</code></pre></p> <p>Message Tools &amp; Development</p> <ul> <li>CLI Tools: Use <code>owl messages</code> commands for message management. See CLI Reference</li> <li>Custom Messages: For detailed guidance on creating custom message types, see Custom Messages Guide</li> </ul>"},{"location":"env/guide/#next-steps","title":"Next Steps","text":"Topic Description Plugin Development Create your own environment extensions Built-in Plugins Explore standard, desktop, and GStreamer plugins CLI Tools Complete command reference"},{"location":"env/plugins/desktop/","title":"Desktop Environment","text":"<p>Mouse, keyboard, window control, and screen capture for desktop automation.</p> <p>Installation</p> <pre><code>pip install owa-env-desktop\n</code></pre>"},{"location":"env/plugins/desktop/#components","title":"Components","text":"Category Component Type Description Mouse <code>desktop/mouse.click</code> Callable Simulate mouse clicks <code>desktop/mouse.move</code> Callable Move cursor to coordinates <code>desktop/mouse.position</code> Callable Get current mouse position <code>desktop/mouse.press</code> Callable Press mouse button <code>desktop/mouse.release</code> Callable Release mouse button <code>desktop/mouse.scroll</code> Callable Simulate mouse wheel scrolling <code>desktop/mouse.get_state</code> Callable Get current mouse position and buttons <code>desktop/mouse.get_pointer_ballistics_config</code> Callable Get Windows pointer ballistics settings <code>desktop/mouse</code> Listener Monitor mouse events <code>desktop/mouse_state</code> Listener Monitor mouse state changes <code>desktop/raw_mouse</code> Listener Raw mouse input (bypasses acceleration) Keyboard <code>desktop/keyboard.press</code> Callable Press/release keys <code>desktop/keyboard.type</code> Callable Type text strings <code>desktop/keyboard.press_repeat</code> Callable Simulate key auto-repeat <code>desktop/keyboard.get_keyboard_repeat_timing</code> Callable Get Windows keyboard repeat timing <code>desktop/keyboard</code> Listener Monitor keyboard events <code>desktop/keyboard_state</code> Listener Monitor keyboard state changes Screen <code>desktop/screen.capture</code> Callable Capture screen (basic) Window <code>desktop/window.get_active_window</code> Callable Get active window info <code>desktop/window.get_window_by_title</code> Callable Find window by title <code>desktop/window.get_pid_by_title</code> Callable Get process ID by window title <code>desktop/window.when_active</code> Callable Wait until window becomes active <code>desktop/window.is_active</code> Callable Check if window is active <code>desktop/window.make_active</code> Callable Activate/focus window <code>desktop/window</code> Listener Monitor window events <p>Performance Note</p> <p>For high-performance screen capture, use GStreamer Environment instead (6x faster).</p>"},{"location":"env/plugins/desktop/#usage-examples","title":"Usage Examples","text":"Mouse ControlKeyboard ControlEvent MonitoringWindow Management <pre><code>from owa.core import CALLABLES\n\n# Click and move\nCALLABLES[\"desktop/mouse.click\"](\"left\", 2)  # Double-click\nCALLABLES[\"desktop/mouse.move\"](100, 200)\n\n# Get position\nx, y = CALLABLES[\"desktop/mouse.position\"]()\nprint(f\"Mouse at: {x}, {y}\")\n</code></pre> <pre><code>from owa.core import CALLABLES\n\n# Type text\nCALLABLES[\"desktop/keyboard.type\"](\"Hello World!\")\n\n# Press keys\nCALLABLES[\"desktop/keyboard.press\"](\"ctrl+c\")\n\n# Auto-repeat (hold key)\nCALLABLES[\"desktop/keyboard.press_repeat\"](\"space\", press_time=2.0)\n</code></pre> <pre><code>from owa.core import LISTENERS\nfrom owa.msgs.desktop.keyboard import KeyboardEvent\n\ndef on_key(event: KeyboardEvent):\n    print(f\"Key {event.event_type}: {event.vk}\")\n\ndef on_mouse(event):\n    print(f\"Mouse: {event.event_type} at {event.x}, {event.y}\")\n\n# Monitor events\nwith LISTENERS[\"desktop/keyboard\"]().configure(callback=on_key).session:\n    with LISTENERS[\"desktop/mouse\"]().configure(callback=on_mouse).session:\n        input(\"Press Enter to stop monitoring...\")\n</code></pre> <pre><code>from owa.core import CALLABLES\n\n# Get window information\nactive = CALLABLES[\"desktop/window.get_active_window\"]()\nprint(f\"Active window: {active}\")\n\n# Find specific window\nwindow = CALLABLES[\"desktop/window.get_window_by_title\"](\"Notepad\")\nif window:\n    print(f\"Found Notepad: {window}\")\n</code></pre>"},{"location":"env/plugins/desktop/#technical-details","title":"Technical Details","text":""},{"location":"env/plugins/desktop/#library-selection-rationale","title":"Library Selection Rationale","text":"<p>This module utilizes <code>pynput</code> for input simulation after evaluating several alternatives:</p> <ul> <li> <p>Why not PyAutoGUI? Though widely used, PyAutoGUI uses deprecated Windows APIs (<code>keybd_event/mouse_event</code>) rather than the modern <code>SendInput</code> method. These older APIs fail in DirectX applications and games. Additionally, PyAutoGUI has seen limited maintenance (last significant update was over 2 years ago).</p> </li> <li> <p>Alternative Solutions: Libraries like pydirectinput and pydirectinput_rgx address the Windows API issue by using <code>SendInput</code>, but they lack input capturing capabilities which are essential for our use case.</p> </li> <li> <p>Other Options: We also evaluated keyboard and mouse libraries but found them inadequately maintained with several unresolved bugs that could impact reliability.</p> </li> </ul>"},{"location":"env/plugins/desktop/#raw-mouse-input","title":"Raw Mouse Input","text":"<p>Raw mouse input capture is available to separate mouse position movement from game's center-locking and from user interactions. This enables access to unfiltered mouse movement data directly from the hardware, bypassing Windows pointer acceleration and game cursor manipulation.</p>"},{"location":"env/plugins/desktop/#key-auto-repeat-functionality","title":"Key Auto-Repeat Functionality","text":"<p>Key auto-repeat is a Windows feature where holding down a key generates multiple key events after an initial delay. When a user presses and holds a key, Windows first waits for the repeat delay period, then generates repeated <code>WM_KEYDOWN</code> messages at intervals determined by the repeat rate.</p>"},{"location":"env/plugins/desktop/#how-windows-auto-repeat-works","title":"How Windows Auto-Repeat Works","text":"<ol> <li>Initial Key Press: First <code>WM_KEYDOWN</code> message is sent immediately with repeat count = 1</li> <li>Repeat Delay: System waits for the configured delay (typically 250-1000ms)</li> <li>Repeated Events: Additional <code>WM_KEYDOWN</code> messages are sent at the repeat rate interval (typically 30ms)</li> <li>Repeat Count: Each repeated message includes an incremented repeat count in the message parameters</li> </ol> <p>System Configuration: Windows allows users to configure auto-repeat behavior through: - Repeat Delay: Time before auto-repeat begins (0-3 scale, maps to 250ms-1000ms, default: 500ms) - Repeat Rate: Frequency of repeated characters (0-31 scale, maps to ~30ms-500ms intervals, default: 30ms)</p> <p>These settings can be accessed programmatically via <code>SystemParametersInfo</code> with <code>SPI_GETKEYBOARDDELAY</code> and <code>SPI_GETKEYBOARDSPEED</code> parameters.</p> <p>References: - Keyboard Repeat Delay and Repeat Rate - Microsoft documentation on keyboard repeat behavior - SystemParametersInfo Function - Windows API for keyboard repeat parameters</p>"},{"location":"env/plugins/desktop/#using-owas-press_repeat-function","title":"Using OWA's press_repeat Function","text":"<p>For simulating key auto-repeat behavior, use the dedicated function:</p> <pre><code>CALLABLES[\"desktop/keyboard.press_repeat\"](key, press_time: float, initial_delay: float = 0.5, repeat_delay: float = 0.033)\n</code></pre> <p>Parameters: - <code>key</code>: The key to press and repeat - <code>press_time</code>: Total duration to hold the key (seconds) - <code>initial_delay</code>: Time before repeating starts (default: 0.5s, matches Windows default) - <code>repeat_delay</code>: Interval between repeated keypresses (default: 0.033s \u2248 30ms, matches Windows default)</p>"},{"location":"env/plugins/desktop/#differences-from-true-windows-auto-repeat","title":"Differences from True Windows Auto-Repeat","text":"<p>The <code>press_repeat</code> function approximates Windows auto-repeat behavior but isn't identical:</p> <p>OS Auto-Repeat vs OWA Implementation: - OS Auto-Repeat: <code>WM_KEYDOWN</code> messages include repeat flag (bit 30) and repeat count - OWA Implementation: Multiple <code>WM_KEYDOWN</code> messages without repeat flags (each appears as individual key press)</p> <p>The difference is small and commonly ignored by applications, making this approach effective for most automation scenarios.</p> <p>Why the difference exists: Windows provides repeat detection through <code>WM_KEYDOWN</code> message parameters, but pynput does not expose these Windows-specific details. Since the primary use case is triggering repeat behavior rather than detecting it, this limitation doesn't affect the functionality.</p> <p>Reference: WM_KEYDOWN Message - Official Windows documentation for key press events and message parameters</p>"},{"location":"env/plugins/desktop/#technical-details-windows-repeat-count-behavior","title":"Technical Details: Windows Repeat Count Behavior","text":"<p>The <code>WM_KEYDOWN</code> repeat count (bits 0-15) behaves differently than many developers expect:</p> <ul> <li>Not cumulative: Each message contains the repeat count since the last processed <code>WM_KEYDOWN</code>, not a running total</li> <li>Usually 1: In typical applications with fast message processing, the repeat count is almost always 1</li> <li>Higher values possible: Only occurs when message processing is slow enough for multiple repeats to queue up</li> </ul> <p>Example: If you hold a key and your message loop processes messages quickly, you'll receive multiple <code>WM_KEYDOWN</code> messages each with repeat count = 1. Only when processing is delayed (e.g., by adding <code>Sleep(1000)</code> in the handler) will you see higher repeat counts like 20-30.</p> <p>This design allows responsive applications to process key events immediately rather than waiting for the key release.</p> <p>Reference: WM_KEYDOWN repeat count behavior explained - Stack Overflow discussion with practical examples</p> <p>Implementation</p> <p>See owa-env-desktop source for detailed implementation.</p>"},{"location":"env/plugins/desktop/#api-reference","title":"API Reference","text":""},{"location":"env/plugins/desktop/#desktop","title":"desktop plugin 0.6.0","text":"<p>Desktop environment plugin with mouse, keyboard, and window control</p> <p>Author: OWA Development Team</p>"},{"location":"env/plugins/desktop/#desktop-callables","title":"Callables","text":"<p>Usage: To use callable components, import <code>CALLABLES</code> from <code>owa.core</code> and access them by their component name:</p> <pre><code>from owa.core import CALLABLES\n\n# Access a callable component (replace 'component_name' with actual name)\ncallable_func = CALLABLES[\"desktop/component_name\"]\nresult = callable_func(your_arguments)</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.screen.callables.capture_screen","title":"screen.capture","text":"<pre><code>capture_screen() -&gt; ndarray\n</code></pre> <p>Capture the current screen as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Screen capture as BGR image array with shape (height, width, 3).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; screen = capture_screen()\n&gt;&gt;&gt; print(f\"Screen dimensions: {screen.shape}\")  # e.g., (1080, 1920, 3)\n&gt;&gt;&gt; # Save to file: cv2.imwrite('screenshot.png', screen)\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/screen/callables.py</code> <pre><code>def capture_screen() -&gt; np.ndarray:\n    \"\"\"\n    Capture the current screen as a numpy array.\n\n    Returns:\n        numpy.ndarray: Screen capture as BGR image array with shape (height, width, 3).\n\n    Examples:\n        &gt;&gt;&gt; screen = capture_screen()\n        &gt;&gt;&gt; print(f\"Screen dimensions: {screen.shape}\")  # e.g., (1080, 1920, 3)\n        &gt;&gt;&gt; # Save to file: cv2.imwrite('screenshot.png', screen)\n    \"\"\"\n    import bettercam\n\n    camera = bettercam.create()\n    return camera.grab()\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.click","title":"mouse.click","text":"<pre><code>click(button: str | Button, count: int) -&gt; None\n</code></pre> <p>Simulate a mouse click.</p> <p>Parameters:</p> Name Type Description Default <code>button</code> <code>str | Button</code> <p>Mouse button to click. Can be \"left\", \"middle\", \"right\" or a Button enum.</p> required <code>count</code> <code>int</code> <p>Number of clicks to perform.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; click(\"left\", 1)  # Single left click\n&gt;&gt;&gt; click(\"right\", 2)  # Double right click\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def click(button: str | Button, count: int) -&gt; None:\n    \"\"\"\n    Simulate a mouse click.\n\n    Args:\n        button: Mouse button to click. Can be \"left\", \"middle\", \"right\" or a Button enum.\n        count: Number of clicks to perform.\n\n    Examples:\n        &gt;&gt;&gt; click(\"left\", 1)  # Single left click\n        &gt;&gt;&gt; click(\"right\", 2)  # Double right click\n    \"\"\"\n    if button in (\"left\", \"middle\", \"right\"):\n        button = getattr(Button, button)\n    return mouse_controller.click(button, count)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.mouse_move","title":"mouse.move","text":"<pre><code>mouse_move(x: int, y: int) -&gt; None\n</code></pre> <p>Move the mouse cursor to specified coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>X coordinate to move to.</p> required <code>y</code> <code>int</code> <p>Y coordinate to move to.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; mouse_move(100, 200)  # Move mouse to position (100, 200)\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def mouse_move(x: int, y: int) -&gt; None:\n    \"\"\"\n    Move the mouse cursor to specified coordinates.\n\n    Args:\n        x: X coordinate to move to.\n        y: Y coordinate to move to.\n\n    Examples:\n        &gt;&gt;&gt; mouse_move(100, 200)  # Move mouse to position (100, 200)\n    \"\"\"\n    return mouse_controller.move(x, y)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.mouse_position","title":"mouse.position","text":"<pre><code>mouse_position() -&gt; tuple[int, int]\n</code></pre> <p>Get the current mouse cursor position.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (x, y) coordinates of the mouse cursor.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x, y = mouse_position()\n&gt;&gt;&gt; print(f\"Mouse is at ({x}, {y})\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def mouse_position() -&gt; tuple[int, int]:\n    \"\"\"\n    Get the current mouse cursor position.\n\n    Returns:\n        Tuple of (x, y) coordinates of the mouse cursor.\n\n    Examples:\n        &gt;&gt;&gt; x, y = mouse_position()\n        &gt;&gt;&gt; print(f\"Mouse is at ({x}, {y})\")\n    \"\"\"\n    return mouse_controller.position\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.mouse_press","title":"mouse.press","text":"<pre><code>mouse_press(button: str | Button) -&gt; None\n</code></pre> <p>Press and hold a mouse button.</p> <p>Parameters:</p> Name Type Description Default <code>button</code> <code>str | Button</code> <p>Mouse button to press. Can be \"left\", \"middle\", \"right\" or a Button enum.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; mouse_press(\"left\")  # Press and hold left mouse button\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def mouse_press(button: str | Button) -&gt; None:\n    \"\"\"\n    Press and hold a mouse button.\n\n    Args:\n        button: Mouse button to press. Can be \"left\", \"middle\", \"right\" or a Button enum.\n\n    Examples:\n        &gt;&gt;&gt; mouse_press(\"left\")  # Press and hold left mouse button\n    \"\"\"\n    return mouse_controller.press(button)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.mouse_release","title":"mouse.release","text":"<pre><code>mouse_release(button: str | Button) -&gt; None\n</code></pre> <p>Release a previously pressed mouse button.</p> <p>Parameters:</p> Name Type Description Default <code>button</code> <code>str | Button</code> <p>Mouse button to release. Can be \"left\", \"middle\", \"right\" or a Button enum.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; mouse_release(\"left\")  # Release left mouse button\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def mouse_release(button: str | Button) -&gt; None:\n    \"\"\"\n    Release a previously pressed mouse button.\n\n    Args:\n        button: Mouse button to release. Can be \"left\", \"middle\", \"right\" or a Button enum.\n\n    Examples:\n        &gt;&gt;&gt; mouse_release(\"left\")  # Release left mouse button\n    \"\"\"\n    return mouse_controller.release(button)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.mouse_scroll","title":"mouse.scroll","text":"<pre><code>mouse_scroll(x: int, y: int, dx: int, dy: int) -&gt; None\n</code></pre> <p>Simulate mouse wheel scrolling.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>X coordinate where scrolling occurs.</p> required <code>y</code> <code>int</code> <p>Y coordinate where scrolling occurs.</p> required <code>dx</code> <code>int</code> <p>Horizontal scroll amount.</p> required <code>dy</code> <code>int</code> <p>Vertical scroll amount.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; mouse_scroll(100, 100, 0, 3)  # Scroll up 3 units at position (100, 100)\n&gt;&gt;&gt; mouse_scroll(100, 100, 0, -3)  # Scroll down 3 units\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def mouse_scroll(x: int, y: int, dx: int, dy: int) -&gt; None:\n    \"\"\"\n    Simulate mouse wheel scrolling.\n\n    Args:\n        x: X coordinate where scrolling occurs.\n        y: Y coordinate where scrolling occurs.\n        dx: Horizontal scroll amount.\n        dy: Vertical scroll amount.\n\n    Examples:\n        &gt;&gt;&gt; mouse_scroll(100, 100, 0, 3)  # Scroll up 3 units at position (100, 100)\n        &gt;&gt;&gt; mouse_scroll(100, 100, 0, -3)  # Scroll down 3 units\n    \"\"\"\n    return mouse_controller.scroll(x, y, dx, dy)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.get_mouse_state","title":"mouse.get_state","text":"<pre><code>get_mouse_state() -&gt; MouseState\n</code></pre> <p>Get the current mouse state including position and pressed buttons.</p> <p>Returns:</p> Type Description <code>MouseState</code> <p>MouseState object containing current mouse position and pressed buttons.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state = get_mouse_state()\n&gt;&gt;&gt; print(f\"Mouse at ({state.x}, {state.y}), buttons: {state.buttons}\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def get_mouse_state() -&gt; MouseState:\n    \"\"\"\n    Get the current mouse state including position and pressed buttons.\n\n    Returns:\n        MouseState object containing current mouse position and pressed buttons.\n\n    Examples:\n        &gt;&gt;&gt; state = get_mouse_state()\n        &gt;&gt;&gt; print(f\"Mouse at ({state.x}, {state.y}), buttons: {state.buttons}\")\n    \"\"\"\n    position = mouse_controller.position\n    if position is None:\n        position = (-1, -1)  # Fallback if position cannot be retrieved\n    mouse_buttons = set()\n    buttons = get_vk_state()\n    for button, vk in {\"left\": 1, \"right\": 2, \"middle\": 4}.items():\n        if vk in buttons:\n            mouse_buttons.add(button)\n    return MouseState(x=position[0], y=position[1], buttons=mouse_buttons)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.get_pointer_ballistics_config","title":"mouse.get_pointer_ballistics_config","text":"<pre><code>get_pointer_ballistics_config() -&gt; PointerBallisticsConfig\n</code></pre> <p>Get Windows pointer ballistics configuration for WM_MOUSEMOVE reconstruction.</p> <p>Examples:</p>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.get_pointer_ballistics_config--check-whether-enhance-pointer-precision-is-enabled","title":"Check whether Enhance pointer precision is enabled","text":"<pre><code>&gt;&gt;&gt; is_mouse_acceleration_enabled = get_pointer_ballistics_config().mouse_speed\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def get_pointer_ballistics_config() -&gt; PointerBallisticsConfig:\n    \"\"\"Get Windows pointer ballistics configuration for WM_MOUSEMOVE reconstruction.\n\n    Examples:\n        # Check whether Enhance pointer precision is enabled\n        &gt;&gt;&gt; is_mouse_acceleration_enabled = get_pointer_ballistics_config().mouse_speed\n    \"\"\"\n    if sys.platform != \"win32\":\n        return PointerBallisticsConfig()  # Return default values\n\n    try:\n        return PointerBallisticsConfig(**_get_mouse_registry_values())\n    except Exception:\n        return PointerBallisticsConfig()  # Return default values\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.press","title":"keyboard.press","text":"<pre><code>press(key: str | int) -&gt; None\n</code></pre> <p>Press and hold a keyboard key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Key to press. Can be a string (e.g., 'a', 'enter') or virtual key code.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; press('a')  # Press and hold the 'a' key\n&gt;&gt;&gt; press(65)  # Press and hold the 'a' key using virtual key code\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def press(key: str | int) -&gt; None:\n    \"\"\"\n    Press and hold a keyboard key.\n\n    Args:\n        key: Key to press. Can be a string (e.g., 'a', 'enter') or virtual key code.\n\n    Examples:\n        &gt;&gt;&gt; press('a')  # Press and hold the 'a' key\n        &gt;&gt;&gt; press(65)  # Press and hold the 'a' key using virtual key code\n    \"\"\"\n    key = vk_to_keycode(key) if isinstance(key, int) else key\n    return keyboard_controller.press(key)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.release","title":"keyboard.release","text":"<pre><code>release(key: str | int) -&gt; None\n</code></pre> <p>Release a previously pressed keyboard key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Key to release. Can be a string (e.g., 'a', 'enter') or virtual key code.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; release('a')  # Release the 'a' key\n&gt;&gt;&gt; release(65)  # Release the 'a' key using virtual key code\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def release(key: str | int) -&gt; None:\n    \"\"\"\n    Release a previously pressed keyboard key.\n\n    Args:\n        key: Key to release. Can be a string (e.g., 'a', 'enter') or virtual key code.\n\n    Examples:\n        &gt;&gt;&gt; release('a')  # Release the 'a' key\n        &gt;&gt;&gt; release(65)  # Release the 'a' key using virtual key code\n    \"\"\"\n    key = vk_to_keycode(key) if isinstance(key, int) else key\n    return keyboard_controller.release(key)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.keyboard_type","title":"keyboard.type","text":"<pre><code>keyboard_type(text: str) -&gt; None\n</code></pre> <p>Type a string of characters.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text string to type.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; keyboard_type(\"Hello, World!\")  # Types the text\n&gt;&gt;&gt; keyboard_type(\"user@example.com\")  # Types an email address\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def keyboard_type(text: str) -&gt; None:\n    \"\"\"\n    Type a string of characters.\n\n    Args:\n        text: Text string to type.\n\n    Examples:\n        &gt;&gt;&gt; keyboard_type(\"Hello, World!\")  # Types the text\n        &gt;&gt;&gt; keyboard_type(\"user@example.com\")  # Types an email address\n    \"\"\"\n    return keyboard_controller.type(text)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.get_keyboard_state","title":"keyboard.get_state","text":"<pre><code>get_keyboard_state() -&gt; KeyboardState\n</code></pre> <p>Get the current keyboard state including pressed keys.</p> <p>Returns:</p> Type Description <code>KeyboardState</code> <p>KeyboardState object containing currently pressed keys.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state = get_keyboard_state()\n&gt;&gt;&gt; print(f\"Pressed keys: {state.buttons}\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def get_keyboard_state() -&gt; KeyboardState:\n    \"\"\"\n    Get the current keyboard state including pressed keys.\n\n    Returns:\n        KeyboardState object containing currently pressed keys.\n\n    Examples:\n        &gt;&gt;&gt; state = get_keyboard_state()\n        &gt;&gt;&gt; print(f\"Pressed keys: {state.buttons}\")\n    \"\"\"\n    return KeyboardState(buttons=get_vk_state())\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.press_repeat_key","title":"keyboard.press_repeat","text":"<pre><code>press_repeat_key(\n    key: str | int,\n    press_time: float,\n    initial_delay: float = 0.5,\n    repeat_delay: float = 0.033,\n) -&gt; None\n</code></pre> <p>Simulate the behavior of holding a key down with auto-repeat.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | int</code> <p>Key to press repeatedly. Can be a string or virtual key code.</p> required <code>press_time</code> <code>float</code> <p>Total time to hold the key down in seconds.</p> required <code>initial_delay</code> <code>float</code> <p>Initial delay before auto-repeat starts (default: 0.5s).</p> <code>0.5</code> <code>repeat_delay</code> <code>float</code> <p>Delay between repeated key presses (default: 0.033s).</p> <code>0.033</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; press_repeat_key('a', 2.0)  # Hold 'a' key for 2 seconds with auto-repeat\n&gt;&gt;&gt; press_repeat_key('space', 1.5, 0.3, 0.05)  # Custom timing for space key\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def press_repeat_key(\n    key: str | int, press_time: float, initial_delay: float = 0.5, repeat_delay: float = 0.033\n) -&gt; None:\n    \"\"\"\n    Simulate the behavior of holding a key down with auto-repeat.\n\n    Args:\n        key: Key to press repeatedly. Can be a string or virtual key code.\n        press_time: Total time to hold the key down in seconds.\n        initial_delay: Initial delay before auto-repeat starts (default: 0.5s).\n        repeat_delay: Delay between repeated key presses (default: 0.033s).\n\n    Examples:\n        &gt;&gt;&gt; press_repeat_key('a', 2.0)  # Hold 'a' key for 2 seconds with auto-repeat\n        &gt;&gt;&gt; press_repeat_key('space', 1.5, 0.3, 0.05)  # Custom timing for space key\n    \"\"\"\n    key = vk_to_keycode(key) if isinstance(key, int) else key\n    repeat_time = max(0, (press_time - initial_delay) // repeat_delay - 1)\n\n    keyboard_controller.press(key)\n    time.sleep(initial_delay)\n    for _ in range(int(repeat_time)):\n        keyboard_controller.press(key)\n        time.sleep(repeat_delay)\n    keyboard_controller.release(key)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.release_all_keys","title":"keyboard.release_all_keys","text":"<pre><code>release_all_keys() -&gt; None\n</code></pre> <p>Release all currently pressed keys on the keyboard.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; release_all_keys()  # Release all pressed keys\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def release_all_keys() -&gt; None:\n    \"\"\"\n    Release all currently pressed keys on the keyboard.\n\n    Examples:\n        &gt;&gt;&gt; release_all_keys()  # Release all pressed keys\n    \"\"\"\n    keyboard_state: KeyboardState = get_keyboard_state()\n    for key in keyboard_state.buttons:\n        release(key)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.callables.get_keyboard_repeat_timing","title":"keyboard.get_keyboard_repeat_timing","text":"<pre><code>get_keyboard_repeat_timing(\n    *, return_seconds: Literal[True] = True\n) -&gt; Dict[str, float]\n</code></pre><pre><code>get_keyboard_repeat_timing(\n    *, return_seconds: Literal[False]\n) -&gt; Dict[str, int]\n</code></pre> <pre><code>get_keyboard_repeat_timing(\n    *, return_seconds: bool = True\n) -&gt; Dict[str, float] | Dict[str, int]\n</code></pre> <p>Get Windows keyboard repeat delay and repeat rate settings.</p> <p>Parameters:</p> Name Type Description Default <code>return_seconds</code> <code>bool</code> <p>If True (default), return timing values in seconds.            If False, return raw Windows API values.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, float] | Dict[str, int]</code> <p>When return_seconds=True: Dict[str, float]: Dictionary with timing in seconds     - keyboard_delay_seconds: Initial delay before auto-repeat starts     - keyboard_rate_seconds: Interval between repeated keystrokes</p> <code>Dict[str, float] | Dict[str, int]</code> <p>When return_seconds=False: Dict[str, int]: Dictionary with raw Windows API values     - keyboard_delay: Raw delay value (0-3 scale)     - keyboard_speed: Raw speed value (0-31 scale)</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If not running on Windows platform</p> <code>RuntimeError</code> <p>If Windows API call fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get timing in seconds (default)\n&gt;&gt;&gt; timing = get_keyboard_repeat_timing()\n&gt;&gt;&gt; print(f\"Delay: {timing['keyboard_delay_seconds']:.3f}s, Rate: {timing['keyboard_rate_seconds']:.3f}s\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Get raw Windows API values\n&gt;&gt;&gt; raw_timing = get_keyboard_repeat_timing(return_seconds=False)\n&gt;&gt;&gt; print(f\"Raw delay: {raw_timing['keyboard_delay']}, Raw speed: {raw_timing['keyboard_speed']}\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/callables.py</code> <pre><code>def get_keyboard_repeat_timing(*, return_seconds: bool = True) -&gt; Dict[str, float] | Dict[str, int]:\n    \"\"\"\n    Get Windows keyboard repeat delay and repeat rate settings.\n\n    Args:\n        return_seconds: If True (default), return timing values in seconds.\n                       If False, return raw Windows API values.\n\n    Returns:\n        When return_seconds=True:\n            Dict[str, float]: Dictionary with timing in seconds\n                - keyboard_delay_seconds: Initial delay before auto-repeat starts\n                - keyboard_rate_seconds: Interval between repeated keystrokes\n\n        When return_seconds=False:\n            Dict[str, int]: Dictionary with raw Windows API values\n                - keyboard_delay: Raw delay value (0-3 scale)\n                - keyboard_speed: Raw speed value (0-31 scale)\n\n    Raises:\n        OSError: If not running on Windows platform\n        RuntimeError: If Windows API call fails\n\n    Examples:\n        &gt;&gt;&gt; # Get timing in seconds (default)\n        &gt;&gt;&gt; timing = get_keyboard_repeat_timing()\n        &gt;&gt;&gt; print(f\"Delay: {timing['keyboard_delay_seconds']:.3f}s, Rate: {timing['keyboard_rate_seconds']:.3f}s\")\n\n        &gt;&gt;&gt; # Get raw Windows API values\n        &gt;&gt;&gt; raw_timing = get_keyboard_repeat_timing(return_seconds=False)\n        &gt;&gt;&gt; print(f\"Raw delay: {raw_timing['keyboard_delay']}, Raw speed: {raw_timing['keyboard_speed']}\")\n    \"\"\"\n    if sys.platform != \"win32\":\n        raise OSError(\"Keyboard repeat settings are only available on Windows\")\n\n    # Windows constants\n    SPI_GETKEYBOARDDELAY = 0x0016\n    SPI_GETKEYBOARDSPEED = 0x000A\n\n    # Get keyboard delay (0-3 scale)\n    keyboard_delay = wintypes.UINT(0)\n    if not ctypes.windll.user32.SystemParametersInfoW(SPI_GETKEYBOARDDELAY, 0, ctypes.byref(keyboard_delay), 0):\n        raise RuntimeError(\"Failed to get keyboard delay setting from Windows API\")\n\n    # Get keyboard speed (0-31 scale)\n    keyboard_speed = wintypes.UINT(0)\n    if not ctypes.windll.user32.SystemParametersInfoW(SPI_GETKEYBOARDSPEED, 0, ctypes.byref(keyboard_speed), 0):\n        raise RuntimeError(\"Failed to get keyboard speed setting from Windows API\")\n\n    # Convert to actual time values based on Microsoft documentation\n    # References:\n    # - KeyboardDelay: https://learn.microsoft.com/en-us/dotnet/api/system.windows.forms.systeminformation.keyboarddelay\n    # - KeyboardSpeed: https://learn.microsoft.com/en-us/dotnet/api/system.windows.forms.systeminformation.keyboardspeed\n\n    # Delay: 0=250ms, 1=500ms, 2=750ms, 3=1000ms (approximately)\n    keyboard_delay_seconds = 0.25 + (keyboard_delay.value * 0.25)\n\n    # Speed: 0=~2.5 repetitions/sec, 31=~30 repetitions/sec (from Microsoft docs)\n    # Linear interpolation formula (derived): repetitions_per_sec = 2.5 + (speed_value * 27.5 / 31)\n    # Where 27.5 = (30 - 2.5) is the range between max and min repetitions per second\n    repetitions_per_sec = 2.5 + (keyboard_speed.value * 27.5 / 31)\n    keyboard_rate_seconds = 1.0 / repetitions_per_sec\n\n    if return_seconds:\n        return {\"keyboard_delay_seconds\": keyboard_delay_seconds, \"keyboard_rate_seconds\": keyboard_rate_seconds}\n    else:\n        return {\"keyboard_delay\": keyboard_delay.value, \"keyboard_speed\": keyboard_speed.value}\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.callables.get_active_window","title":"window.get_active_window","text":"<pre><code>get_active_window() -&gt; WindowInfo | None\n</code></pre> <p>Get information about the currently active window.</p> <p>Returns:</p> Type Description <code>WindowInfo | None</code> <p>WindowInfo object containing title, position, and handle of the active window,</p> <code>WindowInfo | None</code> <p>or None if no active window is found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; window = get_active_window()\n&gt;&gt;&gt; if window:\n...     print(f\"Active window: {window.title}\")\n...     print(f\"Position: {window.rect}\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/window/callables.py</code> <pre><code>def get_active_window() -&gt; WindowInfo | None:\n    \"\"\"\n    Get information about the currently active window.\n\n    Returns:\n        WindowInfo object containing title, position, and handle of the active window,\n        or None if no active window is found.\n\n    Examples:\n        &gt;&gt;&gt; window = get_active_window()\n        &gt;&gt;&gt; if window:\n        ...     print(f\"Active window: {window.title}\")\n        ...     print(f\"Position: {window.rect}\")\n    \"\"\"\n    if _IS_DARWIN:\n        from Quartz import (\n            CGWindowListCopyWindowInfo,\n            kCGNullWindowID,\n            kCGWindowListOptionOnScreenOnly,\n        )\n\n        windows = CGWindowListCopyWindowInfo(kCGWindowListOptionOnScreenOnly, kCGNullWindowID)\n        for window in windows:\n            if window.get(\"kCGWindowLayer\", 0) == 0:  # Frontmost window\n                bounds = window.get(\"kCGWindowBounds\")\n                title = window.get(\"kCGWindowName\", \"\")\n                rect = (\n                    int(bounds[\"X\"]),\n                    int(bounds[\"Y\"]),\n                    int(bounds[\"X\"] + bounds[\"Width\"]),\n                    int(bounds[\"Y\"] + bounds[\"Height\"]),\n                )\n                hWnd = window.get(\"kCGWindowNumber\", 0)\n                return WindowInfo(title=title, rect=rect, hWnd=hWnd)\n        return None\n\n    elif _IS_WINDOWS:\n        import pygetwindow as gw\n\n        active_window = gw.getActiveWindow()\n        if active_window is not None:\n            rect = active_window._getWindowRect()\n            title = active_window.title\n            rect_coords = (rect.left, rect.top, rect.right, rect.bottom)\n            hWnd = active_window._hWnd\n            return WindowInfo(title=title, rect=rect_coords, hWnd=hWnd)\n        return WindowInfo(title=\"\", rect=[0, 0, 0, 0], hWnd=-1)\n    else:\n        raise NotImplementedError(f\"Platform {_PLATFORM} is not supported yet\")\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.callables.get_window_by_title","title":"window.get_window_by_title","text":"<pre><code>get_window_by_title(\n    window_title_substring: str,\n) -&gt; WindowInfo\n</code></pre> <p>Find a window by searching for a substring in its title.</p> <p>Parameters:</p> Name Type Description Default <code>window_title_substring</code> <code>str</code> <p>Substring to search for in window titles.</p> required <p>Returns:</p> Type Description <code>WindowInfo</code> <p>WindowInfo object for the first matching window.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no window with matching title is found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; window = get_window_by_title(\"notepad\")\n&gt;&gt;&gt; print(f\"Found window: {window.title}\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/window/callables.py</code> <pre><code>def get_window_by_title(window_title_substring: str) -&gt; WindowInfo:\n    \"\"\"\n    Find a window by searching for a substring in its title.\n\n    Args:\n        window_title_substring: Substring to search for in window titles.\n\n    Returns:\n        WindowInfo object for the first matching window.\n\n    Raises:\n        ValueError: If no window with matching title is found.\n\n    Examples:\n        &gt;&gt;&gt; window = get_window_by_title(\"notepad\")\n        &gt;&gt;&gt; print(f\"Found window: {window.title}\")\n    \"\"\"\n    if _IS_WINDOWS:\n        import pygetwindow as gw\n\n        windows = gw.getWindowsWithTitle(window_title_substring)\n        if not windows:\n            raise ValueError(f\"No window with title containing '{window_title_substring}' found.\")\n\n        # Temporal workaround to deal with `cmd`'s behavior: it setup own title as the command it running.\n        # e.g. `owl window find abcd` will always find `cmd` window itself running command.\n        if \"Conda\" in windows[0].title:\n            windows.pop(0)\n\n        window = windows[0]  # NOTE: only return the first window matching the title\n        rect = window._getWindowRect()\n        return WindowInfo(\n            title=window.title,\n            rect=(rect.left, rect.top, rect.right, rect.bottom),\n            hWnd=window._hWnd,\n        )\n\n    elif _IS_DARWIN:\n        from Quartz import CGWindowListCopyWindowInfo, kCGNullWindowID, kCGWindowLayer, kCGWindowListOptionOnScreenOnly\n\n        windows = CGWindowListCopyWindowInfo(kCGWindowListOptionOnScreenOnly, kCGNullWindowID)\n        for window in windows:\n            # Skip windows that are not on normal level (like menu bars, etc)\n            if window.get(kCGWindowLayer, 0) != 0:\n                continue\n\n            # Get window name from either kCGWindowName or kCGWindowOwnerName\n            title = window.get(\"kCGWindowName\", \"\")\n            if not title:\n                title = window.get(\"kCGWindowOwnerName\", \"\")\n\n            if title and window_title_substring.lower() in title.lower():\n                bounds = window.get(\"kCGWindowBounds\")\n                if bounds:\n                    return WindowInfo(\n                        title=title,\n                        rect=(\n                            int(bounds[\"X\"]),\n                            int(bounds[\"Y\"]),\n                            int(bounds[\"X\"] + bounds[\"Width\"]),\n                            int(bounds[\"Y\"] + bounds[\"Height\"]),\n                        ),\n                        hWnd=window.get(\"kCGWindowNumber\", 0),\n                    )\n\n        raise ValueError(f\"No window with title containing '{window_title_substring}' found.\")\n    else:\n        # Linux or other OS (not implemented yet)\n        raise NotImplementedError(\"Not implemented for Linux or other OS.\")\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.callables.get_pid_by_title","title":"window.get_pid_by_title","text":"<pre><code>get_pid_by_title(window_title_substring: str) -&gt; int\n</code></pre> <p>Get the process ID (PID) of a window by its title.</p> <p>Parameters:</p> Name Type Description Default <code>window_title_substring</code> <code>str</code> <p>Substring to search for in window titles.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Process ID of the window.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pid = get_pid_by_title(\"notepad\")\n&gt;&gt;&gt; print(f\"Notepad PID: {pid}\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/window/callables.py</code> <pre><code>def get_pid_by_title(window_title_substring: str) -&gt; int:\n    \"\"\"\n    Get the process ID (PID) of a window by its title.\n\n    Args:\n        window_title_substring: Substring to search for in window titles.\n\n    Returns:\n        Process ID of the window.\n\n    Examples:\n        &gt;&gt;&gt; pid = get_pid_by_title(\"notepad\")\n        &gt;&gt;&gt; print(f\"Notepad PID: {pid}\")\n    \"\"\"\n    window = get_window_by_title(window_title_substring)\n    if _IS_WINDOWS:\n        import win32process\n\n        # win32process.GetWindowThreadProcessId returns (tid, pid)\n        _, pid = win32process.GetWindowThreadProcessId(window.hWnd)\n        return pid\n    else:\n        # Implement if needed for other OS\n        raise NotImplementedError(f\"Getting PID by title not implemented for {_PLATFORM}\")\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.callables.when_active","title":"window.when_active","text":"<pre><code>when_active(window_title_substring: str) -&gt; Callable\n</code></pre> <p>Decorator to run a function only when a specific window is active.</p> <p>Parameters:</p> Name Type Description Default <code>window_title_substring</code> <code>str</code> <p>Substring to search for in window titles.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Decorator function that conditionally executes the wrapped function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @when_active(\"notepad\")\n... def do_something():\n...     print(\"Notepad is active!\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/window/callables.py</code> <pre><code>def when_active(window_title_substring: str) -&gt; Callable:\n    \"\"\"\n    Decorator to run a function only when a specific window is active.\n\n    Args:\n        window_title_substring: Substring to search for in window titles.\n\n    Returns:\n        Decorator function that conditionally executes the wrapped function.\n\n    Examples:\n        &gt;&gt;&gt; @when_active(\"notepad\")\n        ... def do_something():\n        ...     print(\"Notepad is active!\")\n    \"\"\"\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            if is_active(window_title_substring):\n                return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.callables.is_active","title":"window.is_active","text":"<pre><code>is_active(window_title_substring: str) -&gt; bool\n</code></pre> <p>Check if a window with the specified title substring is currently active.</p> <p>Parameters:</p> Name Type Description Default <code>window_title_substring</code> <code>str</code> <p>Substring to search for in window titles.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the window is active, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; if is_active(\"notepad\"):\n...     print(\"Notepad is the active window\")\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/window/callables.py</code> <pre><code>def is_active(window_title_substring: str) -&gt; bool:\n    \"\"\"\n    Check if a window with the specified title substring is currently active.\n\n    Args:\n        window_title_substring: Substring to search for in window titles.\n\n    Returns:\n        True if the window is active, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; if is_active(\"notepad\"):\n        ...     print(\"Notepad is the active window\")\n    \"\"\"\n    try:\n        window = get_window_by_title(window_title_substring)\n    except ValueError:\n        return False\n    active = get_active_window()\n    return active is not None and active.hWnd == window.hWnd\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.callables.make_active","title":"window.make_active","text":"<pre><code>make_active(window_title_substring: str) -&gt; None\n</code></pre> <p>Bring a window to the foreground and make it active.</p> <p>Parameters:</p> Name Type Description Default <code>window_title_substring</code> <code>str</code> <p>Substring to search for in window titles.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If no window with matching title is found.</p> <code>NotImplementedError</code> <p>If the operation is not supported on the current OS.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; make_active(\"notepad\")  # Brings notepad window to front\n</code></pre> Source code in <code>projects/owa-env-desktop/owa/env/desktop/window/callables.py</code> <pre><code>def make_active(window_title_substring: str) -&gt; None:\n    \"\"\"\n    Bring a window to the foreground and make it active.\n\n    Args:\n        window_title_substring: Substring to search for in window titles.\n\n    Raises:\n        ValueError: If no window with matching title is found.\n        NotImplementedError: If the operation is not supported on the current OS.\n\n    Examples:\n        &gt;&gt;&gt; make_active(\"notepad\")  # Brings notepad window to front\n    \"\"\"\n\n    os_name = platform.system()\n    if os_name == \"Windows\":\n        import pygetwindow as gw\n\n        windows = gw.getWindowsWithTitle(window_title_substring)\n        if not windows:\n            raise ValueError(f\"No window with title containing '{window_title_substring}' found.\")\n\n        # Temporal workaround to deal with `cmd`'s behavior: it setup own title as the command it running.\n        # e.g. `owl window find abcd` will always find `cmd` window itself running command.\n        if \"Conda\" in windows[0].title:\n            windows.pop(0)\n\n        window = windows[0]  # NOTE: only return the first window matching the title\n        window.activate()\n    else:\n        raise NotImplementedError(f\"Activation not implemented for this OS: {os_name}\")\n</code></pre>"},{"location":"env/plugins/desktop/#desktop-listeners","title":"Listeners","text":"<p>Usage: To use listener components, import <code>LISTENERS</code> from <code>owa.core</code> and call the <code>configure()</code> method with a <code>callback</code> function:</p> <pre><code>from owa.core import LISTENERS\n\n# Configure a listener component (replace 'component_name' with actual name)\nlistener = LISTENERS[\"desktop/component_name\"]\nlistener.configure(callback=my_callback, your_other_arguments)\n\n# Use the listener in a context manager\nwith listener.session as active_listener:\n    # The listener is now running and will call my_callback when events occur\n    pass  # Your main code here</code></pre> <p>Note: The <code>callback</code> argument is required. The <code>on_configure()</code> method shown in the documentation is an internal method called by <code>configure()</code>.</p>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.KeyboardListenerWrapper","title":"keyboard","text":"<p>               Bases: <code>Listener</code></p> <p>Keyboard event listener that captures key press and release events.</p> <p>This listener wraps pynput's KeyboardListener to provide keyboard event monitoring with OWA's listener interface.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def on_key_event(event):\n...     print(f\"Key {event.vk} was {event.event_type}\")\n&gt;&gt;&gt; listener = KeyboardListenerWrapper().configure(callback=on_key_event)\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.MouseListenerWrapper","title":"mouse","text":"<p>               Bases: <code>Listener</code></p> <p>Mouse event listener that captures mouse movement, clicks, and scroll events.</p> <p>This listener wraps pynput's MouseListener to provide mouse event monitoring with OWA's listener interface.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def on_mouse_event(event):\n...     print(f\"Mouse {event.event_type} at ({event.x}, {event.y})\")\n&gt;&gt;&gt; listener = MouseListenerWrapper().configure(callback=on_mouse_event)\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.RawMouseListener","title":"raw_mouse","text":"<p>               Bases: <code>Listener</code></p> <p>Raw mouse input listener using Windows WM_INPUT messages.</p> <p>This listener captures high-definition mouse movement data directly from the HID stack, bypassing Windows pointer acceleration and screen resolution limits. Provides sub-pixel precision and unfiltered input data essential for gaming and precision applications.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def on_raw_mouse_event(event):\n...     print(f\"Raw mouse: dx={event.dx}, dy={event.dy}, flags={event.button_flags}\")\n&gt;&gt;&gt; listener = RawMouseListener().configure(callback=on_raw_mouse_event)\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.RawMouseListener.on_configure","title":"on_configure","text":"<pre><code>on_configure()\n</code></pre> <p>Initialize the raw input capture system.</p> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/listeners.py</code> <pre><code>def on_configure(self):\n    \"\"\"Initialize the raw input capture system.\"\"\"\n    self.raw_input_capture = RawInputCapture()\n    self.raw_input_capture.register_callback(self._on_raw_mouse_event)\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.RawMouseListener.loop","title":"loop","text":"<pre><code>loop(stop_event, callback)\n</code></pre> <p>Start the raw input capture loop.</p> Source code in <code>projects/owa-env-desktop/owa/env/desktop/keyboard_mouse/listeners.py</code> <pre><code>def loop(self, stop_event, callback):\n    \"\"\"Start the raw input capture loop.\"\"\"\n    # Store the callback for use in the raw input callback\n    self._current_callback = callback\n\n    if not self.raw_input_capture.start():\n        raise RuntimeError(\"Failed to start raw input capture\")\n\n    # Keep the loop running while the capture is active\n    try:\n        # The Windows message loop in raw_input_capture handles events efficiently\n        # We just need to wait for the stop event without artificial delays\n        stop_event.wait()\n    finally:\n        self.raw_input_capture.stop()\n        self._current_callback = None\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.KeyboardStateListener","title":"keyboard_state","text":"<p>               Bases: <code>Listener</code></p> <p>Periodically reports the current keyboard state.</p> <p>This listener calls the callback function every second with the current keyboard state, including which keys are currently pressed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def on_keyboard_state(state):\n...     if state.buttons:\n...         print(f\"Keys pressed: {state.buttons}\")\n&gt;&gt;&gt; listener = KeyboardStateListener().configure(callback=on_keyboard_state)\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.keyboard_mouse.listeners.MouseStateListener","title":"mouse_state","text":"<p>               Bases: <code>Listener</code></p> <p>Periodically reports the current mouse state.</p> <p>This listener calls the callback function every second with the current mouse state, including position and pressed buttons.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def on_mouse_state(state):\n...     print(f\"Mouse at ({state.x}, {state.y}), buttons: {state.buttons}\")\n&gt;&gt;&gt; listener = MouseStateListener().configure(callback=on_mouse_state)\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/desktop/#owa.env.desktop.window.listeners.WindowListener","title":"window","text":"<p>               Bases: <code>Listener</code></p> <p>Periodically monitors and reports the currently active window.</p> <p>This listener calls the callback function every second with information about the currently active window, including title, position, and handle.</p> <p>Examples:</p> <p>Monitor active window changes:</p> <pre><code>&gt;&gt;&gt; def on_window_change(window):\n...     if window:\n...         print(f\"Active window: {window.title}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; listener = WindowListener().configure(callback=on_window_change)\n&gt;&gt;&gt; listener.start()\n&gt;&gt;&gt; # ... listener runs in background ...\n&gt;&gt;&gt; listener.stop()\n&gt;&gt;&gt; listener.join()\n</code></pre> <p>Track window focus for automation:</p> <pre><code>&gt;&gt;&gt; def track_focus(window):\n...     if window and \"notepad\" in window.title.lower():\n...         print(\"Notepad is now active!\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; listener = WindowListener().configure(callback=track_focus)\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/gst/","title":"GStreamer Environment","text":"<p>High-performance screen capture and multimedia processing (6x faster than alternatives).</p> <p>Installation</p> <pre><code>pip install owa-env-gst\n# Requires GStreamer dependencies - see installation guide\n</code></pre> <p>Requirements</p> <ul> <li>OS: Windows (Linux/macOS support planned)</li> <li>GPU: NVIDIA GPU required (our GStreamer implementation is NVIDIA-specific)</li> </ul>"},{"location":"env/plugins/gst/#components","title":"Components","text":"Component Type Description <code>gst/screen</code> Listener Real-time screen capture with callbacks <code>gst/screen_capture</code> Runnable On-demand screen capture <code>gst/omnimodal.appsink_recorder</code> Listener Omnimodal recording with appsink <code>gst/omnimodal.subprocess_recorder</code> Runnable Omnimodal recording via subprocess"},{"location":"env/plugins/gst/#performance","title":"Performance","text":"<p>Powered by GStreamer and Windows API, our implementation is 6x faster than alternatives:</p> Library Avg. Time per Frame Relative Speed owa.env.gst 5.7 ms \u26a1 1\u00d7 (Fastest) <code>pyscreenshot</code> 33 ms \ud83d\udeb6\u200d\u2642\ufe0f 5.8\u00d7 slower <code>PIL</code> 34 ms \ud83d\udeb6\u200d\u2642\ufe0f 6.0\u00d7 slower <code>MSS</code> 37 ms \ud83d\udeb6\u200d\u2642\ufe0f 6.5\u00d7 slower <code>PyQt5</code> 137 ms \ud83d\udc22 24\u00d7 slower <p>\ud83d\udccc Tested on: Intel i5-11400, GTX 1650</p> <p>Not only does <code>owa.env.gst</code> achieve higher FPS, but it also maintains lower CPU/GPU usage, making it the ideal choice for screen recording. Same applies for <code>ocap</code>, since it internally imports <code>owa.env.gst</code>.</p> <p>Benchmark Details</p> <p>These performance measurements were generated using our comprehensive benchmark script: <code>benchmark_screen_captures.py</code></p> <p>The script tests multiple screen capture libraries under identical conditions to ensure fair comparison. You can run it yourself to verify performance on your hardware.</p>"},{"location":"env/plugins/gst/#usage-examples","title":"Usage Examples","text":"Real-time CapturePerformance MonitoringOn-Demand Capture <pre><code>from owa.core import LISTENERS\nimport cv2\n\ndef process_frame(frame):\n    cv2.imshow(\"Screen Capture\", frame.frame_arr)\n    cv2.waitKey(1)\n\nscreen = LISTENERS[\"gst/screen\"]().configure(\n    callback=process_frame,\n    fps=60,\n    show_cursor=True\n)\n\nwith screen.session:\n    input(\"Press Enter to stop\")\n</code></pre> <pre><code>def process_with_metrics(frame, metrics):\n    print(f\"FPS: {metrics.fps:.2f}, Latency: {metrics.latency*1000:.2f}ms\")\n    cv2.imshow(\"Screen\", frame.frame_arr)\n    cv2.waitKey(1)\n\nscreen = LISTENERS[\"gst/screen\"]().configure(callback=process_with_metrics)\n</code></pre> <pre><code>from owa.core import RUNNABLES\n\ncapture = RUNNABLES[\"gst/screen_capture\"]().configure(fps=60)\n\nwith capture.session:\n    for i in range(10):\n        frame = capture.grab()\n        print(f\"Frame {i}: {frame.frame_arr.shape}\")\n</code></pre>"},{"location":"env/plugins/gst/#known-limitations","title":"Known Limitations","text":"<p>Current Limitations</p> <ul> <li>Windows only (Linux/macOS support planned)</li> <li>NVIDIA GPU required (our GStreamer implementation is NVIDIA-specific)</li> </ul>"},{"location":"env/plugins/gst/#windows-graphics-capture-api-wgc-issues","title":"Windows Graphics Capture API (WGC) Issues","text":"<p>When capturing some screen with <code>WGC</code> (Windows Graphics Capture API, activated when you specify window handle), the following issues are observed:</p> <ul> <li>FPS Limitation: Maximum FPS can't exceed maximum Hz of physical monitor</li> <li> <p>Variable FPS with specific applications: When capturing <code>Windows Terminal</code> and <code>Discord</code>, the following behavior was reported:</p> <ul> <li>When there's no change in window, FPS drops to 1-5 frames</li> <li>When there's change (e.g. mouse movement) in window, FPS immediately recovers to 60+</li> </ul> </li> </ul> <p>This phenomenon is likely due to WGC's optimization behavior.</p> <p>Implementation</p> <p>See owa-env-gst source for detailed implementation.</p>"},{"location":"env/plugins/gst/#api-reference","title":"API Reference","text":""},{"location":"env/plugins/gst/#gst","title":"gst plugin 0.6.0","text":"<p>High-performance GStreamer-based screen capture and recording plugin</p> <p>Author: OWA Development Team</p>"},{"location":"env/plugins/gst/#gst-listeners","title":"Listeners","text":"<p>Usage: To use listener components, import <code>LISTENERS</code> from <code>owa.core</code> and call the <code>configure()</code> method with a <code>callback</code> function:</p> <pre><code>from owa.core import LISTENERS\n\n# Configure a listener component (replace 'component_name' with actual name)\nlistener = LISTENERS[\"gst/component_name\"]\nlistener.configure(callback=my_callback, your_other_arguments)\n\n# Use the listener in a context manager\nwith listener.session as active_listener:\n    # The listener is now running and will call my_callback when events occur\n    pass  # Your main code here</code></pre> <p>Note: The <code>callback</code> argument is required. The <code>on_configure()</code> method shown in the documentation is an internal method called by <code>configure()</code>.</p>"},{"location":"env/plugins/gst/#owa.env.gst.screen.listeners.ScreenListener","title":"screen","text":"<p>               Bases: <code>GstPipelineRunner</code></p> <p>High-performance GStreamer-based screen capture listener for real-time frame processing.</p> <p>Captures screen content and delivers frames to a callback function. Can capture specific windows, monitors, or the entire screen.</p> <p>Example: <pre><code>from owa.core.registry import LISTENERS\nimport cv2\nimport numpy as np\n\n# Define a callback to process frames\ndef process_frame(frame):\n    # Display the frame\n    cv2.imshow(\"Screen Capture\", frame.frame_arr)\n    cv2.waitKey(1)\n\n# Create and configure the listener\nscreen = LISTENERS[\"screen\"]().configure(\n    callback=process_frame,\n    fps=30,\n    show_cursor=True\n)\n\n# Run the screen capture\nwith screen.session:\n    input(\"Press Enter to stop\")\n</code></pre></p> <p>For performance metrics: <pre><code>def process_with_metrics(frame, metrics):\n    print(f\"FPS: {metrics.fps:.2f}, Latency: {metrics.latency*1000:.2f} ms\")\n    cv2.imshow(\"Screen\", frame.frame_arr)\n    cv2.waitKey(1)\n\nscreen.configure(callback=process_with_metrics)\n</code></pre></p>"},{"location":"env/plugins/gst/#owa.env.gst.screen.listeners.ScreenListener.on_configure","title":"on_configure","text":"<pre><code>on_configure(\n    *,\n    callback: Callable,\n    show_cursor: bool = True,\n    fps: float = 60,\n    window_name: str | None = None,\n    monitor_idx: int | None = None,\n    additional_properties: dict | None = None,\n) -&gt; bool\n</code></pre> <p>Configure the GStreamer pipeline for screen capture.</p> <p>Other Parameters:</p> Name Type Description <code>callback</code> <code>Callable</code> <p>Function to call with each captured frame</p> <code>show_cursor</code> <code>bool</code> <p>Whether to show the cursor in the capture.</p> <code>fps</code> <code>float</code> <p>Frames per second.</p> <code>window_name</code> <code>str | None</code> <p>(Optional) specific window to capture.</p> <code>monitor_idx</code> <code>int | None</code> <p>(Optional) specific monitor index.</p> <code>additional_properties</code> <code>dict | None</code> <p>(Optional) additional arguments to pass to the pipeline.</p> Source code in <code>projects/owa-env-gst/owa/env/gst/screen/listeners.py</code> <pre><code>def on_configure(\n    self,\n    *,\n    callback: Callable,\n    show_cursor: bool = True,\n    fps: float = 60,\n    window_name: str | None = None,\n    monitor_idx: int | None = None,\n    additional_properties: dict | None = None,\n) -&gt; bool:\n    \"\"\"\n    Configure the GStreamer pipeline for screen capture.\n\n    Keyword Arguments:\n        callback: Function to call with each captured frame\n        show_cursor (bool): Whether to show the cursor in the capture.\n        fps (float): Frames per second.\n        window_name (str | None): (Optional) specific window to capture.\n        monitor_idx (int | None): (Optional) specific monitor index.\n        additional_properties (dict | None): (Optional) additional arguments to pass to the pipeline.\n    \"\"\"\n    # Construct the pipeline description\n    pipeline_description = screen_capture_pipeline(\n        show_cursor=show_cursor,\n        fps=fps,\n        window_name=window_name,\n        monitor_idx=monitor_idx,\n        additional_properties=additional_properties,\n    )\n    logger.debug(f\"Constructed pipeline: {pipeline_description}\")\n    super().on_configure(pipeline_description)\n\n    wrapped_callback = build_screen_callback(callback)\n    self.register_appsink_callback(wrapped_callback)\n</code></pre>"},{"location":"env/plugins/gst/#owa.env.gst.omnimodal.appsink_recorder.AppsinkRecorder","title":"omnimodal.appsink_recorder","text":"<p>               Bases: <code>GstPipelineRunner</code></p> <p>High-performance screen recorder using GStreamer appsink for real-time processing.</p> <p>This recorder captures screen content and saves it to a file while providing real-time frame notifications through a callback mechanism. It supports hardware acceleration and various output formats.</p> <p>Examples:</p> <p>Basic screen recording to file:</p> <pre><code>&gt;&gt;&gt; def on_frame(screen_data):\n...     print(f\"Recording frame at {screen_data.utc_ns}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; recorder = AppsinkRecorder()\n&gt;&gt;&gt; recorder.configure(\n...     filesink_location=\"output.mkv\",\n...     callback=on_frame\n... )\n&gt;&gt;&gt; recorder.start()\n</code></pre> <p>Recording with custom resolution:</p> <pre><code>&gt;&gt;&gt; recorder.configure(\n...     filesink_location=\"recording.mkv\",\n...     callback=my_callback,\n...     width=1920,\n...     height=1080\n... )\n</code></pre>"},{"location":"env/plugins/gst/#owa.env.gst.omnimodal.appsink_recorder.AppsinkRecorder.on_configure","title":"on_configure","text":"<pre><code>on_configure(\n    filesink_location: str,\n    *args: Any,\n    callback: Callable,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Configure the appsink recorder with output location and callback.</p> <p>Parameters:</p> Name Type Description Default <code>filesink_location</code> <code>str</code> <p>Path where the recording will be saved.</p> required <code>*args</code> <code>Any</code> <p>Additional positional arguments for pipeline configuration.</p> <code>()</code> <code>callback</code> <code>Callable</code> <p>Function to call for each recorded frame.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for pipeline configuration.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>Configuration is applied to the recorder instance.</p> Source code in <code>projects/owa-env-gst/owa/env/gst/omnimodal/appsink_recorder.py</code> <pre><code>def on_configure(self, filesink_location: str, *args: Any, callback: Callable, **kwargs: Any) -&gt; None:\n    \"\"\"\n    Configure the appsink recorder with output location and callback.\n\n    Args:\n        filesink_location: Path where the recording will be saved.\n        *args: Additional positional arguments for pipeline configuration.\n        callback: Function to call for each recorded frame.\n        **kwargs: Additional keyword arguments for pipeline configuration.\n\n    Returns:\n        None: Configuration is applied to the recorder instance.\n    \"\"\"\n    # if filesink_location does not exist, create it and warn the user\n    if not Path(filesink_location).parent.exists():\n        Path(filesink_location).parent.mkdir(parents=True, exist_ok=True)\n        logger.warning(f\"Output directory {filesink_location} does not exist. Creating it.\")\n\n    # convert to posix path. this is required for gstreamer executable.\n    filesink_location = Path(filesink_location).as_posix()\n\n    pipeline_description = appsink_recorder_pipeline(filesink_location, *args, **kwargs)\n    logger.debug(f\"Constructed pipeline: {pipeline_description}\")\n    super().on_configure(pipeline_description)\n\n    identity = self.pipeline.get_by_name(\"ts\")\n\n    notified_shape = None\n\n    def parse_shape_from_scale():\n        \"\"\"Parse the shape from the d3d11scale element.\"\"\"\n        scale = self.pipeline.get_by_name(\"d3d11scale0\")\n        # Get the source and sink capabilities\n        sink_caps = scale.get_static_pad(\"sink\").get_current_caps()\n        src_caps = scale.get_static_pad(\"src\").get_current_caps()\n        if sink_caps and src_caps:\n            sink_structure = sink_caps.get_structure(0)\n            src_structure = src_caps.get_structure(0)\n            return (sink_structure.get_value(\"width\"), sink_structure.get_value(\"height\")), (\n                src_structure.get_value(\"width\"),\n                src_structure.get_value(\"height\"),\n            )\n        logger.warning(\"Failed to get sink or source capabilities.\")\n        return None, None\n\n    def buffer_probe_callback(pad: Gst.Pad, info: Gst.PadProbeInfo):\n        \"\"\"Callback function to handle buffer probe events.\"\"\"\n\n        nonlocal notified_shape\n        buf = info.get_buffer()\n        frame_time_ns = time.time_ns()\n\n        clock = self.pipeline.get_clock()\n        elapsed = clock.get_time() - self.pipeline.get_base_time()\n        latency = elapsed - buf.pts\n\n        # warn if latency is too high, e.g. &gt; 100ms\n        if latency &gt; 100 * Gst.MSECOND:\n            logger.warning(f\"High latency: {latency / Gst.MSECOND:.2f}ms\")\n\n        original_shape, shape = parse_shape_from_scale()\n        if notified_shape != (original_shape, shape):\n            logger.success(f\"Video's original shape: {original_shape}, rescaled shape: {shape}\")\n            notified_shape = (original_shape, shape)\n\n        # Create ScreenCaptured with external video reference\n        from owa.msgs.desktop.screen import MediaRef\n\n        screen_captured = ScreenCaptured(\n            utc_ns=frame_time_ns,\n            source_shape=original_shape,\n            shape=shape,\n            media_ref=MediaRef(uri=filesink_location, pts_ns=buf.pts),\n        )\n        callback(screen_captured)\n        return Gst.PadProbeReturn.OK\n\n    identity.get_static_pad(\"src\").add_probe(Gst.PadProbeType.BUFFER, buffer_probe_callback)\n    self.enable_fps_display()\n</code></pre>"},{"location":"env/plugins/gst/#gst-runnables","title":"Runnables","text":"<p>Usage: To use runnable components, import <code>RUNNABLES</code> from <code>owa.core</code> and call the <code>configure()</code> method (not <code>on_configure()</code>):</p> <pre><code>from owa.core import RUNNABLES\n\n# Configure a runnable component (replace 'component_name' with actual name)\nrunnable = RUNNABLES[\"gst/component_name\"]\nrunnable.configure(your_arguments)\n\n# Use the runnable in a context manager\nwith runnable.session as active_runnable:\n    # The runnable is now running in the background\n    pass  # Your main code here</code></pre> <p>Note: The <code>on_configure()</code> method shown in the documentation is an internal method called by <code>configure()</code>.</p>"},{"location":"env/plugins/gst/#owa.env.gst.screen.runnable.ScreenCapture","title":"screen_capture","text":"<p>               Bases: <code>ScreenListener</code></p> <p>High-performance screen capture runnable using GStreamer pipeline for continuous frame grabbing.</p> <p>Captures screen frames continuously and makes the latest frame available through a thread-safe interface.</p> <p>Example: <pre><code>from owa.core.registry import RUNNABLES\n\nscreen_capture = RUNNABLES[\"screen_capture\"]().configure(fps=60)\n\nwith screen_capture.session:\n    for _ in range(10):\n        frame = screen_capture.grab()\n        print(f\"Shape: {frame.frame_arr.shape}\")\n</code></pre></p>"},{"location":"env/plugins/gst/#owa.env.gst.screen.runnable.ScreenCapture.on_configure","title":"on_configure","text":"<pre><code>on_configure(*args: Any, **kwargs: Any) -&gt; ScreenCapture\n</code></pre> <p>Configure and start the screen listener.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Additional positional arguments for screen capture configuration.</p> <code>()</code> <code>fps</code> <code>float</code> <p>Frames per second for capture.</p> required <code>window_name</code> <code>str</code> <p>Window to capture. If None, captures entire screen.</p> required <code>monitor_idx</code> <code>int</code> <p>Monitor index to capture.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for screen capture configuration.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ScreenCapture</code> <code>ScreenCapture</code> <p>Configured screen capture instance.</p> Source code in <code>projects/owa-env-gst/owa/env/gst/screen/runnable.py</code> <pre><code>def on_configure(self, *args: Any, **kwargs: Any) -&gt; \"ScreenCapture\":\n    \"\"\"\n    Configure and start the screen listener.\n\n    Args:\n        *args: Additional positional arguments for screen capture configuration.\n        fps (float): Frames per second for capture.\n        window_name (str, optional): Window to capture. If None, captures entire screen.\n        monitor_idx (int, optional): Monitor index to capture.\n        **kwargs: Additional keyword arguments for screen capture configuration.\n\n    Returns:\n        ScreenCapture: Configured screen capture instance.\n    \"\"\"\n    self.queue = deque(maxlen=1)  # Holds the most recent frame\n    self._event = threading.Event()\n\n    def on_frame(frame):\n        self.queue.append(frame)\n        self._event.set()\n\n    super().on_configure(callback=on_frame, *args, **kwargs)\n    return self\n</code></pre>"},{"location":"env/plugins/gst/#owa.env.gst.screen.runnable.ScreenCapture.grab","title":"grab","text":"<pre><code>grab() -&gt; ScreenCaptured\n</code></pre> <p>Get the most recent frame (blocks until frame is available).</p> <p>Returns:</p> Name Type Description <code>ScreenCaptured</code> <code>ScreenCaptured</code> <p>Latest captured frame with timestamp.</p> <p>Raises:</p> Type Description <code>TimeoutError</code> <p>If no frame is received within 1 second.</p> Source code in <code>projects/owa-env-gst/owa/env/gst/screen/runnable.py</code> <pre><code>def grab(self) -&gt; ScreenCaptured:\n    \"\"\"\n    Get the most recent frame (blocks until frame is available).\n\n    Returns:\n        ScreenCaptured: Latest captured frame with timestamp.\n\n    Raises:\n        TimeoutError: If no frame is received within 1 second.\n    \"\"\"\n    if not self._event.wait(timeout=1.0):\n        raise TimeoutError(\"Timeout waiting for frame\")\n    self._event.clear()\n    return self.queue[0]\n</code></pre>"},{"location":"env/plugins/gst/#owa.env.gst.omnimodal.subprocess_recorder.SubprocessRecorder","title":"omnimodal.subprocess_recorder","text":"<pre><code>SubprocessRecorder(*args, **kwargs)\n</code></pre> <p>               Bases: <code>SubprocessRunner</code></p> <p>High-performance screen and audio recorder using GStreamer subprocess.</p> <p>This recorder runs GStreamer as a subprocess to capture screen content and audio, providing excellent performance and stability for long recordings. Supports various output formats and hardware acceleration.</p> <p>Examples:</p> <p>Basic screen recording with audio:</p> <pre><code>&gt;&gt;&gt; recorder = SubprocessRecorder()\n&gt;&gt;&gt; recorder.configure(\n...     filesink_location=\"recording.mkv\",\n...     record_audio=True,\n...     record_video=True,\n...     fps=30\n... )\n&gt;&gt;&gt; recorder.start()\n&gt;&gt;&gt; # ... recording runs in background ...\n&gt;&gt;&gt; recorder.stop()\n</code></pre> <p>Video-only recording with custom settings:</p> <pre><code>&gt;&gt;&gt; recorder.configure(\n...     filesink_location=\"video_only.mp4\",\n...     record_audio=False,\n...     record_video=True,\n...     fps=60,\n...     show_cursor=False\n... )\n</code></pre> Source code in <code>projects/owa-core/owa/core/runnable.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Initialize a new RunnableThread. Whole arguments are passed to threading.Thread.\n\n    To configure the runnable, write your own on_configure method instead.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self._stop_event = threading.Event()\n</code></pre>"},{"location":"env/plugins/gst/#owa.env.gst.omnimodal.subprocess_recorder.SubprocessRecorder.on_configure","title":"on_configure","text":"<pre><code>on_configure(\n    filesink_location: str,\n    record_audio: bool = True,\n    record_video: bool = True,\n    record_timestamp: bool = True,\n    enable_fpsdisplaysink: bool = True,\n    show_cursor: bool = True,\n    fps: float = 60,\n    window_name: Optional[str] = None,\n    audio_window_name: Optional[str] = None,\n    monitor_idx: Optional[int] = None,\n    additional_properties: Optional[dict] = None,\n) -&gt; None\n</code></pre> <p>Prepare the GStreamer pipeline command for subprocess recording.</p> <p>Parameters:</p> Name Type Description Default <code>filesink_location</code> <code>str</code> <p>Path where the recording will be saved.</p> required <code>record_audio</code> <code>bool</code> <p>Whether to include audio in the recording.</p> <code>True</code> <code>record_video</code> <code>bool</code> <p>Whether to include video in the recording.</p> <code>True</code> <code>record_timestamp</code> <code>bool</code> <p>Whether to include timestamp information.</p> <code>True</code> <code>enable_fpsdisplaysink</code> <code>bool</code> <p>Whether to enable FPS display during recording.</p> <code>True</code> <code>show_cursor</code> <code>bool</code> <p>Whether to show the cursor in the recording.</p> <code>True</code> <code>fps</code> <code>float</code> <p>Frames per second for video recording.</p> <code>60</code> <code>window_name</code> <code>Optional[str]</code> <p>Specific window to record (optional).</p> <code>None</code> <code>audio_window_name</code> <code>Optional[str]</code> <p>Specific window to capture audio from (optional). If None, uses window_name.</p> <code>None</code> <code>monitor_idx</code> <code>Optional[int]</code> <p>Monitor index to record from (optional).</p> <code>None</code> <code>additional_properties</code> <code>Optional[dict]</code> <p>Additional pipeline properties (optional).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>Configuration is stored internally for subprocess execution.</p> Source code in <code>projects/owa-env-gst/owa/env/gst/omnimodal/subprocess_recorder.py</code> <pre><code>def on_configure(\n    self,\n    filesink_location: str,\n    record_audio: bool = True,\n    record_video: bool = True,\n    record_timestamp: bool = True,\n    enable_fpsdisplaysink: bool = True,\n    show_cursor: bool = True,\n    fps: float = 60,\n    window_name: Optional[str] = None,\n    audio_window_name: Optional[str] = None,\n    monitor_idx: Optional[int] = None,\n    additional_properties: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"\n    Prepare the GStreamer pipeline command for subprocess recording.\n\n    Args:\n        filesink_location: Path where the recording will be saved.\n        record_audio: Whether to include audio in the recording.\n        record_video: Whether to include video in the recording.\n        record_timestamp: Whether to include timestamp information.\n        enable_fpsdisplaysink: Whether to enable FPS display during recording.\n        show_cursor: Whether to show the cursor in the recording.\n        fps: Frames per second for video recording.\n        window_name: Specific window to record (optional).\n        audio_window_name: Specific window to capture audio from (optional). If None, uses window_name.\n        monitor_idx: Monitor index to record from (optional).\n        additional_properties: Additional pipeline properties (optional).\n\n    Returns:\n        None: Configuration is stored internally for subprocess execution.\n    \"\"\"\n\n    # if filesink_location does not exist, create it and warn the user\n    if not Path(filesink_location).parent.exists():\n        Path(filesink_location).parent.mkdir(parents=True, exist_ok=True)\n        logger.warning(f\"Output directory {filesink_location} does not exist. Creating it.\")\n\n    # convert to posix path. this is required for gstreamer executable.\n    filesink_location = Path(filesink_location).as_posix()\n\n    pipeline_description = subprocess_recorder_pipeline(\n        filesink_location=filesink_location,\n        record_audio=record_audio,\n        record_video=record_video,\n        record_timestamp=record_timestamp,\n        enable_fpsdisplaysink=enable_fpsdisplaysink,\n        show_cursor=show_cursor,\n        fps=fps,\n        window_name=window_name,\n        audio_window_name=audio_window_name,\n        monitor_idx=monitor_idx,\n        additional_properties=additional_properties,\n    )\n\n    super().on_configure(f\"gst-launch-1.0.exe -e -v {pipeline_description}\".split())\n</code></pre>"},{"location":"env/plugins/std/","title":"Standard Environment","text":"<p>Core utilities and timing functions for OWA agents.</p> <p>Installation</p> <pre><code>pip install owa-core  # Included automatically\n</code></pre>"},{"location":"env/plugins/std/#components","title":"Components","text":"Component Type Description <code>std/time_ns</code> Callable Get current time in nanoseconds <code>std/tick</code> Listener Periodic callback execution"},{"location":"env/plugins/std/#usage-examples","title":"Usage Examples","text":"Time FunctionsPeriodic TasksManual Control <pre><code>from owa.core import CALLABLES\n\n# Get current time\ncurrent_time = CALLABLES[\"std/time_ns\"]()\nprint(f\"Current time: {current_time}\")\n</code></pre> <pre><code>from owa.core import LISTENERS\nimport time\n\ndef on_tick():\n    print(f\"Tick: {CALLABLES['std/time_ns']()}\")\n\n# Using context manager (recommended)\ntick = LISTENERS[\"std/tick\"]().configure(callback=on_tick, interval=1)\nwith tick.session:\n    time.sleep(3)  # Prints every second for 3 seconds\n</code></pre> <pre><code># Manual start/stop control\ntick = LISTENERS[\"std/tick\"]().configure(callback=on_tick, interval=1)\ntick.start()\ntime.sleep(3)\ntick.stop()\ntick.join()\n</code></pre>"},{"location":"env/plugins/std/#api-reference","title":"API Reference","text":""},{"location":"env/plugins/std/#std","title":"std plugin 0.6.0","text":"<p>Standard system components for OWA</p> <p>Author: OWA Development Team</p>"},{"location":"env/plugins/std/#std-callables","title":"Callables","text":"<p>Usage: To use callable components, import <code>CALLABLES</code> from <code>owa.core</code> and access them by their component name:</p> <pre><code>from owa.core import CALLABLES\n\n# Access a callable component (replace 'component_name' with actual name)\ncallable_func = CALLABLES[\"std/component_name\"]\nresult = callable_func(your_arguments)</code></pre>"},{"location":"env/plugins/std/#owa.env.std.clock.time_ns","title":"time_ns","text":"<pre><code>time_ns() -&gt; int\n</code></pre> <p>Return the current time in nanoseconds since the Unix epoch.</p> <p>This function provides high-precision timing for OWA components, useful for performance measurement and precise scheduling.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Current time in nanoseconds since Unix epoch (January 1, 1970)</p> <p>Examples:</p> <p>Get current timestamp:</p> <pre><code>&gt;&gt;&gt; current_time = time_ns()\n&gt;&gt;&gt; print(f\"Current time: {current_time}\")\n</code></pre> <p>Measure execution time:</p> <pre><code>&gt;&gt;&gt; start = time_ns()\n&gt;&gt;&gt; # ... some operation ...\n&gt;&gt;&gt; duration = time_ns() - start\n&gt;&gt;&gt; print(f\"Operation took {duration} nanoseconds\")\n</code></pre> Source code in <code>projects/owa-core/owa/env/std/clock.py</code> <pre><code>def time_ns() -&gt; int:\n    \"\"\"\n    Return the current time in nanoseconds since the Unix epoch.\n\n    This function provides high-precision timing for OWA components,\n    useful for performance measurement and precise scheduling.\n\n    Returns:\n        int: Current time in nanoseconds since Unix epoch (January 1, 1970)\n\n    Examples:\n        Get current timestamp:\n\n        &gt;&gt;&gt; current_time = time_ns()\n        &gt;&gt;&gt; print(f\"Current time: {current_time}\")\n\n        Measure execution time:\n\n        &gt;&gt;&gt; start = time_ns()\n        &gt;&gt;&gt; # ... some operation ...\n        &gt;&gt;&gt; duration = time_ns() - start\n        &gt;&gt;&gt; print(f\"Operation took {duration} nanoseconds\")\n    \"\"\"\n    return time.time_ns()\n</code></pre>"},{"location":"env/plugins/std/#std-listeners","title":"Listeners","text":"<p>Usage: To use listener components, import <code>LISTENERS</code> from <code>owa.core</code> and call the <code>configure()</code> method with a <code>callback</code> function:</p> <pre><code>from owa.core import LISTENERS\n\n# Configure a listener component (replace 'component_name' with actual name)\nlistener = LISTENERS[\"std/component_name\"]\nlistener.configure(callback=my_callback, your_other_arguments)\n\n# Use the listener in a context manager\nwith listener.session as active_listener:\n    # The listener is now running and will call my_callback when events occur\n    pass  # Your main code here</code></pre> <p>Note: The <code>callback</code> argument is required. The <code>on_configure()</code> method shown in the documentation is an internal method called by <code>configure()</code>.</p>"},{"location":"env/plugins/std/#owa.env.std.clock.ClockTickListener","title":"tick","text":"<p>               Bases: <code>Listener</code></p> <p>A listener that triggers callbacks at regular intervals.</p> <p>This listener provides precise timing for periodic tasks in OWA, supporting configurable intervals and automatic callback execution.</p> <p>Examples:</p> <p>Basic usage with 1-second interval:</p> <pre><code>&gt;&gt;&gt; def on_tick():\n...     print(f\"Tick at {time_ns()}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; listener = ClockTickListener()\n&gt;&gt;&gt; listener.configure(callback=on_tick, interval=1)\n&gt;&gt;&gt; listener.start()\n&gt;&gt;&gt; # ... listener runs in background ...\n&gt;&gt;&gt; listener.stop()\n&gt;&gt;&gt; listener.join()\n</code></pre> <p>Custom interval timing:</p> <pre><code>&gt;&gt;&gt; listener = ClockTickListener()\n&gt;&gt;&gt; listener.configure(callback=my_callback, interval=0.5)  # 500ms\n&gt;&gt;&gt; listener.start()\n</code></pre>"},{"location":"env/plugins/std/#owa.env.std.clock.ClockTickListener.on_configure","title":"on_configure","text":"<pre><code>on_configure(*, interval: float = 1)\n</code></pre> <p>Configure the tick interval for the listener.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>float</code> <p>Time between ticks in seconds. Defaults to 1.0.</p> <code>1</code> <p>Examples:</p> <p>Configure for 100ms intervals:</p> <pre><code>&gt;&gt;&gt; listener.configure(callback=my_func, interval=0.1)\n</code></pre> Source code in <code>projects/owa-core/owa/env/std/clock.py</code> <pre><code>def on_configure(self, *, interval: float = 1):\n    \"\"\"\n    Configure the tick interval for the listener.\n\n    Args:\n        interval (float): Time between ticks in seconds. Defaults to 1.0.\n\n    Examples:\n        Configure for 100ms intervals:\n\n        &gt;&gt;&gt; listener.configure(callback=my_func, interval=0.1)\n    \"\"\"\n    self.interval = interval * S_TO_NS\n</code></pre>"},{"location":"env/plugins/std/#owa.env.std.clock.ClockTickListener.loop","title":"loop","text":"<pre><code>loop(*, stop_event, callback)\n</code></pre> <p>Main loop that executes callbacks at configured intervals.</p> <p>Parameters:</p> Name Type Description Default <code>stop_event</code> <p>Threading event to signal when to stop</p> required <code>callback</code> <p>Function to call at each tick</p> required Note <p>This method runs in a separate thread and maintains precise timing by accounting for callback execution time.</p> Source code in <code>projects/owa-core/owa/env/std/clock.py</code> <pre><code>def loop(self, *, stop_event, callback):\n    \"\"\"\n    Main loop that executes callbacks at configured intervals.\n\n    Args:\n        stop_event: Threading event to signal when to stop\n        callback: Function to call at each tick\n\n    Note:\n        This method runs in a separate thread and maintains precise timing\n        by accounting for callback execution time.\n    \"\"\"\n    self._last_called = time.time()\n    while not stop_event.is_set():\n        callback()\n        to_sleep = self.interval - (time.time() - self._last_called)\n        if to_sleep &gt; 0:\n            stop_event.wait(to_sleep / S_TO_NS)\n</code></pre>"}]}